{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLlOLCPYgIUT"
      },
      "source": [
        "# Getting the audio files\n",
        "* We send request with urllib.request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wQiba-fcRlce"
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "urllib.request.urlretrieve (\"https://goo.gl/8hY5ER\",\"a.tar.gz\")\n",
        "import tarfile\n",
        "tar = tarfile.open(\"a.tar.gz\")\n",
        "tar.extractall()\n",
        "tar.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "N4GRPmWeXPDE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "\n",
        "os.remove(\"a.tar.gz\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZXBQCe9gSN6"
      },
      "source": [
        "# Metadata DataFrame View"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "0ygZWwjNSLay",
        "outputId": "3e161f3f-483e-4fe6-d0fd-b2753b5343e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4244549e-3dec-4d61-9051-ca9a4f65e562\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4244549e-3dec-4d61-9051-ca9a4f65e562')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4244549e-3dec-4d61-9051-ca9a4f65e562 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4244549e-3dec-4d61-9051-ca9a4f65e562');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "data=pd.read_csv(\"UrbanSound8K/metadata/UrbanSound8K.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62KuqEjySSUU"
      },
      "source": [
        "# Sample Visualisation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "tvKZw1vLSN5w"
      },
      "outputs": [],
      "source": [
        "### Let's read a sample audio using librosa\n",
        "import librosa\n",
        "audio_file_path='/content/UrbanSound8K/audio/fold1/101415-3-0-2.wav'\n",
        "librosa_audio_data,librosa_sample_rate=librosa.load(audio_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5l7YHy9nY0qa",
        "outputId": "80d72ada-21f3-4305-87bf-62ccd35802a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.00011662 -0.00017163 -0.00017833 ... -0.04541198 -0.04675572\n",
            " -0.05040179]\n"
          ]
        }
      ],
      "source": [
        "print(librosa_audio_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lxXcoQI7WZ__",
        "outputId": "d558d410-b318-4b8c-d633-c68fdc04618d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef create_spectrogram(y):\\n  spec = librosa.feature.melspectrogram(y=y)\\n  spec_conv = librosa.amplitude_to_db(spec, ref=np.max)\\n  return spec_conv\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\"\"\"\n",
        "def create_spectrogram(y):\n",
        "  spec = librosa.feature.melspectrogram(y=y)\n",
        "  spec_conv = librosa.amplitude_to_db(spec, ref=np.max)\n",
        "  return spec_conv\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "TIGKBhWtXCv3",
        "outputId": "9e540997-7e0d-465c-e2c9-75dd5df6d5ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5ed1526cd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "###  plot the librosa audio data\n",
        "import matplotlib.pyplot as plt\n",
        "# Original audio with 1 channel \n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(librosa_audio_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZIHijMwghf6"
      },
      "source": [
        "## Read with Scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G1fdBtgGY40Z"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile as wav\n",
        "wave_sample_rate, wave_audio = wav.read(audio_file_path) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZF8tZ2lRY9_M",
        "outputId": "ac6a042a-3a50-4fab-e64c-71bb7269566b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   -5,    -5,    -6, ..., -1576, -1566, -1557], dtype=int16)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "wave_audio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esZ-2h_8gqSU"
      },
      "source": [
        "## Original audio with 2 channel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "l73xz23PY_OE",
        "outputId": "94cbb4a8-629b-4f8d-c90d-4a7fdcf25a0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f5ed096b210>]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAugAAAD4CAYAAAC+ExMiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXxU1fk/8M+TmWxkhSRESIBADCAiyCKiLC6gAi5o3WsVl5bWtdX211KxSutSra39FrVatwouVeoGCoiIoKIiArLIHpYAAUIIZCN7cn5/zA2dhJlkMnOXuXc+79crL2bOvXPPmcssz5x7znNEKQUiIiIiIgoPUVY3gIiIiIiI/ocBOhERERFRGGGATkREREQURhigExERERGFEQboRERERERhxG11A4ySnp6ucnJyrG4GERERETnc6tWrDyulMvQ6nmMD9JycHKxatcrqZhARERGRw4lIgZ7H4xAXIiIiIqIwwgCdiIiIiCiMMEAnIiIiIgojDNCJiIiIiMIIA3QiIiIiojDCAJ2IiIiIKIwwQCciIiIiCiMM0Iki2KGKGtTUN1rdDCIKwJfbi1FQcszqZhCRCRigE0WwEY8uwY9fXGF1M4goADe+vBLnPLnM6mYQkQkYoBNFuDV7Sq1uAhEREXlhgE5EREREFEYYoBNFoH8uy0fOtPlWN4OIiIh8YIBOFIGeW7rD6iYQERGRHwzQiYiIiIjCCAN0ogikrG4AERER+cUAnSgCVdY2WN0EIiIi8oMBOhERERFRGGGATkREREQURhigExFWFxzBrsNcQpyIiCgcuK1uABFZ78rnvgEA7H78YotbQkTtaWxScEWJ1c0gIgOxB52IiMhG3l2zz+omEJHBGKATERHZSBWzMBE5HgN0IiIi8qmxSeHJRVtQWlVndVOIIgoDdCIiojBWWduAmvrG4/dnfLgJdQ1NptT96eYiPLt0B07/02JT6iMiD04SdZAvthWjtLoelw3ubnVTiIhIJwMfWoS0hJgWZWv2HMXIPmmG1/3JxiLD6yCiEzFAd5CbXlkJAAzQiYgcQikFACg5Zs0QE05IJbIGA3SiCLK64Cge/miT1c0gogB9tuWQz3Itbicih2KAThRBrnzua6ubQEQdcLiy1uomHKeUggjzrxOZIeRJoiLSQ0SWisgmEdkoIr/UyruIyGIR2a7921krFxGZKSL5IrJeRIZ6HWuKtv92EZniVT5MRDZoj5kp/IQgIqIIpmB+F/q7awpNr5MoUumRxaUBwK+VUgMAjARwp4gMADANwBKlVB6AJdp9AJgIIE/7mwrgOcAT0AN4CMCZAEYAeKg5qNf2+ZnX4ybo0G4iauWe/3xvdROIKEytLjhqdROIIkbIAbpS6oBSao12uwLAZgBZACYDmKXtNgvA5drtyQBmK48VAFJFpBuAiwAsVkodUUodBbAYwARtW7JSaoXyzJaZ7XUsItLRvHX7rW4CEQXg9RUFVjeBiAykax50EckBMATAtwAylVIHtE0HAWRqt7MA7PV62D6trK3yfT7KiYiIHM3fZNAFGw6a2xAAsGBYDVGk0i1AF5FEAO8C+JVSqtx7m9bzbfg7W0SmisgqEVlVXFxsdHVhq7qusf2diIiI2lDf2HIxpMLSGotaQhR5dAnQRSQanuD8DaXUe1pxkTY8Bdq/zbmiCgH08Hp4tlbWVnm2j/ITKKVeUEoNV0oNz8jICO1J2diyrb7TclFkU8zLRkQd8PWOkhb3v9gWuR1fRGbTI4uLAHgZwGal1FNem+YBaM7EMgXAXK/ym7RsLiMBlGlDYRYBuFBEOmuTQy8EsEjbVi4iI7W6bvI6FhEFiBO8iIiI7EGPPOijANwIYIOIrNXK7gfwOIA5InIbgAIA12jbFgCYBCAfQBWAWwBAKXVERB4G8J2235+UUke023cAeBVAPICF2h8RdUBDE3vQieyGSYWJIlPIAbpSajkAfx8h43zsrwDc6edYrwB4xUf5KgADQ2gmERGR7XBkGlFk0jWLCxEREZEeHv5oE+58c43VzSCyBAN0IiIiCjsvL9+F+esP4EBZtaXtKCg5hpxp8/FV/mFL20GRhQE6EbVg9ZchEQVu39Eqw44dLhnBpr27wdL6z3lyGQDghpe+tbQdFFkYoDtEEycAkk6+3Xmk/Z2IyHJPLtqC0U8sxQff+8w8HLJ/f7XbkON21OfbilHX0NT+jkQOwgDdIcqq661uAoW57/eUBrTfAx/8YHBLiChQbXW9PLt0BwBg7d5SlFbVYe5aYwL1cJB/qNLqJhCZSo80i0RkA098vCWg/SprGwxuCRHpqbFJ4fQ/LQYAZCbHYXB2KuJjXBa3KjRHj9W1uK+MX4ycKKywB52IiChMBZIG/bUVBcdvX/fCCoz72zLD2mOWO95omb3lxpdXWtQSImswQCciInKQ/WU1VjchZEXlLZ/DkVY96mb5obCsxf3ahkZL2kGRhwE6ERERkQ+/nrOuxf07XmdedjIHA3QiIqIwFakjr1v3oFtlV8mxFveXbAmP1JPkfAzQiYiIKKw0MHUwRTgG6A4kgcwqIiIi8uMYszkBCGySLpERGKA7kGLHAxERhWDFzhKf5f7ykReWVmNPiXGrmlqFHV5kFQboDvHs0nyrm0BERA4x9bXVPssXbDjgs3zU459h7JNLdau/liuHUoRjgO4QLy3fZXUTyEFyps3Hb99Z1/6ORORIjX7GgHPoC5E5GKA7EC/JkR7mrNpndROIKMz864udVjfBVMJR6GQRBugOYNUCDkREZKyN+8va34kM46vDa8M+/p+Q8RigO8DRqpYBOieJEhE5w+sr9ljdhLCxavcR0+v01X9+6TPLTW8HRR4G6ERERBS0+kZzJnT6m7hK5EQM0B3ove8LrW4CERFZ6JGPNplWV3V9oyn1tL5a3OzL7cX4zX+NmdQunNRFFmGA7kCLNxVZ3QQKM1sOllvdBCIykZGZvWrqG1FSWWvY8Zv8ZJDxN3zzxpdX4p3Vxkxqr2TWGrIIA3QHOFBaY3UTKMyt3GX+2E0icqYr/vk1hj3yKWobjOk5f3TBZkOOS2QnDNAd4JZXV1rdBCIiihCbD3iuyBk1gfV9DtMkYoDuBPWNTNtCRETmMmtyaKB2Flda3QRT1Dc24a431yD/UIXVTSEDMUAnigArdpZY3QQiMtmwhxebUo/eqX39rWLqS3Xd/4bZzFyyXdd2NF8pCCfVdY3Im74QH60/gPFPfWF1c8hADNAjzPl/W4Y3vi2wuhlksgUbDlrdBCIyWYkFi9it31ca8jHKqusD3vet74zLE19U7n9+V0VN4G3U04pdLTtb2moj2RsD9Aizs/gYpr//g9XNICIim3t84RbkTJuPwX/85HjZZc98ZWobjFyYr60Ui4cqjMti05bPNh9qcb+uIbyGGZF+GKATERGFIWXRstB2Wsq+yesc6X22Pv4h/K48vrai5RXwVQXM0OVUugToIvKKiBwSkR+8yrqIyGIR2a7921krFxGZKSL5IrJeRIZ6PWaKtv92EZniVT5MRDZoj5kpXDmAKGD7S6utbgIRBWHW17stqfeyZ+2zlP0j841Lyfiflf6Hz3j/dqqua8TfF2+zpDf73rfXYenWQ+3vSLajVw/6qwAmtCqbBmCJUioPwBLtPgBMBJCn/U0F8BzgCegBPATgTAAjADzUHNRr+/zM63Gt6yIiP57+LN/qJhBREL7fG/p47mBY1HEfkLauKhytsmZc+PT3N+AfS7a3GdAb6ZZ/f4cXv9hpSd1kHF0CdKXUFwBaX2eZDGCWdnsWgMu9ymcrjxUAUkWkG4CLACxWSh1RSh0FsBjABG1bslJqhfK8M2d7HYuIiIgixME2JkV+sa3YtHbM/mb38dvvaXnbq+uNWbgpEFzcyXmMHIOeqZQ6oN0+CCBTu50FYK/Xfvu0srbK9/koP4GITBWRVSKyqrjYvDdqOCq3aIY5ERGRUZpTMH67s0SXjDHBemf1vhPKHl+4xYKWkFOZMklU6/k2/KKZUuoFpdRwpdTwjIwMo6sLC6v9TBDZdpALGJCHmb1KRKSfb3bYc/2CjfuNm2Q6+oml2FNShWtfWGF6xhgiMxkZoBdpw1Og/ds8i6EQQA+v/bK1srbKs32UE+z7AU7mKeQkUSJbsiqVX6iWbTW2U2Dsk0sNPX4gquqsG85CkcHIAH0egOZMLFMAzPUqv0nL5jISQJk2FGYRgAtFpLM2OfRCAIu0beUiMlLL3nKT17Ei3l8/2eaz/EAZFy8gIiJ7OVTB7y5/2svItfdIlUktITPolWbxPwC+AdBPRPaJyG0AHgdwgYhsBzBeuw8ACwDsBJAP4EUAdwCAUuoIgIcBfKf9/Ukrg7bPS9pjdgBYqEe7nezu/3xvdROIiIg65M1vrcmEEqwP1+03ra7v97Q95p4pdZ3FrcdBlFLX+9k0zse+CsCdfo7zCoBXfJSvAjAwlDZGsqLyGnRJiEG0i+tSERGRsZ5ctBWn90jFqJPTO/zY//t0uwEt6rjtRYHN4zKzM4wrwEQWRmwOV1PfiDMfW4Jp725A/qFKq5tDREQRYOrsVVY3ISQX/P0Lq5vQYcWV9pyzQL4xQHe4Gi0v6+JNB/HI/E0Wt4bsZvAfP8EV/2SmBCKzcTxx+Pvroq0nlDWngTTCHW+saXP7XW9yaKuTMEB3uGItC4CIgFfHIk9ZdWj58Muq6/H9ntI2V+8jIv2Nf+pzq5tgqobGJlTVNVjdjA55ZumJqzQ///kOC1piD5v2l+OTjQetboZtMEB3uObLdGXV9YjiALaIo1dvzlOLfWcLIiJj1DY0Wd2EkEgHv2/ueet7DHhwkUGtMc+eEn2vfLy2ogA50+Zj1+Fjuh7XCpNmfompr622uhm2wQA9guwusf8bnKwxZ9Xe9nciIgrSgg369Kxa3QuvdF6T8Q8f/AAAOO+vyzrWDqXQZOBwGzIeA/QIsqOYAXqk0euaSVE5Jx8RUfirrQ/9ysNnW4pCPkZdQxN2W9jr/bPZq9Dn/gWW1U+hY4DuYM8t41g4IiIKnBOyfTU1KTy+cEvQix69tyb4xcqbp+s88MEGnPvXZSitqgv6WKH4dPOh9neisMYA3cGe+HiL1U0gi63YWWJ1E4jIRpZsDr33GNDv6l1HXf/iCry0fCee/3wHRjy6BJ9u6vjz+WZH8J+bX+8oQf6hSnyV7zlGZa29Jr62RymF2oZGv9tr6huxcX+ZiS1yLgboNrZ0K38hU9vueYtpt4jsZvY3u3U93r6jVagLYNLp3xdvw58X2rtjZ8vBCjy24H/P4adB5GMvORZ8r3dhaXWLDDyjn1h6PJuaFV79apeux3t9RQH6PfAxDpbVYO3e0uOpnGsbGvGz2avQ/w8f4+KZyy19zk6hy0qiZI1b/v2d1U2gMLatqAL1jZwkRGQ3D87dqNuxqusaMfqJpbj89O74v+uGtLnvP5aExyqeVlpdcET3Y367qwSXDOoe8P5l1fWY891e9EzrFHLdMz7chCln53Q4q44/89btBwB8veMw7puzDuNP6epzOI1nsm6sLnVGKgboRA61k5OCiSJe8xCLJVt4xbU989cfwJ1vtr0YkBkenPsD5q7dr9vx6hsVYtz6BOiHtJ7x++asA8Cx7kbiEBcih2LaeyI649FPAQAVNeaOha6obcAnGw/io/X6BZpG0zM4D+XzV8/gXG8FOud5J/8YoBM51Mc/cMU2IgqMEUM7pr62Gne9+T1yps1HQ6P/MfBG5+sOdUVlM723Zp/VTfCrI5M/S6vsc87DFQN0Iod6//vgU4URkfOc9pD/lTqvfO4bQ+uuayNAb2ubHvYesU+v7zur9Q/QP1ynT4/8//vv+oD3/XmrFUOtzAlvVwzQbcpOHzhERBSYgW0E0aGqcFjKPz0dDSFzSyDHbgzwKoERQxNnfrYdSoV+lWLTgfKA9z1Y3jIH/cvL9c0mEwkYoNtUUXlwCzA0y5k2n79oiYjCjNPyZjfTIT40tO4hDy/Wtc59R6uP3/7D3I14bMHmgB7XnD9dTwUlVXhz5R7dj9ue+sYmKKXw0pc78dqKAtPrtzsG6BFs5W79xxwSERF1xC6DO4sUrE83a9acoH1Hq7QUhy3tsWByZ970hfj1nHV4ZH7LHyeHKmoMuWLR1KQMn89gJgboEYxJPoiIwodVy8JbqaquARP/8aWhdcz+pgA50+Zj0/7yNlfBNFJhaTVmtpNnfn9pdZvbAzH6iaUY8OCJw6SsClvf8zEXasSjS3S/YgEAudMXYNJMY19LZmKAblPbiiqtbgIREenoL4u2WlLvmj1HDa/j1IcWnTA0s7ahEb/57zrD626eeDlp5pd4SMdFoDrqqcXb2tx++bNfGVp/eU3wmVVe/GKnji0xhlKelWSdggG6Td3//oaQj6HXymJERBS6tlIRGulH//zalHq80/TtPVKFfg98jAUbzE0H62to58INB0yrv61e8uZFgIzwwhc7MWjGJ5i7NrjsXo8GOIae9MMA3YZmzNOnB2D7oQpdZnZTZKisbcAPhYHnwSWijhETBh4+8MEGPLs03/B6fPH+utlpUZICX195Mz40r1f96ueNTWfZni+2He7wY7baoFfaiZntGKDb0Ktf79blOP/6fCeeWrzNUZMqyDhTZ6/CJU8vR71FvXxEFLrXV+zBk4u24t9fmZ/27rZZq5B/yDM806rrt94TKHcUVyJn2nwUlRvXc93agbLQx5mb7bJnlhtyXD2HVo35y1LdjhUuGKBHuKc/y0ef+xdg2dZDVjeFdLS5A/lqA/X1Dk/6r+X5He+BIaK2rS44irdX7TWtvj9+uMmSSanjn/ocOdPm46ZXVppeNwAUldceH2by4xdXWNIGX4xYoMiXYEa21jYY0ykzY95GXYZ16TG5NhwxQLcZo4ak3Pzv7ww5LlnDyKwIf+ZYRCLdXfmcOePAvR0oC209Dbvaow2HqKk3/2qgrwvWZdX1pkyWBYAvthWbUk8g1u8rw8AZoS/MVVHjzLUD3FY3gDrGyNW4lm45hP7dktAtJd6wOsh4Ri9AxWkLRM4w8R9fYuLAk6xuhumsTo9QUlmLlPhoKADRrihc+rQxQ0h8MXIiajD0+JHk1HwX7EG3mU82Fhl27Fte/Q5n/fkzw45P5jj3r8sMPf7BshqcNmMR5nxn3uV4IiezcrL+QpMW0Aknz3++A6sLrFuob9gjn+Lk6Qsx4MGP8fqKguM9+ma54KnPA973KxOGNG7Yx+QDvjBAt5kKE5aBrqlv5ERAm6qpN34RjoraBlTUNOC3767Hl9vD53IpkV1Zlf88Ui3dWowrn/sGZdXB5wXXQ32jwgMf/GB6vdsPVeKyZ5Zj+fbDOHKsDt/uLPG7709nrTK8PZc+sxzbiyqwvSi4bDFGrEoaDsQuafZEZAKAfwBwAXhJKfV4W/sPHz5crVpl/AvLLI1NCj9/bTU+3WxcD3prux+/2LS6SB850+abXufNZ+egtqEJU8f2QUKMC12T40xvA5FdHTlWh6EGrKpI1BEf/2oM+mUm4Y431qDkWB2G9eqMc/tm4NoXzJ1IO/6UTDx17WAs2VyEgpIq/HRMHxwsq0FuRgJKjtVh84FynNw1EZc+vRyHK+uQlRqPwlaTRK2KXURktVJquG7Hs0OALiIuANsAXABgH4DvAFyvlNrk7zFOCNCVUmhoUvhu1xHM+mY3Fhk4vMWXH5/ZE+f364qtRRW4YkgWLntmOWZePwRn56YDAOoamhDj5kWYcFBRU4/TZnxidTMAAD8Z2RM/H5uLkmN1OFhWjb8s2oqP7h6NjfvLkZYQgz4ZiVY3kSgsrC44asnkUCInY4BuIhE5C8AMpdRF2v3fA4BS6s/+HmNFgL6tqAJLNh/CK1/tQowrCreMykGsOwpVdY3488Itx/e7YEAmBnRLRkHJMRSV16KytgGx7iic178r3v++EN1S4vDldqayay09MRaHK2sxtGcqBmaloGtSLLYfqkRFTQM2FJbh6mHZKKmsQ2FpNZbnH8a1w3uge2o84qKjsKO4EqsLjiIzOQ690jrh863FmDwkC01NCnuPVqGksg5dEmJQXlOPr/JLMDg7BQOzUhAf7cJLy3dhTF46hvRIRV2jQkp8NPYcOYaqukZsOeC5JLfV69LcgG7JGJOXjuKKWhyqqG0zLWFmciyqahtRUduAW0f1xuqCI1i3rwz3ju+LbUUVmK+tcDf+lEzU1Ddi3d5SDMxKwTc7SxDrjkLfzCR0S4nDJ5vM/fEWDob2TEXfzCS85TUWfkxeOnaXHEN1XRNO6ZaE3IxEvLtmHypqGpDXNRHbD1XipOQ49EzrhAHdkrHwhwPolZaAlbuOoHd6Ag5X1KKitgG/OCcXtQ2NcEcJqusb8eX2wygo8YwTvfi0bthRXIluKXE4uWsiXvzyxInbMe4oxLqjMGlgN+QXV2LLgXKc2ScN3VPj8PqKPYh1R+HnY/tg5me+F4xpfq23pf9JSX6XtU6KdR8fDjcwKxmjctPxrwCW6u6dnoDz+3dFWXU9TkqOw8HyGpRU1kJE8MW2YjT4SEEx/pRMfLuzBGf2SUOT8rw/CkurUdfQhLV7S/3W1Sc9AT3TOmHZ1hOHSQ3KTsF6A8aluqPk+HMY1qszhvXqjBd0XsL8zN5dcOGpJyHWHYXXVxS0+D+6dHB3fLhuv671EVFLDNBNJCJXAZiglPqpdv9GAGcqpe5qtd9UAFMBoGfPnsMKCgpMbefctYX45VtrTa2TiIwTH+1CtQnj+omISB9OCdAdlWZRKfUCgBcATw+62fVfdOpJ2PSnixAf7UJtQxPqGptQ19CE2oYmpCXEIP9QJU7plowoAYora5EQ48b+0mpEu6KQnhQLAOgU7cLWogocqqjFtoMVaFKqRe97OMhMjkVReS0G90jF1oPluPv8PDy5aCv6pCfgL1cNwtq9pVi/rww3ntULR4/Vob5RYfOBcjyzNB99MhLw6s0jUFFbj6/yD+PKodlYsvkQot2C4opaXDu8J77acRhn9u4Cd1QUNh4ow4icLth8oALxMVHYc6QKIoJRuelQUIh1u1BWXY/EWDdqGxqxv7QasW4XmpRCQqwbdQ1NqG9sQly0C3HRLsS4olBeU4/UTtGIcUWhtKoeDU0KCbEuHCqvRVKcG1Einr8ozySeTjEuHKttQHJ8NBoaFZqUp0wpoLC0GhlJsSivrse+0mr0zUyCSwRx0VHIP1SJNK0ntKFRITnejYZGhRh3FLomxWLLwQr0TOuE8up6dE+Jx/4yz7EAz8IQpcfqkZkSi71HquGOEsRGRyE1PgZRUcCh8lqkJcZgZ/ExdE2ORXFFLS6eaV6qrlB1S4nD4cpapCXEor6xCSXH6pCbkYDz+nVFdud49M1MwvwNB3Dz2Tn4ZFMRxuZlIDHOjcqaBqR2ikZtQyMyk+NQXdeIxDg3DlfUwe0SZCTFYn9pNQSCrM7xiBLgaFU9yqrrkZYYg7qGJigF1DV63pOrC47ijJwuKK2uQ3JcNLYerEBu10RU1TYgPTEWUVGCpiaFwtJqiABx0S7EuqNQUdOAmvpGZHWOh1LA4k1F6J2eAADISIpFl4QY7D58DF2T4xAlQHlNA9ISYlBcUYvOCTGIdgkOV9YhPtqFh+ZtxAUDMtE7LQGZKbGIdbvQ2KRQVl0PgSdn86ndk1Hb0HQ8NVtJZS3SE2OPDzOrbWjCkWO1SI6LRpMCkuLcKCqvQbQrCgfLa9A3Mwmx7igUV9RCKeCklDiUVdcjIdaF0qp6pMRHo7S6Hkp5Xp9NTUDnBM975FBFLTrFuFBcUYuD5TU4XFmHkb27ICpK0CnG855S8FxBzM1IPL5SZN/MJFTVNaC6vhFNCkhLiEFVXSP2HKlCbkYCVuw8grF90+GOisKGwjJU1zXilldXYvUDF2DX4WNIjHXj823FqKlvRHJ8NKrqGjF3bSH+ffMZePXr3fjluDzsPep5b+w7Wo1/LsvHDWf2RM8uCYiLjkKMOwrvrynEDSN7HT9fmw+UY0D3ZNQ1es5lrNuF7UUVOFxZh4ykGMTHuJGeGIP31hRi0mndUN/YhOKKWvTLTMK+o9WIi46CK0rQKcaNo1V1cEUJmpSCK0qwYucRnJOXgdhoz/9HbUMjauubkBTnxtGqepRr5zsjKQ4vf7kTI3qn4Scvf2vZe5CIwptdetBtMcTFKDX1jZi3bj9++856U+v9bvr44wFjs4bGJrhdHHcejvYeqbJ8ueP1My5Ecly0pW0gspMZ8zbi1a93W90MItx8dg6q6hpweo/OOKdfBmrrG3H+3wJPyaiXhb8cAwD4fk8p7n9/Ax68ZABuHd0bc1btxYNzf2g3d7pTetDtEqC74ZkkOg5AITyTRH+slNro7zFOCtCbmZWhY8OMCxHrdnECqA2ZncWlX2YSPrpnNFbuOgKlgNF56abWT+QUVmRgIuv9/drBuPdtc1YR9aW9YPbSp5djQ6F5ecrn3jkKg3uktrtfc+wqIvjnsnz85eP/pSp1SoBuiwhMKdUA4C4AiwBsBjCnreDcqe4Zl2dKPUlx0QzObWpkny6m1rfo3rGIdkVh1MnpDM6JQnD7ublWNyGi9Ohi3YrZ14/oCcDTY33FkGwM69UZ8dEu0+r//cT+AICHJ5/a7r4f3DnK6OZgya/PQVKcZ8R1IME54AnMRVtCdFBWYI+xG9tEYUqpBUqpvkqpXKXUo1a3xwr3XdAX795+ttXNoDD28pQzrG4CEQXBigD9rakjcXZumun1Wu3Nn52JRb8aa1n9D106AMt/dx5mXOYJkN+9/WxsfniCafVPHdsHH9w5CjeeldPuvq4oQXKcsdMVczMS8e3947DqgfFBPX50Xjo+unu0zq2ynqMmiUaCKDHmuP0yk3Db6N6IjbbNbzbyISHWjb6ZidhWVGlYHf+6cRjOzk1DfWP4D48jsgsr5m6M7JOGYb06I2/6QtPrtlLzWh73T+qPxxaYn4Qh1h2F7M6dTK+3mYjg9AB7qgFgwS/HYPQTxsxvWvvgBQCATjFudIoJPiQ9tXuyXk0KGwzQbWZwdioGZ6dgnY45gnf9eRIAHL9cRNSWi049yeomEDlS95Q47C+rMbXOaIsm/V8zPBtzVu0zvd5fnPO/KxVTx+bilplS5dcAABwjSURBVFG9Tf+BYrfvWiN/TKR2itHlOHY7p4Fgd6nNREUJ5t6l76Uc77FcZH/3XdDX6iYQURAi5XN4YFZy2MxzsuoHCgF/CmAMfCTjK5PIYS4YcBLGcMImke0M6WnOZLeP7h6Nl6f8L9mEWRMmo12Cd28/C6/fdqYp9fni9jFOdMpZvUyr/0dDs0yry5f0RH16rPVwUwBj4CMZA3Sbuvi0blY3gcKUK0rwmgFfgJNOOwmPXjFQ9+MSkcdfrx5sSj0Ds1Iw7pTM4/cF5vTcf/brczGsVxekdorBraN6m1In4FkkCwB+Orq3z8m4D11qTk/uz8f2wVPXnO53++TTuxtW93M3DMXfrh6MeTpfgW9Laif/8yrWPXih7vWN7NPFtPeQGRig29SzNwzV5Tgf/2qMLseh8PPu7WfperxnfzwUN5xpXk8TUaSJMzHVnrfHrjjNlHqyO/+vp75PRmLQWTs66rPfnIuvpp2PBy4ZgITYE6femTGyaNefJ+H3k05pc5+7zzculfKEgSfhymHZ6J4a3NWSYP6vhvRIxY/P7OlzW0obwXuw3pp6Fq4alq37ca3CAD2CTT69O/qf5LyZz+QxrJe+OdEjZXwsUaQxaw2D1p8h6YmxfvbUV0p8NLLaCEzN+GwLpI4YA8fDh/ocg/m/inFH4dJBxl0VcDoG6Db2zi9C6yHtlZagU0uIiMgOdj42yeomhKU5P9f3imMweqaFni1l9QPjwyYn+GWDs3BWbhq2mJjj3UkYoNtYZnJcSI+/5/yTdWoJERHZQZRRi2m044GLfQ/vCJfF90b0NncVZn/WzwhtbHZinBsDs1J0ak1oLh7kmSvXeujWyV0TrWiO7TBAt7FOMaGNV3QzvRQRUVj59L5zrG6CIX46po/P8mG9OpvckvCWHBcd0jlxGThcR69sP29PHanLcZyOEZqNpYUwfm/pb87VryFERKQLp/Qu9krrhMX3jg1oXyMn9o33ylZjF3N+fhY2/emioB5r5Hj6D+4Ydfz2X64cBAAYkeP7ykPrK/RXDnXO5E2zMECPUElxXESWiCgcPXjJAEOOe9to/6kNn7xqEC4YkKlbmrozcrogLzMJ913QF2fnprW5b7ikxnvppuFYZkDn1Zs/7VjaW1eUoFOMG09d0/HzYuQIJu9OwWvO6IGV94/D7NtG+Nz3mjN6tLgf7WKSgY5igB6h+FYhIgpPNxm0cM4f2gj8rx7eAy/eNBxntRNMB0opz7/3jMvDmz+zx5CG8QMykZMeevKEr6ad3+L+wOzgxoQHkxLRVw/67yb0D6p+X6ZN7A+X9iuga3Kc39Sg2Z1bTnj1HrbDjGCBYYBO5GAr7x9ndROIqIOcMD9IQVlSb0KMC4O8AmIrYsG2Ujp2xJk6TVz1tThTsH5xTi52BJEJyEn5yc1i/08BCgp/wUaGriFm+mk21KQlyInIozkDhl0N13kdhkBNm9gff/MaMhPMN12oCRgA4EOvFTvdQY470eN7+rvp5iwG1R7v58LoIzAM0G3uJyN9r9JFpCe7XKImcgo79zimJ8bg+hE92t/RAJNO64a8zCQ8/5NhQR+jSYXe+39adgrWPXgh/vOzkegUY92cr4wkcxaD8ta7nWFCqQasIupEDNAjFH/BRo6+maFnhbBqCXKiSHVev666Hm9cf32P15Y+6Ykd7v3VK3tN80TGPhmeIHFMEKukNuk0OielU3TIY/onnHqSPo0xUHNH4Qd3jsKPhmRh0a/azt7DK/iBYSqPCMX3R+SYf88Y5E1faHUziMgiux+/OOB99fhqmO5nUaK2fPzLMWhSQN8H9Pms6puZhFUPjEdaQkyHH9ukV4RuoaevH4KGpiZT6np48kDMuPRUuF1ROP3a0/3u9+7tZ+n24ycSsAc9ArzmJw0SRYZoB0w4IyL76BXEkvVuVxRi3Pp+VqUnxgbVWzuge7Ku7bDCpYO744oh5gyTEpGAJjYP69UFZ/jJm04n4je3Q33x/84DADxx5WkYk5eBIa0m+QkHuRAREZ1g9q3Bd2plJps/5rvZdWdYM+6fjMEhLg7VM61Ti8ua4/p3xfd7Si1sERERhTs9hj/avQMotVPHh8U0+79rh+jYko5NqOTQVWdhD7rNBf1ByDcyEREZICWCs3TE65Ci0dsDHVhV9lydJxaTtRig21yg6VU5a5qIyF7SE4PvySVr6P1Nmxgb+ECHi2yQ8YUCxwDd5lLig+upYLweWSadxg9uIrtJS7BuPDMFJymOI4dJHwzQbe7O808O6nGMzyPLHecG9zohInt7ecpwq5sQUfpk6JPP3ZeOpMsk+2OAbnOxbi4gQ0REvo07JdPqJhBREBigR4jTslJa3OeY9MiS087Sy0TkPC/cGPxy91Z57oahVjeBKCyEFKCLyNUislFEmkRkeKttvxeRfBHZKiIXeZVP0MryRWSaV3lvEflWK39bRGK08ljtfr62PSeUNkeqsX0zWtzvyMQTsj/+fxPZT6j9KG6X/TpiJgzkfJnW0hNjccEAXgmJNKH2oP8A4EcAvvAuFJEBAK4DcCqACQD+KSIuEXEBeBbARAADAFyv7QsATwD4u1LqZABHAdymld8G4KhW/ndtPyIiItKZK9DUYAbh1d0TrXpgPF68iXMJIk1IAbpSarNSaquPTZMBvKWUqlVK7QKQD2CE9pevlNqplKoD8BaAyeJ5R54P4B3t8bMAXO51rFna7XcAjBO+g4mIiNoUzLLqXZPiQqrzssHdQ3p8uHj1ljPQK62T1c2gCGbUGPQsAHu97u/TyvyVpwEoVUo1tCpvcSxte5m2PxEREfnw1DWDkRQXXBreUIZTxLqdMbXt3H5dcfFp3axuRsAeuXyg1U0gnbU7MFVEPgXga1DYdKXUXP2bFDwRmQpgKgD07NnT4tYQERGRXSmrG9ABPxnZy+omkM7a/amrlBqvlBro46+t4LwQQA+v+9lamb/yEgCpIuJuVd7iWNr2FG1/X219QSk1XCk1PCMjw9cuEW3unaMAAHecm2txS4iIyEh9M5MsqZcDUM2368+TrG4CGcCoa1HzAFynZWDpDSAPwEoA3wHI0zK2xMAzkXSeUkoBWArgKu3xUwDM9TrWFO32VQA+0/anDhrcIxW7H78Yv53Q3+qmkAWyUuM7tP/wXp2REOPC3UEuhkVE1hnYKrVuR4QSY+vx7RzjsucwmXH9u1pSL6flOVNIuddE5AoATwPIADBfRNYqpS5SSm0UkTkANgFoAHCnUqpRe8xdABYBcAF4RSm1UTvc7wC8JSKPAPgewMta+csAXhORfABH4AnqiaiDsjvHo7C0OqB9fzQ0C09dc7rBLSIiOtH1I3pg1jcFVjejw6ZNZOcX6SekAF0p9T6A9/1sexTAoz7KFwBY4KN8JzxZXlqX1wC4OpR2EhERkbM9dc1gXY8X6NWAWbeOwKKNB5Gbkahr/RTZ7HkdiVrITI61ugnkMBLSRW4iIvN1irFmQbYzcjrjsStOQ5QJOeR3PNZyvPm/bznD8DrJGgzQHeDDu0bjF+dw4ie1rSPDFDmkkYginQowj4uZPwxaLyR1Xj9rxr2T8RigO0DX5DiM7NPxBSmIiIhas8MP9HDplPqdhUkXrKybjMcA3SE4i5v0dHYu1wIjilQPTw580ZuNf7xI9/pjAljs6NZROTBhREmbtjw8AbdbkLZ4RG92yEUCBuhEdIIrhmS1vxMRGSo5PriVQEPVNTku4H0TYvUf3vHL8X0D2i8nPUH3ur1NHOh/JdF5d41CXLTL0Pr9GdIz1ZJ6yVwM0B1icHbwOW8pMpydm251E4ioA5758RCrm2CJxACD/iuHZre4r/eF5NN7+A+EB2VbFyTfNro3zuqThmvP6NH+zmRbDNAdIrVTDE7qQK8HRR4rLsUSUfC6JtnvM93MVQSvHpbd/k4O1DUpDv+ZOhJdEmKsbgoZiAG6g9w2urfVTaAwFsV5CkRkgMmndze9zi4JMZYNASIyAwN0IjoBJx0TUaCG55g3afHd28/Ch3eNhtsVhbhoFxbcM+b4Nn5qkZNYk9WfiEzHLy8i+4l1R6G2ocnqZvjUPcUzBCc3w9jJmt6G9Wr5Y2BA92TT6iYyE3vQiYiIwtSLNw23ugl+NV9p856AHm9BZpMnrxoEADilG4N1cg72oDvQmDxm6yAicgK7jbP+3UTzF8+5engPXD2cGU3IWRigO1C/zCSrm0BhiMPKiUhPD1064Pjtz359DlLiowNOkUhEbeM7yUEytfGAWZ3jLW4JERE53cldE4/f7pOR2MaeRNRRDNAd5NJB3ZAU68Y5fTOsbgoRETlcpGZ7WvXAeKubQBGAAbqDiAjO69/V6mYQEZFOIjME9u2+C/pa3QQAQHpirNVNoAjALC5EESJSe7uISH/n9M1AD5OHU8a6GbJQ5OCrnYiIKEwpi+p9qZ30jrNuHQG3y9wQ4uZROabWBwB3n3+y6XUSAQzQiYiIHGWcDkMdxw/I1KEl+op1m59jPTnOXmkuyTkYoBMRETnIRQNPMvT4/U9iKl8iozFAJyIicpBol7HzTS4Z1M3Q4xMRA3QiIqKw1dFQ+55xebh0UHdD2tLsF+fkGnr8cDKJP0bIIkyzSERE5BBGpyKccOpJpk8OtVJWKhf+I2tEzruMiIiIQvK7if1NqeevVw82pZ6Oev4nw6xuAkUIBuhEEWTJr89Btp/cxUmxvKBGFG6sSrPoT7eUOFPquWpYtin1dNQEgyfgEjVjgE4UQXIzErH8d+f73HZWbhoAoFdaJzObREQ2EhdtfqpDokjEAJ2IAADNC43mpCVY2xAiIqIIxwCdiAD8b0GOLJOX7yYi/4xNmNi2G0f2srB2osgWUoAuIk+KyBYRWS8i74tIqte234tIvohsFZGLvMonaGX5IjLNq7y3iHyrlb8tIjFaeax2P1/bnhNKm4kIGNar8wll15zRA8//ZCgevGSABS0iolB1TYo19Pi/udDYDDFt6dHFuo6D3um8qkjmC7UHfTGAgUqpQQC2Afg9AIjIAADXATgVwAQA/xQRl4i4ADwLYCKAAQCu1/YFgCcA/F0pdTKAowBu08pvA3BUK/+7th8R6ejL356HM3K6YMLAbhxjSmRTYnB3+8CsFGMraMPie8+xrO73bj/bsropcoUUoCulPlFKNWh3VwBonnY9GcBbSqlapdQuAPkARmh/+UqpnUqpOgBvAZgsIgLgfADvaI+fBeByr2PN0m6/A2Cctj8RBSmhVcaWHl04MZSIwpeVHQedE2Isq5sil55j0G8FsFC7nQVgr9e2fVqZv/I0AKVewX5zeYtjadvLtP1PICJTRWSViKwqLi4O+QkROdWjlw+0uglEFIDmNIuDstvvveYEb+Pcdd7JePr6IVY3gyJIu4mPReRTAL4Sf05XSs3V9pkOoAHAG/o2r2OUUi8AeAEAhg8fHm7pY4nCRmqnaKubQEQ6+wPnjxjmNxf1s7oJFGHaDdCVUuPb2i4iNwO4BMA4pVRzUFwIoIfXbtlaGfyUlwBIFRG31kvuvX/zsfaJiBtAirY/EQWJv16J7KEj4zlj3cYmZuPoUiLzhJrFZQKA3wK4TClV5bVpHoDrtAwsvQHkAVgJ4DsAeVrGlhh4JpLO0wL7pQCu0h4/BcBcr2NN0W5fBeAzrx8CREREZAKzv3rn/PwsU+sjCieh/tx+BkASgMUislZEngcApdRGAHMAbALwMYA7lVKNWu/4XQAWAdgMYI62LwD8DsB9IpIPzxjzl7XylwGkaeX3ATiempGIgsN+MCIKdyN6d2EudopY7Q5xaYuW+tDftkcBPOqjfAGABT7Kd8KT5aV1eQ2Aq0NpJxEREXWMK6rlT3krhrg8fPlAPMxJ7RSBuJIoERERneDeC6xbmIgo0jFAJ4pAnMRBZA+5XRMR447CvePbD5b17uBOiW+Z7SmKY+OITBPSEBciIiIyTmKsG9semWh1MwAAZ+emW90EoojBHnQiIiIb+uTesXhr6kjkZpizQFHrMelEZBz2oBNFIO+vWaY2JrKnvplJAIBz+nbFjuJdSInnkvRETsEAnSgCeY9B76d9yRORPd0/qT9uG9MbGUmxVjeFiHTCIS5EREQ25nZFISs13tA6zs5NM/T4RNQSA3SiCJfaKbr9nYgool0zvIfVTSCKKAzQiSLcMz8eanUTiIiIyAsDdKIIl57IcatE1DYOcSEyFwN0oggU6+Zbn4gC1zU5zuomEEUUfksTRaBYt8vqJhCRDYw/pStiXAwViMzGNItEEWr2rSNwrLbB6mYQURh7acoZVjeBKCIxQCeKUGP7ZljdBCIiIvKB162IiIiIiMIIe9CJiIhsICs1HoWl1bj93FxcfFo3q5tDRAZigE5ERGQDSikAwA1n9kR2504Wt4aIjMQhLkREREREYYQBOhERkQ2IiNVNICKTMEAnIiIiIgojDNCJiIiIiMIIA3QiIiIiojDCAJ2IiMgG4qI9X9kci07kfEyzSEREZAOv3jICc9cWontKnNVNISKDMUAnIiKygR5dOuGu8/OsbgYRmYBDXIiIiIiIwggDdCIiIiKiMBJSgC4iD4vIehFZKyKfiEh3rVxEZKaI5Gvbh3o9ZoqIbNf+pniVDxORDdpjZoo2C0ZEuojIYm3/xSLSOZQ2ExERERGFs1B70J9USg1SSp0O4CMAD2rlEwHkaX9TATwHeIJtAA8BOBPACAAPeQXczwH4mdfjJmjl0wAsUUrlAVii3SciIiIicqSQAnSlVLnX3QQASrs9GcBs5bECQKqIdANwEYDFSqkjSqmjABYDmKBtS1ZKrVBKKQCzAVzudaxZ2u1ZXuVERERERI4TchYXEXkUwE0AygCcpxVnAdjrtds+rayt8n0+ygEgUyl1QLt9EEBmG22ZCk+PPXr27BnEsyEiIiIisla7Pegi8qmI/ODjbzIAKKWmK6V6AHgDwF1GNlbrXVdtbH9BKTVcKTU8IyPDyKYQERERERmi3R50pdT4AI/1BoAF8IwxLwTQw2tbtlZWCODcVuXLtPJsH/sDQJGIdFNKHdCGwhwKsD1ERERERLYT0hAXEclTSm3X7k4GsEW7PQ/AXSLyFjwTQsu0AHsRgMe8JoZeCOD3SqkjIlIuIiMBfAvPkJmnvY41BcDj2r9zA2nb6tWrD4tIQSjPL0jpAA5bUK9T8PwFj+cueDx3weO5Cw3PX/B47oLHcxc8f+eul56ViGfUSJAPFnkXQD8ATQAKAPxCKVWopUh8Bp5MLFUAblFKrdIecyuA+7VDPKqU+rdWPhzAqwDiASwEcLdSSolIGoA5AHpqdVyjlDoSdKMNJiKrlFLDrW6HXfH8BY/nLng8d8HjuQsNz1/weO6Cx3MXPLPOXUg96EqpK/2UKwB3+tn2CoBXfJSvAjDQR3kJgHGhtJOIiIiIyC64kigRERERURhhgK6/F6xugM3x/AWP5y54PHfB47kLDc9f8HjugsdzFzxTzl1IY9CJiIiIiEhf7EEnIiIiIgojDNCJiIiIiMIIA3QdicgEEdkqIvkiMs3q9lhFRHqIyFIR2SQiG0Xkl1r5DBEpFJG12t8kr8f8XjtvW0XkIq9yn+dURHqLyLda+dsiEmPuszSOiOwWkQ3aOWpOT9pFRBaLyHbt385auYjITO08rBeRoV7HmaLtv11EpniVD9OOn689Vsx/lvoTkX5er6212toKv+Lrzj8ReUVEDonID15lhr/W/NVhJ37O3ZMiskU7P++LSKpWniMi1V6vwee9HtOhc9TW/4Nd+Dl3hr9PRSRWu5+vbc8x5xnrx8+5e9vrvO0WkbVaOV93XsR/bBKen3lKKf7p8AfABWAHgD4AYgCsAzDA6nZZdC66ARiq3U4CsA3AAAAzAPzGx/4DtPMVC6C3dh5dbZ1TeHLjX6fdfh7A7VY/bx3P324A6a3K/gJgmnZ7GoAntNuT4Fk3QACMBPCtVt4FwE7t387a7c7atpXavqI9dqLVz9mAc+gCcBCehSP4uvN/nsYCGArgBzNfa/7qsNOfn3N3IQC3dvsJr3OX471fq+N06Bz5+3+w05+fc2f4+xTAHQCe125fB+Btq8+FHueu1fa/AXiQrzufz9lfbBKWn3nsQdfPCAD5SqmdSqk6AG/Bs7pqxFFKHVBKrdFuVwDYDCCrjYdMBvCWUqpWKbULQD4859PnOdV+kZ4P4B3t8bMAXG7Mswkbk+F5nkDL5zsZwGzlsQJAqoh0A3ARgMVKqSNKqaMAFgOYoG1LVkqtUJ5Pitlw5rkbB2CHUqqt1YQj/nWnlPoCQOuF38x4rfmrwzZ8nTul1CdKqQbt7goA2W0dI8hz5O//wTb8vO780fN96n1O3wEwrrmH0y7aOnfac7kGwH/aOkYEv+78xSZh+ZnHAF0/WQD2et3fh7aD0oigXUIcAuBbregu7VLRK16XePydO3/laQBKvb4InXauFYBPRGS1iEzVyjKVUge02wcBZGq3O3rusrTbrcud5jq0/JLi6y5wZrzW/NXhJLfC04PWrLeIfC8in4vIGK0smHPk5O8ao9+nxx+jbS/T9neKMQCKlFLbvcr4uvOhVWwSlp95DNDJMCKSCOBdAL9SSpUDeA5ALoDTARyA51IcnWi0UmoogIkA7hSRsd4btV/mzI/qhzbe9DIA/9WK+LoLkhmvNSe+nkVkOoAGAG9oRQcA9FRKDQFwH4A3RSQ50OM58Rz5wPdp6K5Hy44Jvu588BGbHBdOn3kM0PVTCKCH1/1srSwiiUg0PG+AN5RS7wGAUqpIKdWolGoC8CI8lygB/+fOX3kJPJea3K3KHUEpVaj9ewjA+/Ccp6Lmy4nav4e03Tt67grR8rK7o86dZiKANUqpIoCvuyCY8VrzV4fticjNAC4BcIP2RQxteEaJdns1PGOn+yK4c+TI7xqT3qfHH6NtT9H2tz3t+fwIwNvNZXzdnchXbIIw/cxjgK6f7wDkiWf2eAw8l9jnWdwmS2jj4F4GsFkp9ZRXufd4tSsANM9CnwfgOvHMsO8NIA+eiRY+z6n2pbcUwFXa46cAmGvkczKLiCSISFLzbXgmnf0Azzlqninu/XznAbhJm20+EkCZdhltEYALRaSzdqn4QgCLtG3lIjJS+3+6CQ45d15a9CLxdddhZrzW/NVhayIyAcBvAVymlKryKs8QEZd2uw88r7WdQZ4jf/8PtmbS+9T7nF4F4LPmH1EOMB7AFqXU8SEWfN215C82Qbh+5qkwmFnrlD94Zvxug+dX6nSr22PheRgNz+Wb9QDWan+TALwGYINWPg9AN6/HTNfO21Z4ZRXxd07hmbm/Ep4JQ/8FEGv189bp3PWBJxvBOgAbm58zPOMklwDYDuBTAF20cgHwrHZ+NgAY7nWsW7Xzkw/gFq/y4fB8+e0A8Ay0FYWd8AcgAZ4esRSvMr7u/J+v/8BzGbwenvGSt5nxWvNXh53+/Jy7fHjGpjZ/7jVnDLlSez+vBbAGwKXBnqO2/h/s8ufn3Bn+PgUQp93P17b3sfpc6HHutPJXAfyi1b583bU8H/5ik7D8zGt+IBERERERhQEOcSEiIiIiCiMM0ImIiIiIwggDdCIiIiKiMMIAnYiIiIgojDBAJyIiIiIKIwzQiYiIiIjCCAN0IiIiIqIw8v8B2KzHtmzuBv4AAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.plot(wave_audio)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDT-6R3aZA7E",
        "outputId": "bc4fc5f8-d1a7-4ead-d7da-b4d273cfcd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40, 173)\n"
          ]
        }
      ],
      "source": [
        "mfccs = librosa.feature.mfcc(y=librosa_audio_data, sr=librosa_sample_rate, n_mfcc=40)\n",
        "print(mfccs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHVSGncwZKWo",
        "outputId": "9b7bffc4-179b-42af-ce8c-eca4c859f574"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-5.21320618e+02, -5.19244873e+02, -5.18639771e+02, ...,\n",
              "        -4.35682465e+02, -3.92686127e+02, -3.53734650e+02],\n",
              "       [ 1.43376465e+01,  1.71779118e+01,  1.81039009e+01, ...,\n",
              "         1.13759216e+02,  1.51305222e+02,  1.78508270e+02],\n",
              "       [ 1.35261917e+01,  1.61207390e+01,  1.72592888e+01, ...,\n",
              "         6.42746277e+01,  6.28374176e+01,  5.72559586e+01],\n",
              "       ...,\n",
              "       [ 3.53906393e-01, -3.32358456e+00, -4.83565140e+00, ...,\n",
              "        -5.26991272e+00, -1.14964163e+00, -2.76052785e+00],\n",
              "       [ 4.51929927e-01, -3.06704044e+00, -4.64729738e+00, ...,\n",
              "        -3.42241073e+00,  2.55063629e+00,  2.86859894e+00],\n",
              "       [ 4.35776591e-01, -2.79775834e+00, -4.41259766e+00, ...,\n",
              "        -2.67133570e+00,  1.37135601e+00, -4.06251371e-01]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "mfccs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "BzoshlTZZlSB",
        "outputId": "5b1e544e-d841-4d1b-eabc-4cc1d3d93374"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      slice_file_name    fsID  start        end  salience  fold  classID  \\\n",
              "0    100032-3-0-0.wav  100032    0.0   0.317551         1     5        3   \n",
              "1  100263-2-0-117.wav  100263   58.5  62.500000         1     5        2   \n",
              "2  100263-2-0-121.wav  100263   60.5  64.500000         1     5        2   \n",
              "3  100263-2-0-126.wav  100263   63.0  67.000000         1     5        2   \n",
              "4  100263-2-0-137.wav  100263   68.5  72.500000         1     5        2   \n",
              "\n",
              "              class  \n",
              "0          dog_bark  \n",
              "1  children_playing  \n",
              "2  children_playing  \n",
              "3  children_playing  \n",
              "4  children_playing  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e85a02c1-0b92-4be6-8131-e20156a46022\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>slice_file_name</th>\n",
              "      <th>fsID</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>salience</th>\n",
              "      <th>fold</th>\n",
              "      <th>classID</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100032-3-0-0.wav</td>\n",
              "      <td>100032</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.317551</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>3</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100263-2-0-117.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>58.5</td>\n",
              "      <td>62.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100263-2-0-121.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>60.5</td>\n",
              "      <td>64.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100263-2-0-126.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>63.0</td>\n",
              "      <td>67.000000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100263-2-0-137.wav</td>\n",
              "      <td>100263</td>\n",
              "      <td>68.5</td>\n",
              "      <td>72.500000</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e85a02c1-0b92-4be6-8131-e20156a46022')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e85a02c1-0b92-4be6-8131-e20156a46022 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e85a02c1-0b92-4be6-8131-e20156a46022');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "audio_dataset_path ='UrbanSound8K/audio/'\n",
        "metadata=pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')\n",
        "metadata.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "71xIIr8TZLXl"
      },
      "outputs": [],
      "source": [
        "def features_extractor(file):\n",
        "    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n",
        "    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
        "    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n",
        "    \n",
        "    return mfccs_scaled_features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU_2KftPg0vU"
      },
      "source": [
        "## Feature Extraction\n",
        "\n",
        "* We divides the data by extracting the characteristics of the frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBsvsPqWZOXd",
        "outputId": "371cb718-da95-49ba-932b-69561efa81f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "3555it [05:19, 10.87it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
            "  n_fft, y.shape[-1]\n",
            "8325it [12:12, 16.73it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1103\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1523\n",
            "  n_fft, y.shape[-1]\n",
            "8732it [12:46, 11.40it/s]\n"
          ]
        }
      ],
      "source": [
        "### Now we iterate through every audio file and extract features \n",
        "### using Mel-Frequency Cepstral Coefficients\n",
        "extracted_features=[]\n",
        "for index_num,row in tqdm(metadata.iterrows()):\n",
        "    file_name = os.path.join(os.path.abspath(audio_dataset_path),'fold'+str(row[\"fold\"])+'/',str(row[\"slice_file_name\"]))\n",
        "    final_class_labels=row[\"class\"]\n",
        "    data=features_extractor(file_name)\n",
        "    extracted_features.append([data,final_class_labels])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-RhK3iqAhIMU"
      },
      "source": [
        "## Our Final DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l_E0l6AxZQiR",
        "outputId": "a3aaef46-628e-451a-b9e1-5b3b5a828021"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             feature             class\n",
              "0  [-214.95764, 70.502464, -130.70279, -53.116936...          dog_bark\n",
              "1  [-423.7311, 109.2299, -52.872597, 60.827538, 0...  children_playing\n",
              "2  [-458.52844, 121.35432, -46.535675, 51.969467,...  children_playing\n",
              "3  [-413.63254, 101.61351, -35.43868, 53.047146, ...  children_playing\n",
              "4  [-446.38693, 113.68634, -52.4572, 60.349724, 2...  children_playing"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5cef160-32d8-406a-a38b-158b977d4580\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[-214.95764, 70.502464, -130.70279, -53.116936...</td>\n",
              "      <td>dog_bark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-423.7311, 109.2299, -52.872597, 60.827538, 0...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[-458.52844, 121.35432, -46.535675, 51.969467,...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-413.63254, 101.61351, -35.43868, 53.047146, ...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[-446.38693, 113.68634, -52.4572, 60.349724, 2...</td>\n",
              "      <td>children_playing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5cef160-32d8-406a-a38b-158b977d4580')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f5cef160-32d8-406a-a38b-158b977d4580 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f5cef160-32d8-406a-a38b-158b977d4580');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','class'])\n",
        "extracted_features_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "lRfU34pzZzO4"
      },
      "outputs": [],
      "source": [
        "# Our features and label.\n",
        "X=np.array(extracted_features_df['feature'].tolist())\n",
        "y=np.array(extracted_features_df['class'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZP5kXMkZ0YJ",
        "outputId": "c87e0c6a-fb3b-4716-a85d-6475e3c70e1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8732, 40)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "AqpC9deYZ2GF"
      },
      "outputs": [],
      "source": [
        "# Label Encoding\n",
        "y=np.array(pd.get_dummies(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNvw1sNXZ3kB",
        "outputId": "2fa76a00-f837-46fe-c6a7-3237f2a66c19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8732, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "FXEUujKyZ5Z3"
      },
      "outputs": [],
      "source": [
        "### Train/Test/Val Split\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=0)\n",
        "X_test , X_val , y_test , y_val = train_test_split(X_test,y_test , test_size = 0.5 , random_state =0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MCE-4IzAZ5t_",
        "outputId": "9d4dcc34-61b2-484c-ffd1-c3b48a8c31a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train---------: [[-1.3082390e+02  1.1256225e+02 -2.2600878e+01 ...  3.2528090e+00\n",
            "  -1.3692100e+00  2.7386472e+00]\n",
            " [-1.3446434e+01  9.1048195e+01 -7.8661475e+00 ... -3.2665925e+00\n",
            "  -5.2884049e+00 -1.5532947e+00]\n",
            " [-4.9575279e+01  2.3543632e-01 -2.0504959e+01 ...  2.8775635e+00\n",
            "  -1.5828822e+00  3.5109408e+00]\n",
            " ...\n",
            " [-4.2677444e+02  9.2583252e+01  3.3174915e+00 ...  7.9330575e-01\n",
            "   7.1890563e-01  7.1397936e-01]\n",
            " [-1.4541722e+02  1.3619025e+02 -3.3450352e+01 ...  1.4591718e+00\n",
            "  -1.9928970e+00 -8.9318532e-01]\n",
            " [-4.2099823e+02  2.1074756e+02  3.5814040e+00 ... -5.4054899e+00\n",
            "  -3.3959770e+00 -1.5590971e+00]]\n",
            "y---------------: [[0 0 0 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " [0 0 1 ... 0 0 0]\n",
            " ...\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]]\n",
            "X_train.shape: (6985, 40)\n",
            "X_test.shape: (873, 40)\n",
            "X_val.shape: (874, 40)\n",
            "y_test.shape: (873, 10)\n"
          ]
        }
      ],
      "source": [
        "print(f\"X_train---------: {X_train}\")\n",
        "print(f\"y---------------: {y}\")\n",
        "print(f\"X_train.shape: {X_train.shape}\")\n",
        "print(f\"X_test.shape: {X_test.shape}\")\n",
        "print(f\"X_val.shape: {X_val.shape}\")\n",
        "print(f\"y_test.shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRQX9hsSaUVK"
      },
      "source": [
        "# Modelling Time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "izW2uklNaVAT"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "UtJ0i_mcaWoL"
      },
      "outputs": [],
      "source": [
        "# This will be our output layer dense\n",
        "num_labels=y.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "XBjD9FACaZHY"
      },
      "outputs": [],
      "source": [
        "model=Sequential()\n",
        "# First layer\n",
        "model.add(Dense(200,input_shape=(40,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Second layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Third layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Third layer\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "# Last layer\n",
        "model.add(Dense(num_labels))\n",
        "model.add(Activation('softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cATdT-pJaaej",
        "outputId": "30673176-3728-4d7d-828c-bd6431381646"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 200)               8200      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 200)               0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               102912    \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 10)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 641,554\n",
            "Trainable params: 641,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Qe3rwY-sabRy"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtmmwck7ahWh",
        "outputId": "5197395f-e96e-47da-8a1d-4beb8ea23817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 751/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5037 - accuracy: 0.8555\n",
            "Epoch 751: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.8547 - val_loss: 0.4190 - val_accuracy: 0.8844\n",
            "Epoch 752/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4879 - accuracy: 0.8633\n",
            "Epoch 752: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.8634 - val_loss: 0.4335 - val_accuracy: 0.8810\n",
            "Epoch 753/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5215 - accuracy: 0.8508\n",
            "Epoch 753: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5233 - accuracy: 0.8508 - val_loss: 0.4303 - val_accuracy: 0.8730\n",
            "Epoch 754/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5722 - accuracy: 0.8393\n",
            "Epoch 754: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5717 - accuracy: 0.8394 - val_loss: 0.4618 - val_accuracy: 0.8730\n",
            "Epoch 755/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4968 - accuracy: 0.8544\n",
            "Epoch 755: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4973 - accuracy: 0.8538 - val_loss: 0.4202 - val_accuracy: 0.8902\n",
            "Epoch 756/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4848 - accuracy: 0.8610\n",
            "Epoch 756: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4848 - accuracy: 0.8610 - val_loss: 0.4216 - val_accuracy: 0.8844\n",
            "Epoch 757/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5309 - accuracy: 0.8511\n",
            "Epoch 757: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5245 - accuracy: 0.8514 - val_loss: 0.4182 - val_accuracy: 0.8787\n",
            "Epoch 758/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5264 - accuracy: 0.8486\n",
            "Epoch 758: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.8494 - val_loss: 0.4493 - val_accuracy: 0.8822\n",
            "Epoch 759/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5381 - accuracy: 0.8521\n",
            "Epoch 759: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5364 - accuracy: 0.8534 - val_loss: 0.4721 - val_accuracy: 0.8684\n",
            "Epoch 760/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5214 - accuracy: 0.8577\n",
            "Epoch 760: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.8557 - val_loss: 0.4414 - val_accuracy: 0.8741\n",
            "Epoch 761/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5414 - accuracy: 0.8518\n",
            "Epoch 761: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5410 - accuracy: 0.8517 - val_loss: 0.4273 - val_accuracy: 0.8753\n",
            "Epoch 762/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5361 - accuracy: 0.8535\n",
            "Epoch 762: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5322 - accuracy: 0.8543 - val_loss: 0.4214 - val_accuracy: 0.8822\n",
            "Epoch 763/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5656 - accuracy: 0.8526\n",
            "Epoch 763: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5624 - accuracy: 0.8525 - val_loss: 0.4301 - val_accuracy: 0.8696\n",
            "Epoch 764/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5534 - accuracy: 0.8479\n",
            "Epoch 764: val_loss did not improve from 0.41651\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5535 - accuracy: 0.8490 - val_loss: 0.4220 - val_accuracy: 0.8799\n",
            "Epoch 765/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5004 - accuracy: 0.8513\n",
            "Epoch 765: val_loss improved from 0.41651 to 0.40117, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5054 - accuracy: 0.8515 - val_loss: 0.4012 - val_accuracy: 0.8867\n",
            "Epoch 766/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5111 - accuracy: 0.8516\n",
            "Epoch 766: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5127 - accuracy: 0.8520 - val_loss: 0.4361 - val_accuracy: 0.8719\n",
            "Epoch 767/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5146 - accuracy: 0.8510\n",
            "Epoch 767: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5151 - accuracy: 0.8511 - val_loss: 0.4154 - val_accuracy: 0.8776\n",
            "Epoch 768/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4971 - accuracy: 0.8553\n",
            "Epoch 768: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4954 - accuracy: 0.8550 - val_loss: 0.4135 - val_accuracy: 0.8764\n",
            "Epoch 769/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5050 - accuracy: 0.8576\n",
            "Epoch 769: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5014 - accuracy: 0.8587 - val_loss: 0.4161 - val_accuracy: 0.8844\n",
            "Epoch 770/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5324 - accuracy: 0.8544\n",
            "Epoch 770: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.8545 - val_loss: 0.4221 - val_accuracy: 0.8764\n",
            "Epoch 771/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5381 - accuracy: 0.8498\n",
            "Epoch 771: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5340 - accuracy: 0.8507 - val_loss: 0.4484 - val_accuracy: 0.8719\n",
            "Epoch 772/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5088 - accuracy: 0.8515\n",
            "Epoch 772: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.8515 - val_loss: 0.4270 - val_accuracy: 0.8844\n",
            "Epoch 773/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4971 - accuracy: 0.8556\n",
            "Epoch 773: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4939 - accuracy: 0.8561 - val_loss: 0.4071 - val_accuracy: 0.8810\n",
            "Epoch 774/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5402 - accuracy: 0.8512\n",
            "Epoch 774: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5418 - accuracy: 0.8510 - val_loss: 0.4439 - val_accuracy: 0.8787\n",
            "Epoch 775/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5436 - accuracy: 0.8481\n",
            "Epoch 775: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.8485 - val_loss: 0.4306 - val_accuracy: 0.8741\n",
            "Epoch 776/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5314 - accuracy: 0.8487\n",
            "Epoch 776: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.8492 - val_loss: 0.4378 - val_accuracy: 0.8764\n",
            "Epoch 777/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5208 - accuracy: 0.8485\n",
            "Epoch 777: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.8507 - val_loss: 0.4264 - val_accuracy: 0.8810\n",
            "Epoch 778/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5217 - accuracy: 0.8469\n",
            "Epoch 778: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.8460 - val_loss: 0.4276 - val_accuracy: 0.8696\n",
            "Epoch 779/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5052 - accuracy: 0.8581\n",
            "Epoch 779: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5028 - accuracy: 0.8581 - val_loss: 0.4491 - val_accuracy: 0.8707\n",
            "Epoch 780/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5125 - accuracy: 0.8537\n",
            "Epoch 780: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5102 - accuracy: 0.8545 - val_loss: 0.4380 - val_accuracy: 0.8844\n",
            "Epoch 781/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4797 - accuracy: 0.8603\n",
            "Epoch 781: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.8606 - val_loss: 0.4114 - val_accuracy: 0.8867\n",
            "Epoch 782/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4939 - accuracy: 0.8591\n",
            "Epoch 782: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5028 - accuracy: 0.8568 - val_loss: 0.4289 - val_accuracy: 0.8730\n",
            "Epoch 783/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.8617\n",
            "Epoch 783: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4925 - accuracy: 0.8620 - val_loss: 0.4406 - val_accuracy: 0.8673\n",
            "Epoch 784/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5437 - accuracy: 0.8583\n",
            "Epoch 784: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5416 - accuracy: 0.8583 - val_loss: 0.4367 - val_accuracy: 0.8776\n",
            "Epoch 785/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5542 - accuracy: 0.8501\n",
            "Epoch 785: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5508 - accuracy: 0.8503 - val_loss: 0.4396 - val_accuracy: 0.8719\n",
            "Epoch 786/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.8526\n",
            "Epoch 786: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5343 - accuracy: 0.8534 - val_loss: 0.4346 - val_accuracy: 0.8799\n",
            "Epoch 787/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5151 - accuracy: 0.8513\n",
            "Epoch 787: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.8530 - val_loss: 0.4209 - val_accuracy: 0.8776\n",
            "Epoch 788/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5069 - accuracy: 0.8526\n",
            "Epoch 788: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.8514 - val_loss: 0.4402 - val_accuracy: 0.8810\n",
            "Epoch 789/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5337 - accuracy: 0.8526\n",
            "Epoch 789: val_loss did not improve from 0.40117\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5327 - accuracy: 0.8538 - val_loss: 0.4336 - val_accuracy: 0.8822\n",
            "Epoch 790/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5134 - accuracy: 0.8533\n",
            "Epoch 790: val_loss improved from 0.40117 to 0.39615, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5124 - accuracy: 0.8528 - val_loss: 0.3961 - val_accuracy: 0.8856\n",
            "Epoch 791/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5134 - accuracy: 0.8584\n",
            "Epoch 791: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.8580 - val_loss: 0.3962 - val_accuracy: 0.8902\n",
            "Epoch 792/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5339 - accuracy: 0.8537\n",
            "Epoch 792: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5332 - accuracy: 0.8538 - val_loss: 0.4286 - val_accuracy: 0.8822\n",
            "Epoch 793/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5214 - accuracy: 0.8550\n",
            "Epoch 793: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5227 - accuracy: 0.8553 - val_loss: 0.4625 - val_accuracy: 0.8627\n",
            "Epoch 794/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.8493\n",
            "Epoch 794: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5523 - accuracy: 0.8494 - val_loss: 0.4421 - val_accuracy: 0.8741\n",
            "Epoch 795/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4699 - accuracy: 0.8624\n",
            "Epoch 795: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4680 - accuracy: 0.8624 - val_loss: 0.4201 - val_accuracy: 0.8776\n",
            "Epoch 796/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5337 - accuracy: 0.8489\n",
            "Epoch 796: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5326 - accuracy: 0.8490 - val_loss: 0.4177 - val_accuracy: 0.8730\n",
            "Epoch 797/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5330 - accuracy: 0.8547\n",
            "Epoch 797: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5281 - accuracy: 0.8553 - val_loss: 0.4194 - val_accuracy: 0.8799\n",
            "Epoch 798/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4690 - accuracy: 0.8633\n",
            "Epoch 798: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4698 - accuracy: 0.8631 - val_loss: 0.4302 - val_accuracy: 0.8799\n",
            "Epoch 799/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5022 - accuracy: 0.8632\n",
            "Epoch 799: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5012 - accuracy: 0.8636 - val_loss: 0.4142 - val_accuracy: 0.8810\n",
            "Epoch 800/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5076 - accuracy: 0.8579\n",
            "Epoch 800: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5070 - accuracy: 0.8573 - val_loss: 0.4268 - val_accuracy: 0.8879\n",
            "Epoch 801/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5314 - accuracy: 0.8512\n",
            "Epoch 801: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5298 - accuracy: 0.8507 - val_loss: 0.4233 - val_accuracy: 0.8833\n",
            "Epoch 802/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5181 - accuracy: 0.8510\n",
            "Epoch 802: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.8503 - val_loss: 0.4337 - val_accuracy: 0.8799\n",
            "Epoch 803/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5457 - accuracy: 0.8540\n",
            "Epoch 803: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5456 - accuracy: 0.8535 - val_loss: 0.4333 - val_accuracy: 0.8753\n",
            "Epoch 804/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4939 - accuracy: 0.8650\n",
            "Epoch 804: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4938 - accuracy: 0.8649 - val_loss: 0.4740 - val_accuracy: 0.8730\n",
            "Epoch 805/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5394 - accuracy: 0.8449\n",
            "Epoch 805: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5360 - accuracy: 0.8461 - val_loss: 0.4349 - val_accuracy: 0.8741\n",
            "Epoch 806/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5149 - accuracy: 0.8534\n",
            "Epoch 806: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.8534 - val_loss: 0.4435 - val_accuracy: 0.8719\n",
            "Epoch 807/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5049 - accuracy: 0.8572\n",
            "Epoch 807: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.8567 - val_loss: 0.4314 - val_accuracy: 0.8822\n",
            "Epoch 808/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5152 - accuracy: 0.8601\n",
            "Epoch 808: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5130 - accuracy: 0.8608 - val_loss: 0.4329 - val_accuracy: 0.8844\n",
            "Epoch 809/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4928 - accuracy: 0.8527\n",
            "Epoch 809: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.8531 - val_loss: 0.4192 - val_accuracy: 0.8776\n",
            "Epoch 810/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5054 - accuracy: 0.8584\n",
            "Epoch 810: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5045 - accuracy: 0.8576 - val_loss: 0.4403 - val_accuracy: 0.8776\n",
            "Epoch 811/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5131 - accuracy: 0.8520\n",
            "Epoch 811: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5156 - accuracy: 0.8523 - val_loss: 0.4449 - val_accuracy: 0.8753\n",
            "Epoch 812/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4852 - accuracy: 0.8637\n",
            "Epoch 812: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.8627 - val_loss: 0.4591 - val_accuracy: 0.8753\n",
            "Epoch 813/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5260 - accuracy: 0.8518\n",
            "Epoch 813: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5263 - accuracy: 0.8527 - val_loss: 0.4407 - val_accuracy: 0.8776\n",
            "Epoch 814/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5245 - accuracy: 0.8580\n",
            "Epoch 814: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5324 - accuracy: 0.8550 - val_loss: 0.4521 - val_accuracy: 0.8661\n",
            "Epoch 815/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5097 - accuracy: 0.8553\n",
            "Epoch 815: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5101 - accuracy: 0.8550 - val_loss: 0.4467 - val_accuracy: 0.8719\n",
            "Epoch 816/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5262 - accuracy: 0.8476\n",
            "Epoch 816: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.8482 - val_loss: 0.4181 - val_accuracy: 0.8902\n",
            "Epoch 817/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4852 - accuracy: 0.8568\n",
            "Epoch 817: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4865 - accuracy: 0.8568 - val_loss: 0.4366 - val_accuracy: 0.8787\n",
            "Epoch 818/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4965 - accuracy: 0.8561\n",
            "Epoch 818: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4995 - accuracy: 0.8555 - val_loss: 0.4315 - val_accuracy: 0.8833\n",
            "Epoch 819/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4927 - accuracy: 0.8573\n",
            "Epoch 819: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.8577 - val_loss: 0.4325 - val_accuracy: 0.8810\n",
            "Epoch 820/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4792 - accuracy: 0.8619\n",
            "Epoch 820: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4805 - accuracy: 0.8613 - val_loss: 0.4347 - val_accuracy: 0.8822\n",
            "Epoch 821/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5063 - accuracy: 0.8558\n",
            "Epoch 821: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5018 - accuracy: 0.8563 - val_loss: 0.4554 - val_accuracy: 0.8673\n",
            "Epoch 822/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5121 - accuracy: 0.8524\n",
            "Epoch 822: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.8525 - val_loss: 0.4525 - val_accuracy: 0.8719\n",
            "Epoch 823/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5123 - accuracy: 0.8520\n",
            "Epoch 823: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5102 - accuracy: 0.8525 - val_loss: 0.4301 - val_accuracy: 0.8776\n",
            "Epoch 824/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5077 - accuracy: 0.8570\n",
            "Epoch 824: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.8567 - val_loss: 0.4332 - val_accuracy: 0.8822\n",
            "Epoch 825/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5197 - accuracy: 0.8504\n",
            "Epoch 825: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.8504 - val_loss: 0.4379 - val_accuracy: 0.8707\n",
            "Epoch 826/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5438 - accuracy: 0.8529\n",
            "Epoch 826: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5402 - accuracy: 0.8530 - val_loss: 0.4729 - val_accuracy: 0.8661\n",
            "Epoch 827/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5403 - accuracy: 0.8512\n",
            "Epoch 827: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5383 - accuracy: 0.8515 - val_loss: 0.4325 - val_accuracy: 0.8776\n",
            "Epoch 828/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5060 - accuracy: 0.8587\n",
            "Epoch 828: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.8588 - val_loss: 0.4208 - val_accuracy: 0.8673\n",
            "Epoch 829/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4829 - accuracy: 0.8628\n",
            "Epoch 829: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4788 - accuracy: 0.8637 - val_loss: 0.4021 - val_accuracy: 0.8741\n",
            "Epoch 830/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4921 - accuracy: 0.8634\n",
            "Epoch 830: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4975 - accuracy: 0.8626 - val_loss: 0.4397 - val_accuracy: 0.8684\n",
            "Epoch 831/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5382 - accuracy: 0.8462\n",
            "Epoch 831: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5457 - accuracy: 0.8451 - val_loss: 0.4349 - val_accuracy: 0.8741\n",
            "Epoch 832/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5297 - accuracy: 0.8511\n",
            "Epoch 832: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5325 - accuracy: 0.8515 - val_loss: 0.4196 - val_accuracy: 0.8787\n",
            "Epoch 833/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5444 - accuracy: 0.8466\n",
            "Epoch 833: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5415 - accuracy: 0.8471 - val_loss: 0.4223 - val_accuracy: 0.8856\n",
            "Epoch 834/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4762 - accuracy: 0.8642\n",
            "Epoch 834: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4754 - accuracy: 0.8641 - val_loss: 0.4386 - val_accuracy: 0.8787\n",
            "Epoch 835/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5062 - accuracy: 0.8555\n",
            "Epoch 835: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8555 - val_loss: 0.4548 - val_accuracy: 0.8753\n",
            "Epoch 836/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4943 - accuracy: 0.8540\n",
            "Epoch 836: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.8544 - val_loss: 0.4106 - val_accuracy: 0.8890\n",
            "Epoch 837/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.8675\n",
            "Epoch 837: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.8670 - val_loss: 0.4272 - val_accuracy: 0.8799\n",
            "Epoch 838/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5053 - accuracy: 0.8606\n",
            "Epoch 838: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.8598 - val_loss: 0.4443 - val_accuracy: 0.8822\n",
            "Epoch 839/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5246 - accuracy: 0.8547\n",
            "Epoch 839: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.8547 - val_loss: 0.4733 - val_accuracy: 0.8833\n",
            "Epoch 840/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5297 - accuracy: 0.8576\n",
            "Epoch 840: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5314 - accuracy: 0.8577 - val_loss: 0.4206 - val_accuracy: 0.8810\n",
            "Epoch 841/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.8550\n",
            "Epoch 841: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.8550 - val_loss: 0.4372 - val_accuracy: 0.8810\n",
            "Epoch 842/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5232 - accuracy: 0.8491\n",
            "Epoch 842: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5216 - accuracy: 0.8490 - val_loss: 0.4460 - val_accuracy: 0.8810\n",
            "Epoch 843/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5001 - accuracy: 0.8585\n",
            "Epoch 843: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.8577 - val_loss: 0.4198 - val_accuracy: 0.8822\n",
            "Epoch 844/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5067 - accuracy: 0.8547\n",
            "Epoch 844: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.8558 - val_loss: 0.4620 - val_accuracy: 0.8741\n",
            "Epoch 845/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5240 - accuracy: 0.8533\n",
            "Epoch 845: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.8525 - val_loss: 0.4387 - val_accuracy: 0.8753\n",
            "Epoch 846/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4896 - accuracy: 0.8621\n",
            "Epoch 846: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4888 - accuracy: 0.8623 - val_loss: 0.4252 - val_accuracy: 0.8856\n",
            "Epoch 847/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5144 - accuracy: 0.8499\n",
            "Epoch 847: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5118 - accuracy: 0.8500 - val_loss: 0.4351 - val_accuracy: 0.8753\n",
            "Epoch 848/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4933 - accuracy: 0.8552\n",
            "Epoch 848: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4892 - accuracy: 0.8563 - val_loss: 0.4447 - val_accuracy: 0.8810\n",
            "Epoch 849/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4972 - accuracy: 0.8604\n",
            "Epoch 849: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.8606 - val_loss: 0.4433 - val_accuracy: 0.8799\n",
            "Epoch 850/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5176 - accuracy: 0.8555\n",
            "Epoch 850: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.8561 - val_loss: 0.4156 - val_accuracy: 0.8764\n",
            "Epoch 851/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4958 - accuracy: 0.8597\n",
            "Epoch 851: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4912 - accuracy: 0.8604 - val_loss: 0.4524 - val_accuracy: 0.8787\n",
            "Epoch 852/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5044 - accuracy: 0.8561\n",
            "Epoch 852: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.8558 - val_loss: 0.4240 - val_accuracy: 0.8856\n",
            "Epoch 853/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5242 - accuracy: 0.8533\n",
            "Epoch 853: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5242 - accuracy: 0.8533 - val_loss: 0.4398 - val_accuracy: 0.8741\n",
            "Epoch 854/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5031 - accuracy: 0.8568\n",
            "Epoch 854: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5031 - accuracy: 0.8568 - val_loss: 0.4322 - val_accuracy: 0.8719\n",
            "Epoch 855/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4824 - accuracy: 0.8639\n",
            "Epoch 855: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.8639 - val_loss: 0.4012 - val_accuracy: 0.8856\n",
            "Epoch 856/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4942 - accuracy: 0.8601\n",
            "Epoch 856: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4942 - accuracy: 0.8601 - val_loss: 0.4306 - val_accuracy: 0.8638\n",
            "Epoch 857/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4700 - accuracy: 0.8601\n",
            "Epoch 857: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4720 - accuracy: 0.8597 - val_loss: 0.4259 - val_accuracy: 0.8753\n",
            "Epoch 858/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4846 - accuracy: 0.8638\n",
            "Epoch 858: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.8636 - val_loss: 0.4261 - val_accuracy: 0.8707\n",
            "Epoch 859/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5383 - accuracy: 0.8543\n",
            "Epoch 859: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5370 - accuracy: 0.8538 - val_loss: 0.4352 - val_accuracy: 0.8730\n",
            "Epoch 860/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5180 - accuracy: 0.8481\n",
            "Epoch 860: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5171 - accuracy: 0.8475 - val_loss: 0.4418 - val_accuracy: 0.8787\n",
            "Epoch 861/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5138 - accuracy: 0.8606\n",
            "Epoch 861: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5166 - accuracy: 0.8597 - val_loss: 0.4376 - val_accuracy: 0.8776\n",
            "Epoch 862/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5286 - accuracy: 0.8493\n",
            "Epoch 862: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5224 - accuracy: 0.8503 - val_loss: 0.4491 - val_accuracy: 0.8764\n",
            "Epoch 863/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5415 - accuracy: 0.8465\n",
            "Epoch 863: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5419 - accuracy: 0.8464 - val_loss: 0.4479 - val_accuracy: 0.8776\n",
            "Epoch 864/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5129 - accuracy: 0.8560\n",
            "Epoch 864: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5147 - accuracy: 0.8557 - val_loss: 0.4305 - val_accuracy: 0.8844\n",
            "Epoch 865/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.8646\n",
            "Epoch 865: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4873 - accuracy: 0.8643 - val_loss: 0.4277 - val_accuracy: 0.8822\n",
            "Epoch 866/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4998 - accuracy: 0.8555\n",
            "Epoch 866: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5063 - accuracy: 0.8553 - val_loss: 0.4502 - val_accuracy: 0.8673\n",
            "Epoch 867/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5226 - accuracy: 0.8525\n",
            "Epoch 867: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.8525 - val_loss: 0.4511 - val_accuracy: 0.8787\n",
            "Epoch 868/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5390 - accuracy: 0.8543\n",
            "Epoch 868: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5318 - accuracy: 0.8547 - val_loss: 0.4608 - val_accuracy: 0.8753\n",
            "Epoch 869/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5250 - accuracy: 0.8460\n",
            "Epoch 869: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5241 - accuracy: 0.8464 - val_loss: 0.4244 - val_accuracy: 0.8753\n",
            "Epoch 870/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4944 - accuracy: 0.8641\n",
            "Epoch 870: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.8641 - val_loss: 0.4230 - val_accuracy: 0.8776\n",
            "Epoch 871/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4857 - accuracy: 0.8660\n",
            "Epoch 871: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4824 - accuracy: 0.8664 - val_loss: 0.4153 - val_accuracy: 0.8810\n",
            "Epoch 872/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5174 - accuracy: 0.8561\n",
            "Epoch 872: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5211 - accuracy: 0.8548 - val_loss: 0.4596 - val_accuracy: 0.8730\n",
            "Epoch 873/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4666 - accuracy: 0.8621\n",
            "Epoch 873: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.8618 - val_loss: 0.4307 - val_accuracy: 0.8730\n",
            "Epoch 874/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5247 - accuracy: 0.8535\n",
            "Epoch 874: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5249 - accuracy: 0.8534 - val_loss: 0.4443 - val_accuracy: 0.8719\n",
            "Epoch 875/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5213 - accuracy: 0.8541\n",
            "Epoch 875: val_loss did not improve from 0.39615\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.8534 - val_loss: 0.4313 - val_accuracy: 0.8787\n",
            "Epoch 876/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5353 - accuracy: 0.8553\n",
            "Epoch 876: val_loss improved from 0.39615 to 0.39570, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5268 - accuracy: 0.8548 - val_loss: 0.3957 - val_accuracy: 0.8924\n",
            "Epoch 877/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5288 - accuracy: 0.8542\n",
            "Epoch 877: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5277 - accuracy: 0.8543 - val_loss: 0.4309 - val_accuracy: 0.8799\n",
            "Epoch 878/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5388 - accuracy: 0.8647\n",
            "Epoch 878: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5382 - accuracy: 0.8659 - val_loss: 0.4218 - val_accuracy: 0.8753\n",
            "Epoch 879/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4846 - accuracy: 0.8638\n",
            "Epoch 879: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4851 - accuracy: 0.8634 - val_loss: 0.4065 - val_accuracy: 0.8822\n",
            "Epoch 880/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4919 - accuracy: 0.8671\n",
            "Epoch 880: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4915 - accuracy: 0.8667 - val_loss: 0.4264 - val_accuracy: 0.8741\n",
            "Epoch 881/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5485 - accuracy: 0.8462\n",
            "Epoch 881: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5472 - accuracy: 0.8468 - val_loss: 0.4475 - val_accuracy: 0.8730\n",
            "Epoch 882/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5116 - accuracy: 0.8528\n",
            "Epoch 882: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.8537 - val_loss: 0.4494 - val_accuracy: 0.8776\n",
            "Epoch 883/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5175 - accuracy: 0.8565\n",
            "Epoch 883: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5210 - accuracy: 0.8554 - val_loss: 0.4248 - val_accuracy: 0.8810\n",
            "Epoch 884/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5042 - accuracy: 0.8533\n",
            "Epoch 884: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.8534 - val_loss: 0.4046 - val_accuracy: 0.8924\n",
            "Epoch 885/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4936 - accuracy: 0.8610\n",
            "Epoch 885: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4937 - accuracy: 0.8603 - val_loss: 0.4077 - val_accuracy: 0.8902\n",
            "Epoch 886/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5132 - accuracy: 0.8550\n",
            "Epoch 886: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5132 - accuracy: 0.8545 - val_loss: 0.4442 - val_accuracy: 0.8799\n",
            "Epoch 887/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5128 - accuracy: 0.8564\n",
            "Epoch 887: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5150 - accuracy: 0.8567 - val_loss: 0.4155 - val_accuracy: 0.8764\n",
            "Epoch 888/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5152 - accuracy: 0.8584\n",
            "Epoch 888: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.8581 - val_loss: 0.4109 - val_accuracy: 0.8810\n",
            "Epoch 889/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5056 - accuracy: 0.8570\n",
            "Epoch 889: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4994 - accuracy: 0.8577 - val_loss: 0.4164 - val_accuracy: 0.8856\n",
            "Epoch 890/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5069 - accuracy: 0.8540\n",
            "Epoch 890: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5051 - accuracy: 0.8543 - val_loss: 0.4300 - val_accuracy: 0.8810\n",
            "Epoch 891/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5539 - accuracy: 0.8436\n",
            "Epoch 891: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5443 - accuracy: 0.8460 - val_loss: 0.4461 - val_accuracy: 0.8741\n",
            "Epoch 892/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5101 - accuracy: 0.8582\n",
            "Epoch 892: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5104 - accuracy: 0.8586 - val_loss: 0.4297 - val_accuracy: 0.8936\n",
            "Epoch 893/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5320 - accuracy: 0.8578\n",
            "Epoch 893: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5320 - accuracy: 0.8578 - val_loss: 0.4293 - val_accuracy: 0.8776\n",
            "Epoch 894/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4781 - accuracy: 0.8606\n",
            "Epoch 894: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8607 - val_loss: 0.4089 - val_accuracy: 0.8913\n",
            "Epoch 895/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4910 - accuracy: 0.8639\n",
            "Epoch 895: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4920 - accuracy: 0.8633 - val_loss: 0.4167 - val_accuracy: 0.8822\n",
            "Epoch 896/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5039 - accuracy: 0.8625\n",
            "Epoch 896: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5027 - accuracy: 0.8631 - val_loss: 0.4151 - val_accuracy: 0.8902\n",
            "Epoch 897/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5165 - accuracy: 0.8632\n",
            "Epoch 897: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.8633 - val_loss: 0.4414 - val_accuracy: 0.8856\n",
            "Epoch 898/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5012 - accuracy: 0.8579\n",
            "Epoch 898: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5002 - accuracy: 0.8577 - val_loss: 0.4407 - val_accuracy: 0.8822\n",
            "Epoch 899/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.8510\n",
            "Epoch 899: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.8510 - val_loss: 0.4304 - val_accuracy: 0.8730\n",
            "Epoch 900/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5296 - accuracy: 0.8532\n",
            "Epoch 900: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5257 - accuracy: 0.8537 - val_loss: 0.4194 - val_accuracy: 0.8856\n",
            "Epoch 901/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5111 - accuracy: 0.8597\n",
            "Epoch 901: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.8596 - val_loss: 0.4159 - val_accuracy: 0.8833\n",
            "Epoch 902/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4903 - accuracy: 0.8557\n",
            "Epoch 902: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.8561 - val_loss: 0.4217 - val_accuracy: 0.8799\n",
            "Epoch 903/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5181 - accuracy: 0.8530\n",
            "Epoch 903: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.8534 - val_loss: 0.4280 - val_accuracy: 0.8822\n",
            "Epoch 904/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4707 - accuracy: 0.8668\n",
            "Epoch 904: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4758 - accuracy: 0.8659 - val_loss: 0.4304 - val_accuracy: 0.8776\n",
            "Epoch 905/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5029 - accuracy: 0.8593\n",
            "Epoch 905: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5029 - accuracy: 0.8593 - val_loss: 0.4309 - val_accuracy: 0.8856\n",
            "Epoch 906/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5339 - accuracy: 0.8596\n",
            "Epoch 906: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.8596 - val_loss: 0.4406 - val_accuracy: 0.8764\n",
            "Epoch 907/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5089 - accuracy: 0.8593\n",
            "Epoch 907: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.8598 - val_loss: 0.4522 - val_accuracy: 0.8810\n",
            "Epoch 908/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5066 - accuracy: 0.8581\n",
            "Epoch 908: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5026 - accuracy: 0.8590 - val_loss: 0.4287 - val_accuracy: 0.8787\n",
            "Epoch 909/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5159 - accuracy: 0.8558\n",
            "Epoch 909: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5178 - accuracy: 0.8550 - val_loss: 0.4023 - val_accuracy: 0.8856\n",
            "Epoch 910/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4952 - accuracy: 0.8644\n",
            "Epoch 910: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.8639 - val_loss: 0.4328 - val_accuracy: 0.8753\n",
            "Epoch 911/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5317 - accuracy: 0.8550\n",
            "Epoch 911: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5320 - accuracy: 0.8547 - val_loss: 0.4061 - val_accuracy: 0.8890\n",
            "Epoch 912/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.8576\n",
            "Epoch 912: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5060 - accuracy: 0.8577 - val_loss: 0.4244 - val_accuracy: 0.8764\n",
            "Epoch 913/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4986 - accuracy: 0.8596\n",
            "Epoch 913: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4975 - accuracy: 0.8596 - val_loss: 0.4389 - val_accuracy: 0.8833\n",
            "Epoch 914/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4904 - accuracy: 0.8564\n",
            "Epoch 914: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4887 - accuracy: 0.8561 - val_loss: 0.4024 - val_accuracy: 0.8833\n",
            "Epoch 915/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5564 - accuracy: 0.8482\n",
            "Epoch 915: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5698 - accuracy: 0.8462 - val_loss: 0.4297 - val_accuracy: 0.8741\n",
            "Epoch 916/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5371 - accuracy: 0.8507\n",
            "Epoch 916: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5381 - accuracy: 0.8497 - val_loss: 0.4237 - val_accuracy: 0.8822\n",
            "Epoch 917/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5167 - accuracy: 0.8518\n",
            "Epoch 917: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5133 - accuracy: 0.8527 - val_loss: 0.4192 - val_accuracy: 0.8879\n",
            "Epoch 918/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5478 - accuracy: 0.8556\n",
            "Epoch 918: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5463 - accuracy: 0.8560 - val_loss: 0.4216 - val_accuracy: 0.8902\n",
            "Epoch 919/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4811 - accuracy: 0.8599\n",
            "Epoch 919: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.8591 - val_loss: 0.4109 - val_accuracy: 0.8833\n",
            "Epoch 920/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.8540\n",
            "Epoch 920: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5060 - accuracy: 0.8528 - val_loss: 0.4340 - val_accuracy: 0.8833\n",
            "Epoch 921/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5155 - accuracy: 0.8603\n",
            "Epoch 921: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.8608 - val_loss: 0.4028 - val_accuracy: 0.8856\n",
            "Epoch 922/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5427 - accuracy: 0.8546\n",
            "Epoch 922: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5404 - accuracy: 0.8553 - val_loss: 0.4514 - val_accuracy: 0.8844\n",
            "Epoch 923/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.6229 - accuracy: 0.8382\n",
            "Epoch 923: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.6242 - accuracy: 0.8368 - val_loss: 0.4778 - val_accuracy: 0.8719\n",
            "Epoch 924/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5189 - accuracy: 0.8527\n",
            "Epoch 924: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.8521 - val_loss: 0.4191 - val_accuracy: 0.8810\n",
            "Epoch 925/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5106 - accuracy: 0.8558\n",
            "Epoch 925: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5123 - accuracy: 0.8550 - val_loss: 0.4183 - val_accuracy: 0.8856\n",
            "Epoch 926/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5112 - accuracy: 0.8540\n",
            "Epoch 926: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5105 - accuracy: 0.8548 - val_loss: 0.4146 - val_accuracy: 0.8844\n",
            "Epoch 927/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5212 - accuracy: 0.8545\n",
            "Epoch 927: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5203 - accuracy: 0.8547 - val_loss: 0.4206 - val_accuracy: 0.8753\n",
            "Epoch 928/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5270 - accuracy: 0.8488\n",
            "Epoch 928: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5283 - accuracy: 0.8492 - val_loss: 0.4104 - val_accuracy: 0.8764\n",
            "Epoch 929/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4917 - accuracy: 0.8645\n",
            "Epoch 929: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.8643 - val_loss: 0.4159 - val_accuracy: 0.8890\n",
            "Epoch 930/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5163 - accuracy: 0.8581\n",
            "Epoch 930: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.8581 - val_loss: 0.4348 - val_accuracy: 0.8844\n",
            "Epoch 931/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5127 - accuracy: 0.8507\n",
            "Epoch 931: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5116 - accuracy: 0.8508 - val_loss: 0.4221 - val_accuracy: 0.8822\n",
            "Epoch 932/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5037 - accuracy: 0.8594\n",
            "Epoch 932: val_loss did not improve from 0.39570\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5037 - accuracy: 0.8594 - val_loss: 0.4237 - val_accuracy: 0.8764\n",
            "Epoch 933/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4781 - accuracy: 0.8604\n",
            "Epoch 933: val_loss improved from 0.39570 to 0.39457, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.8604 - val_loss: 0.3946 - val_accuracy: 0.8879\n",
            "Epoch 934/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4908 - accuracy: 0.8587\n",
            "Epoch 934: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4894 - accuracy: 0.8593 - val_loss: 0.4129 - val_accuracy: 0.8764\n",
            "Epoch 935/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5024 - accuracy: 0.8538\n",
            "Epoch 935: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5020 - accuracy: 0.8540 - val_loss: 0.4172 - val_accuracy: 0.8810\n",
            "Epoch 936/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5068 - accuracy: 0.8573\n",
            "Epoch 936: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5027 - accuracy: 0.8580 - val_loss: 0.4294 - val_accuracy: 0.8764\n",
            "Epoch 937/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5003 - accuracy: 0.8619\n",
            "Epoch 937: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4996 - accuracy: 0.8621 - val_loss: 0.4226 - val_accuracy: 0.8844\n",
            "Epoch 938/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4796 - accuracy: 0.8607\n",
            "Epoch 938: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4776 - accuracy: 0.8610 - val_loss: 0.4115 - val_accuracy: 0.8799\n",
            "Epoch 939/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4996 - accuracy: 0.8608\n",
            "Epoch 939: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.8597 - val_loss: 0.4469 - val_accuracy: 0.8776\n",
            "Epoch 940/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4928 - accuracy: 0.8534\n",
            "Epoch 940: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.8535 - val_loss: 0.3993 - val_accuracy: 0.8867\n",
            "Epoch 941/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5010 - accuracy: 0.8618\n",
            "Epoch 941: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4932 - accuracy: 0.8630 - val_loss: 0.4248 - val_accuracy: 0.8879\n",
            "Epoch 942/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4882 - accuracy: 0.8598\n",
            "Epoch 942: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4959 - accuracy: 0.8593 - val_loss: 0.4274 - val_accuracy: 0.8741\n",
            "Epoch 943/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5097 - accuracy: 0.8564\n",
            "Epoch 943: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5095 - accuracy: 0.8560 - val_loss: 0.4319 - val_accuracy: 0.8799\n",
            "Epoch 944/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4559 - accuracy: 0.8688\n",
            "Epoch 944: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4616 - accuracy: 0.8687 - val_loss: 0.4133 - val_accuracy: 0.8879\n",
            "Epoch 945/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5204 - accuracy: 0.8557\n",
            "Epoch 945: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5196 - accuracy: 0.8560 - val_loss: 0.4505 - val_accuracy: 0.8764\n",
            "Epoch 946/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4892 - accuracy: 0.8604\n",
            "Epoch 946: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4939 - accuracy: 0.8603 - val_loss: 0.4094 - val_accuracy: 0.8890\n",
            "Epoch 947/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5469 - accuracy: 0.8550\n",
            "Epoch 947: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5442 - accuracy: 0.8555 - val_loss: 0.4402 - val_accuracy: 0.8902\n",
            "Epoch 948/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5273 - accuracy: 0.8606\n",
            "Epoch 948: val_loss did not improve from 0.39457\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.8616 - val_loss: 0.3983 - val_accuracy: 0.8879\n",
            "Epoch 949/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4880 - accuracy: 0.8609\n",
            "Epoch 949: val_loss improved from 0.39457 to 0.39033, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4868 - accuracy: 0.8611 - val_loss: 0.3903 - val_accuracy: 0.8867\n",
            "Epoch 950/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4796 - accuracy: 0.8657\n",
            "Epoch 950: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.8657 - val_loss: 0.4282 - val_accuracy: 0.8844\n",
            "Epoch 951/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4819 - accuracy: 0.8627\n",
            "Epoch 951: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4844 - accuracy: 0.8617 - val_loss: 0.4459 - val_accuracy: 0.8867\n",
            "Epoch 952/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5139 - accuracy: 0.8539\n",
            "Epoch 952: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.8543 - val_loss: 0.4215 - val_accuracy: 0.8924\n",
            "Epoch 953/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5065 - accuracy: 0.8574\n",
            "Epoch 953: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5044 - accuracy: 0.8580 - val_loss: 0.4239 - val_accuracy: 0.8776\n",
            "Epoch 954/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4941 - accuracy: 0.8607\n",
            "Epoch 954: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4941 - accuracy: 0.8607 - val_loss: 0.3994 - val_accuracy: 0.8924\n",
            "Epoch 955/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5093 - accuracy: 0.8624\n",
            "Epoch 955: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5162 - accuracy: 0.8621 - val_loss: 0.4248 - val_accuracy: 0.8776\n",
            "Epoch 956/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5115 - accuracy: 0.8568\n",
            "Epoch 956: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.8560 - val_loss: 0.4153 - val_accuracy: 0.8902\n",
            "Epoch 957/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5206 - accuracy: 0.8538\n",
            "Epoch 957: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5176 - accuracy: 0.8545 - val_loss: 0.4389 - val_accuracy: 0.8890\n",
            "Epoch 958/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5136 - accuracy: 0.8554\n",
            "Epoch 958: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5106 - accuracy: 0.8561 - val_loss: 0.4219 - val_accuracy: 0.8787\n",
            "Epoch 959/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5098 - accuracy: 0.8560\n",
            "Epoch 959: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5131 - accuracy: 0.8547 - val_loss: 0.4224 - val_accuracy: 0.8741\n",
            "Epoch 960/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4856 - accuracy: 0.8595\n",
            "Epoch 960: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4897 - accuracy: 0.8587 - val_loss: 0.4135 - val_accuracy: 0.8890\n",
            "Epoch 961/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5132 - accuracy: 0.8526\n",
            "Epoch 961: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5118 - accuracy: 0.8525 - val_loss: 0.4194 - val_accuracy: 0.8879\n",
            "Epoch 962/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5535 - accuracy: 0.8491\n",
            "Epoch 962: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5527 - accuracy: 0.8491 - val_loss: 0.4229 - val_accuracy: 0.8924\n",
            "Epoch 963/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4683 - accuracy: 0.8690\n",
            "Epoch 963: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4664 - accuracy: 0.8694 - val_loss: 0.4133 - val_accuracy: 0.8867\n",
            "Epoch 964/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5235 - accuracy: 0.8557\n",
            "Epoch 964: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.8553 - val_loss: 0.4213 - val_accuracy: 0.8822\n",
            "Epoch 965/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4932 - accuracy: 0.8584\n",
            "Epoch 965: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.8584 - val_loss: 0.3993 - val_accuracy: 0.8947\n",
            "Epoch 966/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5354 - accuracy: 0.8506\n",
            "Epoch 966: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.8501 - val_loss: 0.4421 - val_accuracy: 0.8776\n",
            "Epoch 967/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5216 - accuracy: 0.8527\n",
            "Epoch 967: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.8524 - val_loss: 0.3926 - val_accuracy: 0.8982\n",
            "Epoch 968/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5066 - accuracy: 0.8575\n",
            "Epoch 968: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.8574 - val_loss: 0.3943 - val_accuracy: 0.8936\n",
            "Epoch 969/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5190 - accuracy: 0.8617\n",
            "Epoch 969: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5181 - accuracy: 0.8617 - val_loss: 0.3916 - val_accuracy: 0.9016\n",
            "Epoch 970/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5065 - accuracy: 0.8588\n",
            "Epoch 970: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5065 - accuracy: 0.8588 - val_loss: 0.4153 - val_accuracy: 0.8753\n",
            "Epoch 971/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5456 - accuracy: 0.8512\n",
            "Epoch 971: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5432 - accuracy: 0.8525 - val_loss: 0.4107 - val_accuracy: 0.8879\n",
            "Epoch 972/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4903 - accuracy: 0.8585\n",
            "Epoch 972: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.8596 - val_loss: 0.4410 - val_accuracy: 0.8719\n",
            "Epoch 973/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5042 - accuracy: 0.8584\n",
            "Epoch 973: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.8581 - val_loss: 0.4126 - val_accuracy: 0.8902\n",
            "Epoch 974/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.5343 - accuracy: 0.8533\n",
            "Epoch 974: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5295 - accuracy: 0.8524 - val_loss: 0.4335 - val_accuracy: 0.8844\n",
            "Epoch 975/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5000 - accuracy: 0.8604\n",
            "Epoch 975: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.8614 - val_loss: 0.4253 - val_accuracy: 0.8902\n",
            "Epoch 976/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5295 - accuracy: 0.8546\n",
            "Epoch 976: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.8538 - val_loss: 0.4208 - val_accuracy: 0.8844\n",
            "Epoch 977/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4991 - accuracy: 0.8586\n",
            "Epoch 977: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.8591 - val_loss: 0.4153 - val_accuracy: 0.8890\n",
            "Epoch 978/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5041 - accuracy: 0.8607\n",
            "Epoch 978: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5050 - accuracy: 0.8600 - val_loss: 0.4081 - val_accuracy: 0.8890\n",
            "Epoch 979/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5586 - accuracy: 0.8487\n",
            "Epoch 979: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5529 - accuracy: 0.8492 - val_loss: 0.4468 - val_accuracy: 0.8879\n",
            "Epoch 980/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5214 - accuracy: 0.8619\n",
            "Epoch 980: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5213 - accuracy: 0.8620 - val_loss: 0.4276 - val_accuracy: 0.8879\n",
            "Epoch 981/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4966 - accuracy: 0.8647\n",
            "Epoch 981: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5059 - accuracy: 0.8636 - val_loss: 0.4283 - val_accuracy: 0.8810\n",
            "Epoch 982/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5315 - accuracy: 0.8514\n",
            "Epoch 982: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5369 - accuracy: 0.8505 - val_loss: 0.4428 - val_accuracy: 0.8741\n",
            "Epoch 983/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4837 - accuracy: 0.8654\n",
            "Epoch 983: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4837 - accuracy: 0.8654 - val_loss: 0.4335 - val_accuracy: 0.8719\n",
            "Epoch 984/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5377 - accuracy: 0.8546\n",
            "Epoch 984: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5323 - accuracy: 0.8544 - val_loss: 0.4543 - val_accuracy: 0.8844\n",
            "Epoch 985/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5074 - accuracy: 0.8540\n",
            "Epoch 985: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.8537 - val_loss: 0.4298 - val_accuracy: 0.8833\n",
            "Epoch 986/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4455 - accuracy: 0.8729\n",
            "Epoch 986: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4500 - accuracy: 0.8723 - val_loss: 0.4342 - val_accuracy: 0.8879\n",
            "Epoch 987/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5184 - accuracy: 0.8612\n",
            "Epoch 987: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.8604 - val_loss: 0.4368 - val_accuracy: 0.8844\n",
            "Epoch 988/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4966 - accuracy: 0.8617\n",
            "Epoch 988: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.8620 - val_loss: 0.4533 - val_accuracy: 0.8741\n",
            "Epoch 989/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4895 - accuracy: 0.8648\n",
            "Epoch 989: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.8651 - val_loss: 0.4279 - val_accuracy: 0.8822\n",
            "Epoch 990/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5095 - accuracy: 0.8630\n",
            "Epoch 990: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5095 - accuracy: 0.8630 - val_loss: 0.4261 - val_accuracy: 0.8730\n",
            "Epoch 991/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4843 - accuracy: 0.8602\n",
            "Epoch 991: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4920 - accuracy: 0.8603 - val_loss: 0.4164 - val_accuracy: 0.8856\n",
            "Epoch 992/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5064 - accuracy: 0.8569\n",
            "Epoch 992: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.8573 - val_loss: 0.4344 - val_accuracy: 0.8810\n",
            "Epoch 993/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4968 - accuracy: 0.8658\n",
            "Epoch 993: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4920 - accuracy: 0.8664 - val_loss: 0.4610 - val_accuracy: 0.8719\n",
            "Epoch 994/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5243 - accuracy: 0.8556\n",
            "Epoch 994: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5199 - accuracy: 0.8567 - val_loss: 0.4322 - val_accuracy: 0.8822\n",
            "Epoch 995/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4923 - accuracy: 0.8576\n",
            "Epoch 995: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.8558 - val_loss: 0.4720 - val_accuracy: 0.8719\n",
            "Epoch 996/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5291 - accuracy: 0.8580\n",
            "Epoch 996: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5291 - accuracy: 0.8580 - val_loss: 0.4681 - val_accuracy: 0.8719\n",
            "Epoch 997/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5380 - accuracy: 0.8487\n",
            "Epoch 997: val_loss did not improve from 0.39033\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.8487 - val_loss: 0.4228 - val_accuracy: 0.8787\n",
            "Epoch 998/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5278 - accuracy: 0.8579\n",
            "Epoch 998: val_loss improved from 0.39033 to 0.38707, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5261 - accuracy: 0.8573 - val_loss: 0.3871 - val_accuracy: 0.8982\n",
            "Epoch 999/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4957 - accuracy: 0.8625\n",
            "Epoch 999: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4973 - accuracy: 0.8627 - val_loss: 0.4230 - val_accuracy: 0.8856\n",
            "Epoch 1000/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5156 - accuracy: 0.8587\n",
            "Epoch 1000: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.8590 - val_loss: 0.4277 - val_accuracy: 0.8764\n",
            "Epoch 1001/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5508 - accuracy: 0.8482\n",
            "Epoch 1001: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5522 - accuracy: 0.8487 - val_loss: 0.4206 - val_accuracy: 0.8810\n",
            "Epoch 1002/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5133 - accuracy: 0.8560\n",
            "Epoch 1002: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.8558 - val_loss: 0.4130 - val_accuracy: 0.8822\n",
            "Epoch 1003/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5051 - accuracy: 0.8604\n",
            "Epoch 1003: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8601 - val_loss: 0.4327 - val_accuracy: 0.8776\n",
            "Epoch 1004/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5459 - accuracy: 0.8534\n",
            "Epoch 1004: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5437 - accuracy: 0.8531 - val_loss: 0.4095 - val_accuracy: 0.8913\n",
            "Epoch 1005/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4826 - accuracy: 0.8609\n",
            "Epoch 1005: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5028 - accuracy: 0.8590 - val_loss: 0.4243 - val_accuracy: 0.8856\n",
            "Epoch 1006/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4818 - accuracy: 0.8649\n",
            "Epoch 1006: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4867 - accuracy: 0.8637 - val_loss: 0.4562 - val_accuracy: 0.8810\n",
            "Epoch 1007/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5292 - accuracy: 0.8522\n",
            "Epoch 1007: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5237 - accuracy: 0.8533 - val_loss: 0.4476 - val_accuracy: 0.8799\n",
            "Epoch 1008/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4864 - accuracy: 0.8589\n",
            "Epoch 1008: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4926 - accuracy: 0.8580 - val_loss: 0.4513 - val_accuracy: 0.8810\n",
            "Epoch 1009/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4887 - accuracy: 0.8641\n",
            "Epoch 1009: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.8653 - val_loss: 0.4798 - val_accuracy: 0.8787\n",
            "Epoch 1010/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4667 - accuracy: 0.8631\n",
            "Epoch 1010: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.8639 - val_loss: 0.4697 - val_accuracy: 0.8810\n",
            "Epoch 1011/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4977 - accuracy: 0.8603\n",
            "Epoch 1011: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4926 - accuracy: 0.8614 - val_loss: 0.4560 - val_accuracy: 0.8707\n",
            "Epoch 1012/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4788 - accuracy: 0.8661\n",
            "Epoch 1012: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.8647 - val_loss: 0.4539 - val_accuracy: 0.8764\n",
            "Epoch 1013/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4952 - accuracy: 0.8613\n",
            "Epoch 1013: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4958 - accuracy: 0.8618 - val_loss: 0.4431 - val_accuracy: 0.8810\n",
            "Epoch 1014/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5640 - accuracy: 0.8602\n",
            "Epoch 1014: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5614 - accuracy: 0.8597 - val_loss: 0.4497 - val_accuracy: 0.8799\n",
            "Epoch 1015/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5550 - accuracy: 0.8516\n",
            "Epoch 1015: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5483 - accuracy: 0.8525 - val_loss: 0.4335 - val_accuracy: 0.8787\n",
            "Epoch 1016/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5165 - accuracy: 0.8572\n",
            "Epoch 1016: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5145 - accuracy: 0.8571 - val_loss: 0.4306 - val_accuracy: 0.8707\n",
            "Epoch 1017/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5097 - accuracy: 0.8554\n",
            "Epoch 1017: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.8558 - val_loss: 0.4385 - val_accuracy: 0.8844\n",
            "Epoch 1018/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4734 - accuracy: 0.8674\n",
            "Epoch 1018: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.8673 - val_loss: 0.4361 - val_accuracy: 0.8764\n",
            "Epoch 1019/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5457 - accuracy: 0.8553\n",
            "Epoch 1019: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5445 - accuracy: 0.8535 - val_loss: 0.4492 - val_accuracy: 0.8753\n",
            "Epoch 1020/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4567 - accuracy: 0.8720\n",
            "Epoch 1020: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.8716 - val_loss: 0.4216 - val_accuracy: 0.8902\n",
            "Epoch 1021/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4890 - accuracy: 0.8626\n",
            "Epoch 1021: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4908 - accuracy: 0.8623 - val_loss: 0.4486 - val_accuracy: 0.8810\n",
            "Epoch 1022/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5707 - accuracy: 0.8523\n",
            "Epoch 1022: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5735 - accuracy: 0.8510 - val_loss: 0.4623 - val_accuracy: 0.8719\n",
            "Epoch 1023/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5137 - accuracy: 0.8533\n",
            "Epoch 1023: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5172 - accuracy: 0.8525 - val_loss: 0.4209 - val_accuracy: 0.8673\n",
            "Epoch 1024/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4783 - accuracy: 0.8648\n",
            "Epoch 1024: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4797 - accuracy: 0.8643 - val_loss: 0.4051 - val_accuracy: 0.8833\n",
            "Epoch 1025/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5272 - accuracy: 0.8518\n",
            "Epoch 1025: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.8524 - val_loss: 0.4450 - val_accuracy: 0.8719\n",
            "Epoch 1026/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5528 - accuracy: 0.8518\n",
            "Epoch 1026: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5528 - accuracy: 0.8518 - val_loss: 0.4379 - val_accuracy: 0.8764\n",
            "Epoch 1027/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5179 - accuracy: 0.8594\n",
            "Epoch 1027: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5211 - accuracy: 0.8590 - val_loss: 0.4490 - val_accuracy: 0.8638\n",
            "Epoch 1028/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4991 - accuracy: 0.8626\n",
            "Epoch 1028: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4991 - accuracy: 0.8626 - val_loss: 0.4166 - val_accuracy: 0.8844\n",
            "Epoch 1029/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5253 - accuracy: 0.8568\n",
            "Epoch 1029: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5236 - accuracy: 0.8574 - val_loss: 0.4614 - val_accuracy: 0.8764\n",
            "Epoch 1030/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4938 - accuracy: 0.8652\n",
            "Epoch 1030: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4953 - accuracy: 0.8651 - val_loss: 0.4080 - val_accuracy: 0.8810\n",
            "Epoch 1031/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4995 - accuracy: 0.8610\n",
            "Epoch 1031: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4971 - accuracy: 0.8604 - val_loss: 0.4117 - val_accuracy: 0.8833\n",
            "Epoch 1032/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5193 - accuracy: 0.8584\n",
            "Epoch 1032: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.8576 - val_loss: 0.4296 - val_accuracy: 0.8799\n",
            "Epoch 1033/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4660 - accuracy: 0.8667\n",
            "Epoch 1033: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4660 - accuracy: 0.8667 - val_loss: 0.4174 - val_accuracy: 0.8902\n",
            "Epoch 1034/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5092 - accuracy: 0.8678\n",
            "Epoch 1034: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5064 - accuracy: 0.8674 - val_loss: 0.4451 - val_accuracy: 0.8787\n",
            "Epoch 1035/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4701 - accuracy: 0.8678\n",
            "Epoch 1035: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4727 - accuracy: 0.8673 - val_loss: 0.4613 - val_accuracy: 0.8764\n",
            "Epoch 1036/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4761 - accuracy: 0.8654\n",
            "Epoch 1036: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4756 - accuracy: 0.8654 - val_loss: 0.4244 - val_accuracy: 0.8833\n",
            "Epoch 1037/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5075 - accuracy: 0.8656\n",
            "Epoch 1037: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5062 - accuracy: 0.8660 - val_loss: 0.4319 - val_accuracy: 0.8822\n",
            "Epoch 1038/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5026 - accuracy: 0.8587\n",
            "Epoch 1038: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.8583 - val_loss: 0.4160 - val_accuracy: 0.8753\n",
            "Epoch 1039/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5024 - accuracy: 0.8676\n",
            "Epoch 1039: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8669 - val_loss: 0.3939 - val_accuracy: 0.8879\n",
            "Epoch 1040/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5123 - accuracy: 0.8564\n",
            "Epoch 1040: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5146 - accuracy: 0.8557 - val_loss: 0.4348 - val_accuracy: 0.8764\n",
            "Epoch 1041/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5121 - accuracy: 0.8570\n",
            "Epoch 1041: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5139 - accuracy: 0.8567 - val_loss: 0.4314 - val_accuracy: 0.8764\n",
            "Epoch 1042/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5453 - accuracy: 0.8525\n",
            "Epoch 1042: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5453 - accuracy: 0.8525 - val_loss: 0.4196 - val_accuracy: 0.8879\n",
            "Epoch 1043/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.8641\n",
            "Epoch 1043: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.8633 - val_loss: 0.4224 - val_accuracy: 0.8867\n",
            "Epoch 1044/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5057 - accuracy: 0.8647\n",
            "Epoch 1044: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.8637 - val_loss: 0.4009 - val_accuracy: 0.8776\n",
            "Epoch 1045/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4972 - accuracy: 0.8597\n",
            "Epoch 1045: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4964 - accuracy: 0.8598 - val_loss: 0.4085 - val_accuracy: 0.8924\n",
            "Epoch 1046/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5189 - accuracy: 0.8612\n",
            "Epoch 1046: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5150 - accuracy: 0.8610 - val_loss: 0.4211 - val_accuracy: 0.8902\n",
            "Epoch 1047/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5208 - accuracy: 0.8638\n",
            "Epoch 1047: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5151 - accuracy: 0.8640 - val_loss: 0.4328 - val_accuracy: 0.8810\n",
            "Epoch 1048/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5361 - accuracy: 0.8630\n",
            "Epoch 1048: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5331 - accuracy: 0.8630 - val_loss: 0.4462 - val_accuracy: 0.8833\n",
            "Epoch 1049/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5168 - accuracy: 0.8601\n",
            "Epoch 1049: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5149 - accuracy: 0.8603 - val_loss: 0.4403 - val_accuracy: 0.8741\n",
            "Epoch 1050/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4917 - accuracy: 0.8608\n",
            "Epoch 1050: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4895 - accuracy: 0.8607 - val_loss: 0.4101 - val_accuracy: 0.8890\n",
            "Epoch 1051/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5103 - accuracy: 0.8665\n",
            "Epoch 1051: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.8641 - val_loss: 0.4012 - val_accuracy: 0.8764\n",
            "Epoch 1052/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5089 - accuracy: 0.8617\n",
            "Epoch 1052: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5096 - accuracy: 0.8610 - val_loss: 0.4129 - val_accuracy: 0.8776\n",
            "Epoch 1053/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4805 - accuracy: 0.8606\n",
            "Epoch 1053: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4933 - accuracy: 0.8604 - val_loss: 0.4177 - val_accuracy: 0.8787\n",
            "Epoch 1054/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.8545\n",
            "Epoch 1054: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5376 - accuracy: 0.8547 - val_loss: 0.4281 - val_accuracy: 0.8719\n",
            "Epoch 1055/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5072 - accuracy: 0.8558\n",
            "Epoch 1055: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.8568 - val_loss: 0.4226 - val_accuracy: 0.8924\n",
            "Epoch 1056/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4568 - accuracy: 0.8685\n",
            "Epoch 1056: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.8681 - val_loss: 0.4107 - val_accuracy: 0.8890\n",
            "Epoch 1057/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5458 - accuracy: 0.8562\n",
            "Epoch 1057: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5511 - accuracy: 0.8547 - val_loss: 0.4667 - val_accuracy: 0.8719\n",
            "Epoch 1058/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4860 - accuracy: 0.8650\n",
            "Epoch 1058: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.8636 - val_loss: 0.4053 - val_accuracy: 0.8924\n",
            "Epoch 1059/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.5299 - accuracy: 0.8642\n",
            "Epoch 1059: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5241 - accuracy: 0.8636 - val_loss: 0.4308 - val_accuracy: 0.8822\n",
            "Epoch 1060/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5013 - accuracy: 0.8623\n",
            "Epoch 1060: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.8626 - val_loss: 0.4179 - val_accuracy: 0.8776\n",
            "Epoch 1061/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4845 - accuracy: 0.8737\n",
            "Epoch 1061: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4845 - accuracy: 0.8737 - val_loss: 0.4277 - val_accuracy: 0.8867\n",
            "Epoch 1062/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5121 - accuracy: 0.8656\n",
            "Epoch 1062: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5054 - accuracy: 0.8676 - val_loss: 0.4035 - val_accuracy: 0.8799\n",
            "Epoch 1063/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4870 - accuracy: 0.8636\n",
            "Epoch 1063: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4841 - accuracy: 0.8649 - val_loss: 0.4147 - val_accuracy: 0.8833\n",
            "Epoch 1064/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.8593\n",
            "Epoch 1064: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5300 - accuracy: 0.8597 - val_loss: 0.4296 - val_accuracy: 0.8764\n",
            "Epoch 1065/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5621 - accuracy: 0.8557\n",
            "Epoch 1065: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5532 - accuracy: 0.8554 - val_loss: 0.4311 - val_accuracy: 0.8776\n",
            "Epoch 1066/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5262 - accuracy: 0.8537\n",
            "Epoch 1066: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.8524 - val_loss: 0.4129 - val_accuracy: 0.8924\n",
            "Epoch 1067/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4968 - accuracy: 0.8614\n",
            "Epoch 1067: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4935 - accuracy: 0.8618 - val_loss: 0.4336 - val_accuracy: 0.8787\n",
            "Epoch 1068/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4890 - accuracy: 0.8620\n",
            "Epoch 1068: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4876 - accuracy: 0.8633 - val_loss: 0.4206 - val_accuracy: 0.8844\n",
            "Epoch 1069/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4907 - accuracy: 0.8654\n",
            "Epoch 1069: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4872 - accuracy: 0.8650 - val_loss: 0.4393 - val_accuracy: 0.8787\n",
            "Epoch 1070/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.5089 - accuracy: 0.8589\n",
            "Epoch 1070: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5057 - accuracy: 0.8581 - val_loss: 0.4255 - val_accuracy: 0.8856\n",
            "Epoch 1071/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4823 - accuracy: 0.8667\n",
            "Epoch 1071: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.8654 - val_loss: 0.4131 - val_accuracy: 0.8879\n",
            "Epoch 1072/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5054 - accuracy: 0.8565\n",
            "Epoch 1072: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5035 - accuracy: 0.8570 - val_loss: 0.4329 - val_accuracy: 0.8844\n",
            "Epoch 1073/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4848 - accuracy: 0.8622\n",
            "Epoch 1073: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.8620 - val_loss: 0.4366 - val_accuracy: 0.8810\n",
            "Epoch 1074/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4851 - accuracy: 0.8629\n",
            "Epoch 1074: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4960 - accuracy: 0.8621 - val_loss: 0.4031 - val_accuracy: 0.8799\n",
            "Epoch 1075/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5094 - accuracy: 0.8614\n",
            "Epoch 1075: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5086 - accuracy: 0.8604 - val_loss: 0.4242 - val_accuracy: 0.8822\n",
            "Epoch 1076/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.8659\n",
            "Epoch 1076: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.8661 - val_loss: 0.4087 - val_accuracy: 0.8879\n",
            "Epoch 1077/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.8651\n",
            "Epoch 1077: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.8644 - val_loss: 0.4223 - val_accuracy: 0.8844\n",
            "Epoch 1078/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4976 - accuracy: 0.8571\n",
            "Epoch 1078: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.8578 - val_loss: 0.3931 - val_accuracy: 0.8924\n",
            "Epoch 1079/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4899 - accuracy: 0.8581\n",
            "Epoch 1079: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4894 - accuracy: 0.8584 - val_loss: 0.4064 - val_accuracy: 0.8844\n",
            "Epoch 1080/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4712 - accuracy: 0.8641\n",
            "Epoch 1080: val_loss did not improve from 0.38707\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.8641 - val_loss: 0.3963 - val_accuracy: 0.8741\n",
            "Epoch 1081/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5208 - accuracy: 0.8594\n",
            "Epoch 1081: val_loss improved from 0.38707 to 0.38430, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5201 - accuracy: 0.8591 - val_loss: 0.3843 - val_accuracy: 0.8810\n",
            "Epoch 1082/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5196 - accuracy: 0.8609\n",
            "Epoch 1082: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5161 - accuracy: 0.8613 - val_loss: 0.3992 - val_accuracy: 0.8810\n",
            "Epoch 1083/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5223 - accuracy: 0.8544\n",
            "Epoch 1083: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5246 - accuracy: 0.8548 - val_loss: 0.4274 - val_accuracy: 0.8650\n",
            "Epoch 1084/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5041 - accuracy: 0.8611\n",
            "Epoch 1084: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.8611 - val_loss: 0.4254 - val_accuracy: 0.8776\n",
            "Epoch 1085/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5152 - accuracy: 0.8562\n",
            "Epoch 1085: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.8561 - val_loss: 0.4254 - val_accuracy: 0.8707\n",
            "Epoch 1086/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4966 - accuracy: 0.8611\n",
            "Epoch 1086: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4966 - accuracy: 0.8611 - val_loss: 0.4162 - val_accuracy: 0.8810\n",
            "Epoch 1087/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5048 - accuracy: 0.8642\n",
            "Epoch 1087: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5057 - accuracy: 0.8634 - val_loss: 0.4269 - val_accuracy: 0.8684\n",
            "Epoch 1088/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4884 - accuracy: 0.8612\n",
            "Epoch 1088: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4875 - accuracy: 0.8613 - val_loss: 0.4079 - val_accuracy: 0.8776\n",
            "Epoch 1089/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.8673\n",
            "Epoch 1089: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4855 - accuracy: 0.8673 - val_loss: 0.4091 - val_accuracy: 0.8764\n",
            "Epoch 1090/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4931 - accuracy: 0.8654\n",
            "Epoch 1090: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.8657 - val_loss: 0.4241 - val_accuracy: 0.8856\n",
            "Epoch 1091/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5276 - accuracy: 0.8596\n",
            "Epoch 1091: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5317 - accuracy: 0.8586 - val_loss: 0.4246 - val_accuracy: 0.8844\n",
            "Epoch 1092/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5024 - accuracy: 0.8600\n",
            "Epoch 1092: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.8598 - val_loss: 0.4191 - val_accuracy: 0.8902\n",
            "Epoch 1093/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4740 - accuracy: 0.8676\n",
            "Epoch 1093: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4762 - accuracy: 0.8660 - val_loss: 0.4417 - val_accuracy: 0.8833\n",
            "Epoch 1094/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5068 - accuracy: 0.8581\n",
            "Epoch 1094: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5045 - accuracy: 0.8586 - val_loss: 0.4255 - val_accuracy: 0.8879\n",
            "Epoch 1095/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.8636\n",
            "Epoch 1095: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5336 - accuracy: 0.8639 - val_loss: 0.4193 - val_accuracy: 0.8879\n",
            "Epoch 1096/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4783 - accuracy: 0.8631\n",
            "Epoch 1096: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4841 - accuracy: 0.8607 - val_loss: 0.4773 - val_accuracy: 0.8661\n",
            "Epoch 1097/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5341 - accuracy: 0.8543\n",
            "Epoch 1097: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5341 - accuracy: 0.8543 - val_loss: 0.4260 - val_accuracy: 0.8856\n",
            "Epoch 1098/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.8641\n",
            "Epoch 1098: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.8641 - val_loss: 0.4497 - val_accuracy: 0.8799\n",
            "Epoch 1099/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5118 - accuracy: 0.8657\n",
            "Epoch 1099: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5184 - accuracy: 0.8636 - val_loss: 0.4465 - val_accuracy: 0.8753\n",
            "Epoch 1100/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5439 - accuracy: 0.8525\n",
            "Epoch 1100: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5416 - accuracy: 0.8531 - val_loss: 0.4208 - val_accuracy: 0.8867\n",
            "Epoch 1101/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4955 - accuracy: 0.8649\n",
            "Epoch 1101: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4935 - accuracy: 0.8649 - val_loss: 0.4178 - val_accuracy: 0.8776\n",
            "Epoch 1102/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4803 - accuracy: 0.8612\n",
            "Epoch 1102: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.8608 - val_loss: 0.4113 - val_accuracy: 0.8833\n",
            "Epoch 1103/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5201 - accuracy: 0.8567\n",
            "Epoch 1103: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5141 - accuracy: 0.8577 - val_loss: 0.4136 - val_accuracy: 0.8879\n",
            "Epoch 1104/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5009 - accuracy: 0.8578\n",
            "Epoch 1104: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4998 - accuracy: 0.8577 - val_loss: 0.4107 - val_accuracy: 0.8844\n",
            "Epoch 1105/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4821 - accuracy: 0.8671\n",
            "Epoch 1105: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4915 - accuracy: 0.8679 - val_loss: 0.4514 - val_accuracy: 0.8753\n",
            "Epoch 1106/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5281 - accuracy: 0.8518\n",
            "Epoch 1106: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5256 - accuracy: 0.8517 - val_loss: 0.4274 - val_accuracy: 0.8776\n",
            "Epoch 1107/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4870 - accuracy: 0.8637\n",
            "Epoch 1107: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4891 - accuracy: 0.8643 - val_loss: 0.4382 - val_accuracy: 0.8822\n",
            "Epoch 1108/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5366 - accuracy: 0.8591\n",
            "Epoch 1108: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5302 - accuracy: 0.8593 - val_loss: 0.4239 - val_accuracy: 0.8890\n",
            "Epoch 1109/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5294 - accuracy: 0.8590\n",
            "Epoch 1109: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5294 - accuracy: 0.8590 - val_loss: 0.4277 - val_accuracy: 0.8822\n",
            "Epoch 1110/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5603 - accuracy: 0.8555\n",
            "Epoch 1110: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5574 - accuracy: 0.8563 - val_loss: 0.4797 - val_accuracy: 0.8707\n",
            "Epoch 1111/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4923 - accuracy: 0.8553\n",
            "Epoch 1111: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.8570 - val_loss: 0.4312 - val_accuracy: 0.8822\n",
            "Epoch 1112/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5309 - accuracy: 0.8581\n",
            "Epoch 1112: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5297 - accuracy: 0.8586 - val_loss: 0.4495 - val_accuracy: 0.8833\n",
            "Epoch 1113/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5334 - accuracy: 0.8550\n",
            "Epoch 1113: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5372 - accuracy: 0.8544 - val_loss: 0.4367 - val_accuracy: 0.8833\n",
            "Epoch 1114/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5520 - accuracy: 0.8507\n",
            "Epoch 1114: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5519 - accuracy: 0.8507 - val_loss: 0.4708 - val_accuracy: 0.8707\n",
            "Epoch 1115/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5162 - accuracy: 0.8613\n",
            "Epoch 1115: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5158 - accuracy: 0.8600 - val_loss: 0.4660 - val_accuracy: 0.8753\n",
            "Epoch 1116/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4798 - accuracy: 0.8659\n",
            "Epoch 1116: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.8651 - val_loss: 0.4149 - val_accuracy: 0.8879\n",
            "Epoch 1117/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5125 - accuracy: 0.8572\n",
            "Epoch 1117: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.8565 - val_loss: 0.4154 - val_accuracy: 0.8822\n",
            "Epoch 1118/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4993 - accuracy: 0.8648\n",
            "Epoch 1118: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5039 - accuracy: 0.8631 - val_loss: 0.4337 - val_accuracy: 0.8890\n",
            "Epoch 1119/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4536 - accuracy: 0.8700\n",
            "Epoch 1119: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4549 - accuracy: 0.8691 - val_loss: 0.4135 - val_accuracy: 0.8890\n",
            "Epoch 1120/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4725 - accuracy: 0.8664\n",
            "Epoch 1120: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.8669 - val_loss: 0.4121 - val_accuracy: 0.8879\n",
            "Epoch 1121/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4794 - accuracy: 0.8695\n",
            "Epoch 1121: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4804 - accuracy: 0.8691 - val_loss: 0.4372 - val_accuracy: 0.8902\n",
            "Epoch 1122/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4959 - accuracy: 0.8612\n",
            "Epoch 1122: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4967 - accuracy: 0.8610 - val_loss: 0.4328 - val_accuracy: 0.8890\n",
            "Epoch 1123/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4792 - accuracy: 0.8671\n",
            "Epoch 1123: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4792 - accuracy: 0.8670 - val_loss: 0.4341 - val_accuracy: 0.8787\n",
            "Epoch 1124/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4791 - accuracy: 0.8614\n",
            "Epoch 1124: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4791 - accuracy: 0.8614 - val_loss: 0.4398 - val_accuracy: 0.8856\n",
            "Epoch 1125/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4659 - accuracy: 0.8630\n",
            "Epoch 1125: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4661 - accuracy: 0.8626 - val_loss: 0.4351 - val_accuracy: 0.8822\n",
            "Epoch 1126/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4680 - accuracy: 0.8673\n",
            "Epoch 1126: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4744 - accuracy: 0.8664 - val_loss: 0.4453 - val_accuracy: 0.8719\n",
            "Epoch 1127/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4730 - accuracy: 0.8703\n",
            "Epoch 1127: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4731 - accuracy: 0.8703 - val_loss: 0.4145 - val_accuracy: 0.8787\n",
            "Epoch 1128/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.8622\n",
            "Epoch 1128: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4830 - accuracy: 0.8624 - val_loss: 0.4064 - val_accuracy: 0.8936\n",
            "Epoch 1129/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4859 - accuracy: 0.8615\n",
            "Epoch 1129: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4857 - accuracy: 0.8616 - val_loss: 0.4114 - val_accuracy: 0.8924\n",
            "Epoch 1130/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4890 - accuracy: 0.8681\n",
            "Epoch 1130: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.8683 - val_loss: 0.3972 - val_accuracy: 0.8833\n",
            "Epoch 1131/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5276 - accuracy: 0.8540\n",
            "Epoch 1131: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.8554 - val_loss: 0.4268 - val_accuracy: 0.8924\n",
            "Epoch 1132/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4994 - accuracy: 0.8626\n",
            "Epoch 1132: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5043 - accuracy: 0.8627 - val_loss: 0.4368 - val_accuracy: 0.8867\n",
            "Epoch 1133/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5281 - accuracy: 0.8618\n",
            "Epoch 1133: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5264 - accuracy: 0.8628 - val_loss: 0.4549 - val_accuracy: 0.8741\n",
            "Epoch 1134/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5081 - accuracy: 0.8634\n",
            "Epoch 1134: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5081 - accuracy: 0.8634 - val_loss: 0.4217 - val_accuracy: 0.8833\n",
            "Epoch 1135/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5070 - accuracy: 0.8600\n",
            "Epoch 1135: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8604 - val_loss: 0.4423 - val_accuracy: 0.8787\n",
            "Epoch 1136/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4884 - accuracy: 0.8609\n",
            "Epoch 1136: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.8600 - val_loss: 0.4533 - val_accuracy: 0.8879\n",
            "Epoch 1137/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5050 - accuracy: 0.8614\n",
            "Epoch 1137: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5050 - accuracy: 0.8614 - val_loss: 0.4512 - val_accuracy: 0.8776\n",
            "Epoch 1138/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5222 - accuracy: 0.8637\n",
            "Epoch 1138: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5169 - accuracy: 0.8650 - val_loss: 0.4344 - val_accuracy: 0.8879\n",
            "Epoch 1139/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5063 - accuracy: 0.8637\n",
            "Epoch 1139: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5035 - accuracy: 0.8634 - val_loss: 0.4471 - val_accuracy: 0.8719\n",
            "Epoch 1140/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4948 - accuracy: 0.8603\n",
            "Epoch 1140: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.8608 - val_loss: 0.4438 - val_accuracy: 0.8810\n",
            "Epoch 1141/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5281 - accuracy: 0.8600\n",
            "Epoch 1141: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5353 - accuracy: 0.8587 - val_loss: 0.4510 - val_accuracy: 0.8844\n",
            "Epoch 1142/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5556 - accuracy: 0.8541\n",
            "Epoch 1142: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5556 - accuracy: 0.8541 - val_loss: 0.4332 - val_accuracy: 0.8833\n",
            "Epoch 1143/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4620 - accuracy: 0.8722\n",
            "Epoch 1143: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4592 - accuracy: 0.8733 - val_loss: 0.4094 - val_accuracy: 0.8844\n",
            "Epoch 1144/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4965 - accuracy: 0.8652\n",
            "Epoch 1144: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5001 - accuracy: 0.8647 - val_loss: 0.4036 - val_accuracy: 0.8856\n",
            "Epoch 1145/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4557 - accuracy: 0.8744\n",
            "Epoch 1145: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4562 - accuracy: 0.8740 - val_loss: 0.4352 - val_accuracy: 0.8787\n",
            "Epoch 1146/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4858 - accuracy: 0.8662\n",
            "Epoch 1146: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4844 - accuracy: 0.8667 - val_loss: 0.4311 - val_accuracy: 0.8879\n",
            "Epoch 1147/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4922 - accuracy: 0.8611\n",
            "Epoch 1147: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4886 - accuracy: 0.8616 - val_loss: 0.4568 - val_accuracy: 0.8879\n",
            "Epoch 1148/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4833 - accuracy: 0.8622\n",
            "Epoch 1148: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.8618 - val_loss: 0.4418 - val_accuracy: 0.8787\n",
            "Epoch 1149/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5098 - accuracy: 0.8578\n",
            "Epoch 1149: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.8571 - val_loss: 0.4417 - val_accuracy: 0.8833\n",
            "Epoch 1150/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4967 - accuracy: 0.8622\n",
            "Epoch 1150: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4957 - accuracy: 0.8623 - val_loss: 0.4340 - val_accuracy: 0.8856\n",
            "Epoch 1151/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5572 - accuracy: 0.8573\n",
            "Epoch 1151: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5557 - accuracy: 0.8564 - val_loss: 0.4613 - val_accuracy: 0.8581\n",
            "Epoch 1152/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4695 - accuracy: 0.8654\n",
            "Epoch 1152: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.8654 - val_loss: 0.4375 - val_accuracy: 0.8799\n",
            "Epoch 1153/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5139 - accuracy: 0.8603\n",
            "Epoch 1153: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5125 - accuracy: 0.8604 - val_loss: 0.4438 - val_accuracy: 0.8833\n",
            "Epoch 1154/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4962 - accuracy: 0.8628\n",
            "Epoch 1154: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4956 - accuracy: 0.8624 - val_loss: 0.4254 - val_accuracy: 0.8810\n",
            "Epoch 1155/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4959 - accuracy: 0.8647\n",
            "Epoch 1155: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.8643 - val_loss: 0.4198 - val_accuracy: 0.8902\n",
            "Epoch 1156/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4706 - accuracy: 0.8650\n",
            "Epoch 1156: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.8640 - val_loss: 0.4360 - val_accuracy: 0.8833\n",
            "Epoch 1157/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5413 - accuracy: 0.8560\n",
            "Epoch 1157: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5413 - accuracy: 0.8560 - val_loss: 0.4260 - val_accuracy: 0.8867\n",
            "Epoch 1158/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5741 - accuracy: 0.8542\n",
            "Epoch 1158: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5686 - accuracy: 0.8553 - val_loss: 0.4617 - val_accuracy: 0.8696\n",
            "Epoch 1159/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5534 - accuracy: 0.8511\n",
            "Epoch 1159: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5493 - accuracy: 0.8518 - val_loss: 0.4129 - val_accuracy: 0.8867\n",
            "Epoch 1160/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4774 - accuracy: 0.8583\n",
            "Epoch 1160: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4802 - accuracy: 0.8581 - val_loss: 0.4130 - val_accuracy: 0.8879\n",
            "Epoch 1161/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4888 - accuracy: 0.8668\n",
            "Epoch 1161: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4877 - accuracy: 0.8669 - val_loss: 0.4084 - val_accuracy: 0.8867\n",
            "Epoch 1162/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4784 - accuracy: 0.8655\n",
            "Epoch 1162: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4773 - accuracy: 0.8656 - val_loss: 0.4624 - val_accuracy: 0.8764\n",
            "Epoch 1163/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4727 - accuracy: 0.8616\n",
            "Epoch 1163: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4732 - accuracy: 0.8616 - val_loss: 0.4126 - val_accuracy: 0.8867\n",
            "Epoch 1164/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4724 - accuracy: 0.8658\n",
            "Epoch 1164: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.8669 - val_loss: 0.4182 - val_accuracy: 0.8844\n",
            "Epoch 1165/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4612 - accuracy: 0.8717\n",
            "Epoch 1165: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.8709 - val_loss: 0.3922 - val_accuracy: 0.8947\n",
            "Epoch 1166/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4642 - accuracy: 0.8656\n",
            "Epoch 1166: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4642 - accuracy: 0.8656 - val_loss: 0.4076 - val_accuracy: 0.8924\n",
            "Epoch 1167/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4649 - accuracy: 0.8733\n",
            "Epoch 1167: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4634 - accuracy: 0.8716 - val_loss: 0.4200 - val_accuracy: 0.8856\n",
            "Epoch 1168/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4992 - accuracy: 0.8610\n",
            "Epoch 1168: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4992 - accuracy: 0.8610 - val_loss: 0.4386 - val_accuracy: 0.8844\n",
            "Epoch 1169/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5143 - accuracy: 0.8615\n",
            "Epoch 1169: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5255 - accuracy: 0.8617 - val_loss: 0.4568 - val_accuracy: 0.8844\n",
            "Epoch 1170/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5419 - accuracy: 0.8539\n",
            "Epoch 1170: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5400 - accuracy: 0.8540 - val_loss: 0.4493 - val_accuracy: 0.8833\n",
            "Epoch 1171/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5398 - accuracy: 0.8517\n",
            "Epoch 1171: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5434 - accuracy: 0.8517 - val_loss: 0.4055 - val_accuracy: 0.8959\n",
            "Epoch 1172/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5108 - accuracy: 0.8647\n",
            "Epoch 1172: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.8631 - val_loss: 0.4170 - val_accuracy: 0.8913\n",
            "Epoch 1173/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5092 - accuracy: 0.8564\n",
            "Epoch 1173: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5098 - accuracy: 0.8558 - val_loss: 0.4410 - val_accuracy: 0.8867\n",
            "Epoch 1174/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5174 - accuracy: 0.8558\n",
            "Epoch 1174: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5132 - accuracy: 0.8576 - val_loss: 0.4071 - val_accuracy: 0.8947\n",
            "Epoch 1175/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5314 - accuracy: 0.8587\n",
            "Epoch 1175: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5354 - accuracy: 0.8586 - val_loss: 0.4128 - val_accuracy: 0.8822\n",
            "Epoch 1176/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5403 - accuracy: 0.8606\n",
            "Epoch 1176: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5396 - accuracy: 0.8606 - val_loss: 0.4273 - val_accuracy: 0.8799\n",
            "Epoch 1177/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5500 - accuracy: 0.8523\n",
            "Epoch 1177: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5500 - accuracy: 0.8523 - val_loss: 0.4515 - val_accuracy: 0.8638\n",
            "Epoch 1178/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5325 - accuracy: 0.8486\n",
            "Epoch 1178: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5347 - accuracy: 0.8485 - val_loss: 0.4339 - val_accuracy: 0.8810\n",
            "Epoch 1179/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5016 - accuracy: 0.8597\n",
            "Epoch 1179: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5103 - accuracy: 0.8581 - val_loss: 0.3887 - val_accuracy: 0.8959\n",
            "Epoch 1180/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5420 - accuracy: 0.8551\n",
            "Epoch 1180: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5400 - accuracy: 0.8558 - val_loss: 0.4271 - val_accuracy: 0.8799\n",
            "Epoch 1181/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5316 - accuracy: 0.8537\n",
            "Epoch 1181: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5316 - accuracy: 0.8537 - val_loss: 0.4092 - val_accuracy: 0.8867\n",
            "Epoch 1182/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5192 - accuracy: 0.8649\n",
            "Epoch 1182: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5166 - accuracy: 0.8653 - val_loss: 0.4344 - val_accuracy: 0.8787\n",
            "Epoch 1183/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.8634\n",
            "Epoch 1183: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.8634 - val_loss: 0.4250 - val_accuracy: 0.8867\n",
            "Epoch 1184/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4893 - accuracy: 0.8677\n",
            "Epoch 1184: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.8684 - val_loss: 0.4261 - val_accuracy: 0.8810\n",
            "Epoch 1185/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4765 - accuracy: 0.8714\n",
            "Epoch 1185: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.8704 - val_loss: 0.4325 - val_accuracy: 0.8913\n",
            "Epoch 1186/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4645 - accuracy: 0.8680\n",
            "Epoch 1186: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.8674 - val_loss: 0.4300 - val_accuracy: 0.8730\n",
            "Epoch 1187/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4965 - accuracy: 0.8674\n",
            "Epoch 1187: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4983 - accuracy: 0.8671 - val_loss: 0.4462 - val_accuracy: 0.8719\n",
            "Epoch 1188/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5223 - accuracy: 0.8635\n",
            "Epoch 1188: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5272 - accuracy: 0.8611 - val_loss: 0.3978 - val_accuracy: 0.8890\n",
            "Epoch 1189/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5012 - accuracy: 0.8558\n",
            "Epoch 1189: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4974 - accuracy: 0.8553 - val_loss: 0.3948 - val_accuracy: 0.8833\n",
            "Epoch 1190/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4920 - accuracy: 0.8587\n",
            "Epoch 1190: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4912 - accuracy: 0.8586 - val_loss: 0.3969 - val_accuracy: 0.8822\n",
            "Epoch 1191/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8657\n",
            "Epoch 1191: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4945 - accuracy: 0.8661 - val_loss: 0.4326 - val_accuracy: 0.8810\n",
            "Epoch 1192/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.8597\n",
            "Epoch 1192: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4858 - accuracy: 0.8594 - val_loss: 0.4103 - val_accuracy: 0.8799\n",
            "Epoch 1193/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4755 - accuracy: 0.8740\n",
            "Epoch 1193: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.8740 - val_loss: 0.4120 - val_accuracy: 0.8913\n",
            "Epoch 1194/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4861 - accuracy: 0.8624\n",
            "Epoch 1194: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4889 - accuracy: 0.8628 - val_loss: 0.3909 - val_accuracy: 0.8810\n",
            "Epoch 1195/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4969 - accuracy: 0.8601\n",
            "Epoch 1195: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4955 - accuracy: 0.8597 - val_loss: 0.4137 - val_accuracy: 0.8822\n",
            "Epoch 1196/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5336 - accuracy: 0.8633\n",
            "Epoch 1196: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5329 - accuracy: 0.8633 - val_loss: 0.4181 - val_accuracy: 0.8810\n",
            "Epoch 1197/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4983 - accuracy: 0.8600\n",
            "Epoch 1197: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4956 - accuracy: 0.8606 - val_loss: 0.4231 - val_accuracy: 0.8730\n",
            "Epoch 1198/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5158 - accuracy: 0.8645\n",
            "Epoch 1198: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5234 - accuracy: 0.8631 - val_loss: 0.4218 - val_accuracy: 0.8776\n",
            "Epoch 1199/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5150 - accuracy: 0.8547\n",
            "Epoch 1199: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5092 - accuracy: 0.8563 - val_loss: 0.4487 - val_accuracy: 0.8822\n",
            "Epoch 1200/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4857 - accuracy: 0.8624\n",
            "Epoch 1200: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.8639 - val_loss: 0.4290 - val_accuracy: 0.8890\n",
            "Epoch 1201/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5091 - accuracy: 0.8606\n",
            "Epoch 1201: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5078 - accuracy: 0.8608 - val_loss: 0.4251 - val_accuracy: 0.8833\n",
            "Epoch 1202/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4911 - accuracy: 0.8606\n",
            "Epoch 1202: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.8628 - val_loss: 0.3930 - val_accuracy: 0.8822\n",
            "Epoch 1203/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4916 - accuracy: 0.8694\n",
            "Epoch 1203: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.8694 - val_loss: 0.4404 - val_accuracy: 0.8787\n",
            "Epoch 1204/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5025 - accuracy: 0.8630\n",
            "Epoch 1204: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4960 - accuracy: 0.8644 - val_loss: 0.4194 - val_accuracy: 0.8787\n",
            "Epoch 1205/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5541 - accuracy: 0.8533\n",
            "Epoch 1205: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5488 - accuracy: 0.8530 - val_loss: 0.4374 - val_accuracy: 0.8661\n",
            "Epoch 1206/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5278 - accuracy: 0.8528\n",
            "Epoch 1206: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5248 - accuracy: 0.8528 - val_loss: 0.4129 - val_accuracy: 0.8833\n",
            "Epoch 1207/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5344 - accuracy: 0.8550\n",
            "Epoch 1207: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5341 - accuracy: 0.8544 - val_loss: 0.4130 - val_accuracy: 0.8787\n",
            "Epoch 1208/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5221 - accuracy: 0.8577\n",
            "Epoch 1208: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5206 - accuracy: 0.8581 - val_loss: 0.4126 - val_accuracy: 0.8856\n",
            "Epoch 1209/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4693 - accuracy: 0.8673\n",
            "Epoch 1209: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4672 - accuracy: 0.8674 - val_loss: 0.4178 - val_accuracy: 0.8822\n",
            "Epoch 1210/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5718 - accuracy: 0.8505\n",
            "Epoch 1210: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5705 - accuracy: 0.8505 - val_loss: 0.4334 - val_accuracy: 0.8776\n",
            "Epoch 1211/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5373 - accuracy: 0.8545\n",
            "Epoch 1211: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.8574 - val_loss: 0.4455 - val_accuracy: 0.8833\n",
            "Epoch 1212/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4864 - accuracy: 0.8645\n",
            "Epoch 1212: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4830 - accuracy: 0.8654 - val_loss: 0.4364 - val_accuracy: 0.8753\n",
            "Epoch 1213/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4942 - accuracy: 0.8725\n",
            "Epoch 1213: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4930 - accuracy: 0.8720 - val_loss: 0.4179 - val_accuracy: 0.8810\n",
            "Epoch 1214/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5013 - accuracy: 0.8634\n",
            "Epoch 1214: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5080 - accuracy: 0.8628 - val_loss: 0.4247 - val_accuracy: 0.8822\n",
            "Epoch 1215/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5491 - accuracy: 0.8480\n",
            "Epoch 1215: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5540 - accuracy: 0.8468 - val_loss: 0.4068 - val_accuracy: 0.8787\n",
            "Epoch 1216/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4827 - accuracy: 0.8617\n",
            "Epoch 1216: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4847 - accuracy: 0.8614 - val_loss: 0.4130 - val_accuracy: 0.8833\n",
            "Epoch 1217/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5246 - accuracy: 0.8626\n",
            "Epoch 1217: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5180 - accuracy: 0.8634 - val_loss: 0.4605 - val_accuracy: 0.8776\n",
            "Epoch 1218/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5092 - accuracy: 0.8627\n",
            "Epoch 1218: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5113 - accuracy: 0.8620 - val_loss: 0.4356 - val_accuracy: 0.8833\n",
            "Epoch 1219/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5245 - accuracy: 0.8635\n",
            "Epoch 1219: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.8633 - val_loss: 0.4313 - val_accuracy: 0.8867\n",
            "Epoch 1220/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5180 - accuracy: 0.8628\n",
            "Epoch 1220: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5093 - accuracy: 0.8627 - val_loss: 0.4059 - val_accuracy: 0.8936\n",
            "Epoch 1221/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5126 - accuracy: 0.8627\n",
            "Epoch 1221: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.8627 - val_loss: 0.4182 - val_accuracy: 0.8787\n",
            "Epoch 1222/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4911 - accuracy: 0.8665\n",
            "Epoch 1222: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4859 - accuracy: 0.8664 - val_loss: 0.4153 - val_accuracy: 0.8947\n",
            "Epoch 1223/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5104 - accuracy: 0.8629\n",
            "Epoch 1223: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5098 - accuracy: 0.8627 - val_loss: 0.4075 - val_accuracy: 0.8822\n",
            "Epoch 1224/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4632 - accuracy: 0.8753\n",
            "Epoch 1224: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4596 - accuracy: 0.8744 - val_loss: 0.4173 - val_accuracy: 0.8810\n",
            "Epoch 1225/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4811 - accuracy: 0.8676\n",
            "Epoch 1225: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4769 - accuracy: 0.8683 - val_loss: 0.4125 - val_accuracy: 0.8844\n",
            "Epoch 1226/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4903 - accuracy: 0.8666\n",
            "Epoch 1226: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4939 - accuracy: 0.8666 - val_loss: 0.4043 - val_accuracy: 0.8913\n",
            "Epoch 1227/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5489 - accuracy: 0.8614\n",
            "Epoch 1227: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5504 - accuracy: 0.8613 - val_loss: 0.4321 - val_accuracy: 0.8810\n",
            "Epoch 1228/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5079 - accuracy: 0.8594\n",
            "Epoch 1228: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.8587 - val_loss: 0.4180 - val_accuracy: 0.8902\n",
            "Epoch 1229/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4737 - accuracy: 0.8678\n",
            "Epoch 1229: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.8673 - val_loss: 0.3925 - val_accuracy: 0.8924\n",
            "Epoch 1230/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5106 - accuracy: 0.8657\n",
            "Epoch 1230: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5106 - accuracy: 0.8657 - val_loss: 0.4143 - val_accuracy: 0.8867\n",
            "Epoch 1231/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5113 - accuracy: 0.8640\n",
            "Epoch 1231: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.8641 - val_loss: 0.4163 - val_accuracy: 0.8810\n",
            "Epoch 1232/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5765 - accuracy: 0.8463\n",
            "Epoch 1232: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5747 - accuracy: 0.8472 - val_loss: 0.4247 - val_accuracy: 0.8844\n",
            "Epoch 1233/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4806 - accuracy: 0.8664\n",
            "Epoch 1233: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4876 - accuracy: 0.8656 - val_loss: 0.4234 - val_accuracy: 0.8776\n",
            "Epoch 1234/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.8626\n",
            "Epoch 1234: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4845 - accuracy: 0.8627 - val_loss: 0.3907 - val_accuracy: 0.8833\n",
            "Epoch 1235/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5238 - accuracy: 0.8611\n",
            "Epoch 1235: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5244 - accuracy: 0.8598 - val_loss: 0.3986 - val_accuracy: 0.8822\n",
            "Epoch 1236/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4837 - accuracy: 0.8647\n",
            "Epoch 1236: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4916 - accuracy: 0.8624 - val_loss: 0.4090 - val_accuracy: 0.8867\n",
            "Epoch 1237/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4726 - accuracy: 0.8688\n",
            "Epoch 1237: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4743 - accuracy: 0.8677 - val_loss: 0.4396 - val_accuracy: 0.8787\n",
            "Epoch 1238/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4797 - accuracy: 0.8620\n",
            "Epoch 1238: val_loss did not improve from 0.38430\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4796 - accuracy: 0.8618 - val_loss: 0.3879 - val_accuracy: 0.8924\n",
            "Epoch 1239/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4745 - accuracy: 0.8697\n",
            "Epoch 1239: val_loss improved from 0.38430 to 0.37512, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4736 - accuracy: 0.8696 - val_loss: 0.3751 - val_accuracy: 0.8890\n",
            "Epoch 1240/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4685 - accuracy: 0.8660\n",
            "Epoch 1240: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.8656 - val_loss: 0.3910 - val_accuracy: 0.8879\n",
            "Epoch 1241/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5418 - accuracy: 0.8615\n",
            "Epoch 1241: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5409 - accuracy: 0.8607 - val_loss: 0.4126 - val_accuracy: 0.8913\n",
            "Epoch 1242/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5354 - accuracy: 0.8609\n",
            "Epoch 1242: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.8611 - val_loss: 0.4133 - val_accuracy: 0.8947\n",
            "Epoch 1243/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5069 - accuracy: 0.8674\n",
            "Epoch 1243: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.8680 - val_loss: 0.3960 - val_accuracy: 0.8924\n",
            "Epoch 1244/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4744 - accuracy: 0.8570\n",
            "Epoch 1244: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.8578 - val_loss: 0.4160 - val_accuracy: 0.8867\n",
            "Epoch 1245/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5144 - accuracy: 0.8616\n",
            "Epoch 1245: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.8620 - val_loss: 0.4023 - val_accuracy: 0.8822\n",
            "Epoch 1246/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5107 - accuracy: 0.8571\n",
            "Epoch 1246: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.8570 - val_loss: 0.4145 - val_accuracy: 0.8856\n",
            "Epoch 1247/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4999 - accuracy: 0.8633\n",
            "Epoch 1247: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5002 - accuracy: 0.8628 - val_loss: 0.4000 - val_accuracy: 0.8970\n",
            "Epoch 1248/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4783 - accuracy: 0.8646\n",
            "Epoch 1248: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4775 - accuracy: 0.8657 - val_loss: 0.4033 - val_accuracy: 0.8890\n",
            "Epoch 1249/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5137 - accuracy: 0.8574\n",
            "Epoch 1249: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.8576 - val_loss: 0.4125 - val_accuracy: 0.8879\n",
            "Epoch 1250/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4861 - accuracy: 0.8622\n",
            "Epoch 1250: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4876 - accuracy: 0.8621 - val_loss: 0.4114 - val_accuracy: 0.8856\n",
            "Epoch 1251/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5021 - accuracy: 0.8633\n",
            "Epoch 1251: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4989 - accuracy: 0.8643 - val_loss: 0.4292 - val_accuracy: 0.8902\n",
            "Epoch 1252/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4993 - accuracy: 0.8682\n",
            "Epoch 1252: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5024 - accuracy: 0.8663 - val_loss: 0.4263 - val_accuracy: 0.8879\n",
            "Epoch 1253/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4642 - accuracy: 0.8746\n",
            "Epoch 1253: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4692 - accuracy: 0.8742 - val_loss: 0.4475 - val_accuracy: 0.8822\n",
            "Epoch 1254/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5345 - accuracy: 0.8543\n",
            "Epoch 1254: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5345 - accuracy: 0.8543 - val_loss: 0.4187 - val_accuracy: 0.8867\n",
            "Epoch 1255/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4925 - accuracy: 0.8568\n",
            "Epoch 1255: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4925 - accuracy: 0.8568 - val_loss: 0.4012 - val_accuracy: 0.8924\n",
            "Epoch 1256/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4873 - accuracy: 0.8618\n",
            "Epoch 1256: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4893 - accuracy: 0.8607 - val_loss: 0.4262 - val_accuracy: 0.8776\n",
            "Epoch 1257/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5404 - accuracy: 0.8652\n",
            "Epoch 1257: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5375 - accuracy: 0.8646 - val_loss: 0.4568 - val_accuracy: 0.8787\n",
            "Epoch 1258/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4916 - accuracy: 0.8649\n",
            "Epoch 1258: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.8650 - val_loss: 0.4042 - val_accuracy: 0.8844\n",
            "Epoch 1259/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4735 - accuracy: 0.8724\n",
            "Epoch 1259: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4744 - accuracy: 0.8723 - val_loss: 0.4063 - val_accuracy: 0.8867\n",
            "Epoch 1260/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4773 - accuracy: 0.8663\n",
            "Epoch 1260: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4773 - accuracy: 0.8663 - val_loss: 0.4059 - val_accuracy: 0.8787\n",
            "Epoch 1261/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4718 - accuracy: 0.8721\n",
            "Epoch 1261: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.8716 - val_loss: 0.4126 - val_accuracy: 0.8810\n",
            "Epoch 1262/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5529 - accuracy: 0.8633\n",
            "Epoch 1262: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5524 - accuracy: 0.8630 - val_loss: 0.4142 - val_accuracy: 0.8822\n",
            "Epoch 1263/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4628 - accuracy: 0.8651\n",
            "Epoch 1263: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4628 - accuracy: 0.8651 - val_loss: 0.4131 - val_accuracy: 0.8867\n",
            "Epoch 1264/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4669 - accuracy: 0.8679\n",
            "Epoch 1264: val_loss did not improve from 0.37512\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.8686 - val_loss: 0.4123 - val_accuracy: 0.8810\n",
            "Epoch 1265/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4912 - accuracy: 0.8669\n",
            "Epoch 1265: val_loss improved from 0.37512 to 0.37249, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4903 - accuracy: 0.8671 - val_loss: 0.3725 - val_accuracy: 0.8902\n",
            "Epoch 1266/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5162 - accuracy: 0.8600\n",
            "Epoch 1266: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.8620 - val_loss: 0.4007 - val_accuracy: 0.8764\n",
            "Epoch 1267/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5234 - accuracy: 0.8632\n",
            "Epoch 1267: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5229 - accuracy: 0.8633 - val_loss: 0.4377 - val_accuracy: 0.8696\n",
            "Epoch 1268/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5193 - accuracy: 0.8524\n",
            "Epoch 1268: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.8537 - val_loss: 0.4096 - val_accuracy: 0.8844\n",
            "Epoch 1269/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5128 - accuracy: 0.8513\n",
            "Epoch 1269: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5100 - accuracy: 0.8517 - val_loss: 0.4134 - val_accuracy: 0.8867\n",
            "Epoch 1270/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5394 - accuracy: 0.8573\n",
            "Epoch 1270: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.8577 - val_loss: 0.4046 - val_accuracy: 0.8913\n",
            "Epoch 1271/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4680 - accuracy: 0.8703\n",
            "Epoch 1271: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4705 - accuracy: 0.8694 - val_loss: 0.4227 - val_accuracy: 0.8902\n",
            "Epoch 1272/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4943 - accuracy: 0.8607\n",
            "Epoch 1272: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4910 - accuracy: 0.8618 - val_loss: 0.4198 - val_accuracy: 0.8890\n",
            "Epoch 1273/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5037 - accuracy: 0.8648\n",
            "Epoch 1273: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8650 - val_loss: 0.4200 - val_accuracy: 0.8833\n",
            "Epoch 1274/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4639 - accuracy: 0.8682\n",
            "Epoch 1274: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4638 - accuracy: 0.8677 - val_loss: 0.4521 - val_accuracy: 0.8844\n",
            "Epoch 1275/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5190 - accuracy: 0.8653\n",
            "Epoch 1275: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5153 - accuracy: 0.8651 - val_loss: 0.4334 - val_accuracy: 0.8856\n",
            "Epoch 1276/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5489 - accuracy: 0.8568\n",
            "Epoch 1276: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5455 - accuracy: 0.8578 - val_loss: 0.4369 - val_accuracy: 0.8833\n",
            "Epoch 1277/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4956 - accuracy: 0.8600\n",
            "Epoch 1277: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5071 - accuracy: 0.8588 - val_loss: 0.4411 - val_accuracy: 0.8799\n",
            "Epoch 1278/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5047 - accuracy: 0.8601\n",
            "Epoch 1278: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.8601 - val_loss: 0.4183 - val_accuracy: 0.8890\n",
            "Epoch 1279/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4871 - accuracy: 0.8666\n",
            "Epoch 1279: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.8660 - val_loss: 0.4064 - val_accuracy: 0.8913\n",
            "Epoch 1280/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5031 - accuracy: 0.8565\n",
            "Epoch 1280: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.8560 - val_loss: 0.4366 - val_accuracy: 0.8982\n",
            "Epoch 1281/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5327 - accuracy: 0.8636\n",
            "Epoch 1281: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5335 - accuracy: 0.8639 - val_loss: 0.4661 - val_accuracy: 0.8810\n",
            "Epoch 1282/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4952 - accuracy: 0.8613\n",
            "Epoch 1282: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4952 - accuracy: 0.8613 - val_loss: 0.4209 - val_accuracy: 0.8913\n",
            "Epoch 1283/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4836 - accuracy: 0.8683\n",
            "Epoch 1283: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4836 - accuracy: 0.8683 - val_loss: 0.4242 - val_accuracy: 0.8867\n",
            "Epoch 1284/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4545 - accuracy: 0.8694\n",
            "Epoch 1284: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4581 - accuracy: 0.8686 - val_loss: 0.4096 - val_accuracy: 0.8947\n",
            "Epoch 1285/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4751 - accuracy: 0.8638\n",
            "Epoch 1285: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4791 - accuracy: 0.8634 - val_loss: 0.4127 - val_accuracy: 0.8902\n",
            "Epoch 1286/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4364 - accuracy: 0.8743\n",
            "Epoch 1286: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4404 - accuracy: 0.8730 - val_loss: 0.4208 - val_accuracy: 0.8913\n",
            "Epoch 1287/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4685 - accuracy: 0.8696\n",
            "Epoch 1287: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4676 - accuracy: 0.8699 - val_loss: 0.4309 - val_accuracy: 0.8936\n",
            "Epoch 1288/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5079 - accuracy: 0.8656\n",
            "Epoch 1288: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5115 - accuracy: 0.8657 - val_loss: 0.4398 - val_accuracy: 0.8787\n",
            "Epoch 1289/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4637 - accuracy: 0.8730\n",
            "Epoch 1289: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4653 - accuracy: 0.8729 - val_loss: 0.4215 - val_accuracy: 0.8970\n",
            "Epoch 1290/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5511 - accuracy: 0.8627\n",
            "Epoch 1290: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5439 - accuracy: 0.8631 - val_loss: 0.3929 - val_accuracy: 0.8913\n",
            "Epoch 1291/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4901 - accuracy: 0.8688\n",
            "Epoch 1291: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4895 - accuracy: 0.8687 - val_loss: 0.4177 - val_accuracy: 0.8799\n",
            "Epoch 1292/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4960 - accuracy: 0.8668\n",
            "Epoch 1292: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 0.8669 - val_loss: 0.4281 - val_accuracy: 0.8730\n",
            "Epoch 1293/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5033 - accuracy: 0.8660\n",
            "Epoch 1293: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5094 - accuracy: 0.8649 - val_loss: 0.4380 - val_accuracy: 0.8707\n",
            "Epoch 1294/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4997 - accuracy: 0.8611\n",
            "Epoch 1294: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8600 - val_loss: 0.4842 - val_accuracy: 0.8638\n",
            "Epoch 1295/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4810 - accuracy: 0.8637\n",
            "Epoch 1295: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.8639 - val_loss: 0.4247 - val_accuracy: 0.8822\n",
            "Epoch 1296/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4754 - accuracy: 0.8704\n",
            "Epoch 1296: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4741 - accuracy: 0.8710 - val_loss: 0.4405 - val_accuracy: 0.8741\n",
            "Epoch 1297/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5158 - accuracy: 0.8584\n",
            "Epoch 1297: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5220 - accuracy: 0.8564 - val_loss: 0.4463 - val_accuracy: 0.8707\n",
            "Epoch 1298/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4804 - accuracy: 0.8690\n",
            "Epoch 1298: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4773 - accuracy: 0.8696 - val_loss: 0.4215 - val_accuracy: 0.8844\n",
            "Epoch 1299/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5086 - accuracy: 0.8643\n",
            "Epoch 1299: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5059 - accuracy: 0.8650 - val_loss: 0.4355 - val_accuracy: 0.8890\n",
            "Epoch 1300/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4532 - accuracy: 0.8755\n",
            "Epoch 1300: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4538 - accuracy: 0.8744 - val_loss: 0.4161 - val_accuracy: 0.8867\n",
            "Epoch 1301/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5298 - accuracy: 0.8578\n",
            "Epoch 1301: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5295 - accuracy: 0.8571 - val_loss: 0.4305 - val_accuracy: 0.8799\n",
            "Epoch 1302/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5031 - accuracy: 0.8627\n",
            "Epoch 1302: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5028 - accuracy: 0.8627 - val_loss: 0.4214 - val_accuracy: 0.8879\n",
            "Epoch 1303/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4371 - accuracy: 0.8770\n",
            "Epoch 1303: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4360 - accuracy: 0.8770 - val_loss: 0.4394 - val_accuracy: 0.8867\n",
            "Epoch 1304/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4843 - accuracy: 0.8659\n",
            "Epoch 1304: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4845 - accuracy: 0.8659 - val_loss: 0.4431 - val_accuracy: 0.8890\n",
            "Epoch 1305/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8674\n",
            "Epoch 1305: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.8681 - val_loss: 0.4611 - val_accuracy: 0.8822\n",
            "Epoch 1306/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4730 - accuracy: 0.8686\n",
            "Epoch 1306: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4762 - accuracy: 0.8687 - val_loss: 0.4629 - val_accuracy: 0.8730\n",
            "Epoch 1307/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5292 - accuracy: 0.8608\n",
            "Epoch 1307: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5244 - accuracy: 0.8617 - val_loss: 0.4521 - val_accuracy: 0.8787\n",
            "Epoch 1308/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4844 - accuracy: 0.8689\n",
            "Epoch 1308: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.8700 - val_loss: 0.4507 - val_accuracy: 0.8799\n",
            "Epoch 1309/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4847 - accuracy: 0.8594\n",
            "Epoch 1309: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.8618 - val_loss: 0.4525 - val_accuracy: 0.8856\n",
            "Epoch 1310/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4834 - accuracy: 0.8665\n",
            "Epoch 1310: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.8664 - val_loss: 0.4260 - val_accuracy: 0.8970\n",
            "Epoch 1311/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4925 - accuracy: 0.8655\n",
            "Epoch 1311: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4905 - accuracy: 0.8663 - val_loss: 0.4177 - val_accuracy: 0.8879\n",
            "Epoch 1312/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4578 - accuracy: 0.8729\n",
            "Epoch 1312: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4551 - accuracy: 0.8737 - val_loss: 0.4328 - val_accuracy: 0.8902\n",
            "Epoch 1313/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4892 - accuracy: 0.8680\n",
            "Epoch 1313: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4852 - accuracy: 0.8681 - val_loss: 0.4389 - val_accuracy: 0.8890\n",
            "Epoch 1314/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4510 - accuracy: 0.8679\n",
            "Epoch 1314: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4514 - accuracy: 0.8679 - val_loss: 0.4216 - val_accuracy: 0.8879\n",
            "Epoch 1315/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5695 - accuracy: 0.8682\n",
            "Epoch 1315: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5622 - accuracy: 0.8679 - val_loss: 0.4416 - val_accuracy: 0.8753\n",
            "Epoch 1316/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5076 - accuracy: 0.8586\n",
            "Epoch 1316: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.8581 - val_loss: 0.4423 - val_accuracy: 0.8799\n",
            "Epoch 1317/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4839 - accuracy: 0.8618\n",
            "Epoch 1317: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4835 - accuracy: 0.8614 - val_loss: 0.4532 - val_accuracy: 0.8741\n",
            "Epoch 1318/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4876 - accuracy: 0.8629\n",
            "Epoch 1318: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4929 - accuracy: 0.8620 - val_loss: 0.4188 - val_accuracy: 0.8867\n",
            "Epoch 1319/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5097 - accuracy: 0.8567\n",
            "Epoch 1319: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5108 - accuracy: 0.8561 - val_loss: 0.4198 - val_accuracy: 0.8810\n",
            "Epoch 1320/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4784 - accuracy: 0.8714\n",
            "Epoch 1320: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.8720 - val_loss: 0.3940 - val_accuracy: 0.8970\n",
            "Epoch 1321/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5050 - accuracy: 0.8641\n",
            "Epoch 1321: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5059 - accuracy: 0.8631 - val_loss: 0.4414 - val_accuracy: 0.8787\n",
            "Epoch 1322/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5050 - accuracy: 0.8586\n",
            "Epoch 1322: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5214 - accuracy: 0.8576 - val_loss: 0.4202 - val_accuracy: 0.8822\n",
            "Epoch 1323/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5120 - accuracy: 0.8596\n",
            "Epoch 1323: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5091 - accuracy: 0.8593 - val_loss: 0.4269 - val_accuracy: 0.8787\n",
            "Epoch 1324/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4934 - accuracy: 0.8625\n",
            "Epoch 1324: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4882 - accuracy: 0.8634 - val_loss: 0.4486 - val_accuracy: 0.8730\n",
            "Epoch 1325/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5397 - accuracy: 0.8602\n",
            "Epoch 1325: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.8623 - val_loss: 0.4301 - val_accuracy: 0.8856\n",
            "Epoch 1326/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4898 - accuracy: 0.8642\n",
            "Epoch 1326: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4878 - accuracy: 0.8641 - val_loss: 0.4475 - val_accuracy: 0.8799\n",
            "Epoch 1327/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5016 - accuracy: 0.8606\n",
            "Epoch 1327: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5012 - accuracy: 0.8607 - val_loss: 0.4398 - val_accuracy: 0.8776\n",
            "Epoch 1328/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5767 - accuracy: 0.8508\n",
            "Epoch 1328: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5848 - accuracy: 0.8508 - val_loss: 0.4362 - val_accuracy: 0.8764\n",
            "Epoch 1329/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5620 - accuracy: 0.8615\n",
            "Epoch 1329: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5644 - accuracy: 0.8603 - val_loss: 0.4095 - val_accuracy: 0.8844\n",
            "Epoch 1330/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5223 - accuracy: 0.8609\n",
            "Epoch 1330: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.8616 - val_loss: 0.4222 - val_accuracy: 0.8902\n",
            "Epoch 1331/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4948 - accuracy: 0.8656\n",
            "Epoch 1331: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5002 - accuracy: 0.8651 - val_loss: 0.4250 - val_accuracy: 0.8799\n",
            "Epoch 1332/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4962 - accuracy: 0.8639\n",
            "Epoch 1332: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4931 - accuracy: 0.8653 - val_loss: 0.4087 - val_accuracy: 0.8856\n",
            "Epoch 1333/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5112 - accuracy: 0.8623\n",
            "Epoch 1333: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5118 - accuracy: 0.8621 - val_loss: 0.4509 - val_accuracy: 0.8787\n",
            "Epoch 1334/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4782 - accuracy: 0.8646\n",
            "Epoch 1334: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8640 - val_loss: 0.4388 - val_accuracy: 0.8799\n",
            "Epoch 1335/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4918 - accuracy: 0.8581\n",
            "Epoch 1335: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4915 - accuracy: 0.8583 - val_loss: 0.4615 - val_accuracy: 0.8684\n",
            "Epoch 1336/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5089 - accuracy: 0.8609\n",
            "Epoch 1336: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5138 - accuracy: 0.8597 - val_loss: 0.4303 - val_accuracy: 0.8822\n",
            "Epoch 1337/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5160 - accuracy: 0.8670\n",
            "Epoch 1337: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5122 - accuracy: 0.8674 - val_loss: 0.3944 - val_accuracy: 0.8799\n",
            "Epoch 1338/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5461 - accuracy: 0.8629\n",
            "Epoch 1338: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5477 - accuracy: 0.8626 - val_loss: 0.4101 - val_accuracy: 0.8787\n",
            "Epoch 1339/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4943 - accuracy: 0.8611\n",
            "Epoch 1339: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 0.8606 - val_loss: 0.4382 - val_accuracy: 0.8799\n",
            "Epoch 1340/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4855 - accuracy: 0.8651\n",
            "Epoch 1340: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.8651 - val_loss: 0.4168 - val_accuracy: 0.8879\n",
            "Epoch 1341/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4866 - accuracy: 0.8612\n",
            "Epoch 1341: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4867 - accuracy: 0.8610 - val_loss: 0.4125 - val_accuracy: 0.8867\n",
            "Epoch 1342/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5425 - accuracy: 0.8508\n",
            "Epoch 1342: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5435 - accuracy: 0.8520 - val_loss: 0.4416 - val_accuracy: 0.8753\n",
            "Epoch 1343/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5462 - accuracy: 0.8520\n",
            "Epoch 1343: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5462 - accuracy: 0.8520 - val_loss: 0.4321 - val_accuracy: 0.8753\n",
            "Epoch 1344/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4993 - accuracy: 0.8610\n",
            "Epoch 1344: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5007 - accuracy: 0.8608 - val_loss: 0.4174 - val_accuracy: 0.8833\n",
            "Epoch 1345/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4825 - accuracy: 0.8702\n",
            "Epoch 1345: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.8704 - val_loss: 0.4381 - val_accuracy: 0.8810\n",
            "Epoch 1346/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4912 - accuracy: 0.8656\n",
            "Epoch 1346: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4925 - accuracy: 0.8656 - val_loss: 0.3941 - val_accuracy: 0.8822\n",
            "Epoch 1347/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4878 - accuracy: 0.8665\n",
            "Epoch 1347: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4897 - accuracy: 0.8661 - val_loss: 0.4038 - val_accuracy: 0.8856\n",
            "Epoch 1348/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4880 - accuracy: 0.8652\n",
            "Epoch 1348: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4905 - accuracy: 0.8647 - val_loss: 0.4130 - val_accuracy: 0.8844\n",
            "Epoch 1349/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5142 - accuracy: 0.8583\n",
            "Epoch 1349: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5072 - accuracy: 0.8597 - val_loss: 0.4226 - val_accuracy: 0.8867\n",
            "Epoch 1350/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.8606\n",
            "Epoch 1350: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4970 - accuracy: 0.8604 - val_loss: 0.4049 - val_accuracy: 0.8787\n",
            "Epoch 1351/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4535 - accuracy: 0.8732\n",
            "Epoch 1351: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.8714 - val_loss: 0.4016 - val_accuracy: 0.8867\n",
            "Epoch 1352/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4868 - accuracy: 0.8626\n",
            "Epoch 1352: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4852 - accuracy: 0.8633 - val_loss: 0.4173 - val_accuracy: 0.8879\n",
            "Epoch 1353/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4739 - accuracy: 0.8678\n",
            "Epoch 1353: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.8681 - val_loss: 0.4334 - val_accuracy: 0.8799\n",
            "Epoch 1354/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4752 - accuracy: 0.8696\n",
            "Epoch 1354: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.8687 - val_loss: 0.4185 - val_accuracy: 0.8867\n",
            "Epoch 1355/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5138 - accuracy: 0.8635\n",
            "Epoch 1355: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5075 - accuracy: 0.8633 - val_loss: 0.4444 - val_accuracy: 0.8822\n",
            "Epoch 1356/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5020 - accuracy: 0.8683\n",
            "Epoch 1356: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5011 - accuracy: 0.8673 - val_loss: 0.4178 - val_accuracy: 0.8879\n",
            "Epoch 1357/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4604 - accuracy: 0.8655\n",
            "Epoch 1357: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4614 - accuracy: 0.8640 - val_loss: 0.4691 - val_accuracy: 0.8856\n",
            "Epoch 1358/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.8583\n",
            "Epoch 1358: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.8584 - val_loss: 0.4469 - val_accuracy: 0.8822\n",
            "Epoch 1359/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4817 - accuracy: 0.8624\n",
            "Epoch 1359: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.8626 - val_loss: 0.4269 - val_accuracy: 0.8936\n",
            "Epoch 1360/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4695 - accuracy: 0.8659\n",
            "Epoch 1360: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4699 - accuracy: 0.8656 - val_loss: 0.4252 - val_accuracy: 0.8856\n",
            "Epoch 1361/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4875 - accuracy: 0.8664\n",
            "Epoch 1361: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4858 - accuracy: 0.8660 - val_loss: 0.4199 - val_accuracy: 0.8799\n",
            "Epoch 1362/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4812 - accuracy: 0.8667\n",
            "Epoch 1362: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4832 - accuracy: 0.8651 - val_loss: 0.4122 - val_accuracy: 0.8787\n",
            "Epoch 1363/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5154 - accuracy: 0.8599\n",
            "Epoch 1363: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.8588 - val_loss: 0.4419 - val_accuracy: 0.8924\n",
            "Epoch 1364/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5017 - accuracy: 0.8672\n",
            "Epoch 1364: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5000 - accuracy: 0.8670 - val_loss: 0.4562 - val_accuracy: 0.8856\n",
            "Epoch 1365/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4760 - accuracy: 0.8659\n",
            "Epoch 1365: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.8659 - val_loss: 0.4241 - val_accuracy: 0.8844\n",
            "Epoch 1366/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4873 - accuracy: 0.8640\n",
            "Epoch 1366: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.8651 - val_loss: 0.4193 - val_accuracy: 0.8867\n",
            "Epoch 1367/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5415 - accuracy: 0.8673\n",
            "Epoch 1367: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5303 - accuracy: 0.8679 - val_loss: 0.4325 - val_accuracy: 0.8753\n",
            "Epoch 1368/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5018 - accuracy: 0.8584\n",
            "Epoch 1368: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5006 - accuracy: 0.8586 - val_loss: 0.4411 - val_accuracy: 0.8810\n",
            "Epoch 1369/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4879 - accuracy: 0.8615\n",
            "Epoch 1369: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4918 - accuracy: 0.8608 - val_loss: 0.4517 - val_accuracy: 0.8810\n",
            "Epoch 1370/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5203 - accuracy: 0.8581\n",
            "Epoch 1370: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5186 - accuracy: 0.8584 - val_loss: 0.4077 - val_accuracy: 0.8890\n",
            "Epoch 1371/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5072 - accuracy: 0.8578\n",
            "Epoch 1371: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5068 - accuracy: 0.8580 - val_loss: 0.4413 - val_accuracy: 0.8799\n",
            "Epoch 1372/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4662 - accuracy: 0.8727\n",
            "Epoch 1372: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4690 - accuracy: 0.8720 - val_loss: 0.4367 - val_accuracy: 0.8844\n",
            "Epoch 1373/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4754 - accuracy: 0.8708\n",
            "Epoch 1373: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4755 - accuracy: 0.8704 - val_loss: 0.4192 - val_accuracy: 0.8867\n",
            "Epoch 1374/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.5211 - accuracy: 0.8623\n",
            "Epoch 1374: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5276 - accuracy: 0.8621 - val_loss: 0.4340 - val_accuracy: 0.8879\n",
            "Epoch 1375/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5208 - accuracy: 0.8553\n",
            "Epoch 1375: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.8554 - val_loss: 0.4609 - val_accuracy: 0.8741\n",
            "Epoch 1376/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4671 - accuracy: 0.8728\n",
            "Epoch 1376: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.8720 - val_loss: 0.4104 - val_accuracy: 0.8844\n",
            "Epoch 1377/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5294 - accuracy: 0.8560\n",
            "Epoch 1377: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5294 - accuracy: 0.8558 - val_loss: 0.4344 - val_accuracy: 0.8913\n",
            "Epoch 1378/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4859 - accuracy: 0.8685\n",
            "Epoch 1378: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.8676 - val_loss: 0.4113 - val_accuracy: 0.8902\n",
            "Epoch 1379/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5224 - accuracy: 0.8556\n",
            "Epoch 1379: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5186 - accuracy: 0.8560 - val_loss: 0.4291 - val_accuracy: 0.8776\n",
            "Epoch 1380/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5219 - accuracy: 0.8640\n",
            "Epoch 1380: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5285 - accuracy: 0.8623 - val_loss: 0.4318 - val_accuracy: 0.8867\n",
            "Epoch 1381/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4887 - accuracy: 0.8650\n",
            "Epoch 1381: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4885 - accuracy: 0.8651 - val_loss: 0.4162 - val_accuracy: 0.8902\n",
            "Epoch 1382/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5144 - accuracy: 0.8612\n",
            "Epoch 1382: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.8616 - val_loss: 0.4104 - val_accuracy: 0.8913\n",
            "Epoch 1383/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4503 - accuracy: 0.8705\n",
            "Epoch 1383: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4532 - accuracy: 0.8703 - val_loss: 0.4006 - val_accuracy: 0.8993\n",
            "Epoch 1384/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4947 - accuracy: 0.8670\n",
            "Epoch 1384: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4930 - accuracy: 0.8666 - val_loss: 0.4165 - val_accuracy: 0.8936\n",
            "Epoch 1385/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5020 - accuracy: 0.8674\n",
            "Epoch 1385: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4980 - accuracy: 0.8687 - val_loss: 0.3915 - val_accuracy: 0.8902\n",
            "Epoch 1386/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4577 - accuracy: 0.8669\n",
            "Epoch 1386: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4580 - accuracy: 0.8669 - val_loss: 0.4049 - val_accuracy: 0.8924\n",
            "Epoch 1387/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5100 - accuracy: 0.8607\n",
            "Epoch 1387: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5100 - accuracy: 0.8607 - val_loss: 0.4376 - val_accuracy: 0.8844\n",
            "Epoch 1388/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4971 - accuracy: 0.8644\n",
            "Epoch 1388: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.8644 - val_loss: 0.4310 - val_accuracy: 0.8822\n",
            "Epoch 1389/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4705 - accuracy: 0.8706\n",
            "Epoch 1389: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4668 - accuracy: 0.8703 - val_loss: 0.4156 - val_accuracy: 0.8833\n",
            "Epoch 1390/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4852 - accuracy: 0.8648\n",
            "Epoch 1390: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4795 - accuracy: 0.8667 - val_loss: 0.4180 - val_accuracy: 0.8867\n",
            "Epoch 1391/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4842 - accuracy: 0.8650\n",
            "Epoch 1391: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4871 - accuracy: 0.8649 - val_loss: 0.4176 - val_accuracy: 0.8902\n",
            "Epoch 1392/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8656\n",
            "Epoch 1392: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.8663 - val_loss: 0.4208 - val_accuracy: 0.8890\n",
            "Epoch 1393/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5172 - accuracy: 0.8609\n",
            "Epoch 1393: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5146 - accuracy: 0.8606 - val_loss: 0.4195 - val_accuracy: 0.8810\n",
            "Epoch 1394/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4990 - accuracy: 0.8632\n",
            "Epoch 1394: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4991 - accuracy: 0.8631 - val_loss: 0.4166 - val_accuracy: 0.8902\n",
            "Epoch 1395/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5734 - accuracy: 0.8548\n",
            "Epoch 1395: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5734 - accuracy: 0.8548 - val_loss: 0.4188 - val_accuracy: 0.8913\n",
            "Epoch 1396/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5018 - accuracy: 0.8695\n",
            "Epoch 1396: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5059 - accuracy: 0.8679 - val_loss: 0.4385 - val_accuracy: 0.8707\n",
            "Epoch 1397/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5704 - accuracy: 0.8555\n",
            "Epoch 1397: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5667 - accuracy: 0.8563 - val_loss: 0.4390 - val_accuracy: 0.8776\n",
            "Epoch 1398/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5054 - accuracy: 0.8597\n",
            "Epoch 1398: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5054 - accuracy: 0.8597 - val_loss: 0.4040 - val_accuracy: 0.8913\n",
            "Epoch 1399/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5027 - accuracy: 0.8723\n",
            "Epoch 1399: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5010 - accuracy: 0.8722 - val_loss: 0.4293 - val_accuracy: 0.8867\n",
            "Epoch 1400/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4825 - accuracy: 0.8673\n",
            "Epoch 1400: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4815 - accuracy: 0.8677 - val_loss: 0.4311 - val_accuracy: 0.8856\n",
            "Epoch 1401/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4979 - accuracy: 0.8619\n",
            "Epoch 1401: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8604 - val_loss: 0.4149 - val_accuracy: 0.8810\n",
            "Epoch 1402/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5036 - accuracy: 0.8663\n",
            "Epoch 1402: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8660 - val_loss: 0.4190 - val_accuracy: 0.8879\n",
            "Epoch 1403/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4911 - accuracy: 0.8662\n",
            "Epoch 1403: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4899 - accuracy: 0.8661 - val_loss: 0.3926 - val_accuracy: 0.8902\n",
            "Epoch 1404/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5431 - accuracy: 0.8559\n",
            "Epoch 1404: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5468 - accuracy: 0.8547 - val_loss: 0.4263 - val_accuracy: 0.8810\n",
            "Epoch 1405/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4775 - accuracy: 0.8715\n",
            "Epoch 1405: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.8724 - val_loss: 0.4047 - val_accuracy: 0.8867\n",
            "Epoch 1406/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5330 - accuracy: 0.8594\n",
            "Epoch 1406: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5370 - accuracy: 0.8583 - val_loss: 0.4320 - val_accuracy: 0.8810\n",
            "Epoch 1407/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5059 - accuracy: 0.8656\n",
            "Epoch 1407: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4941 - accuracy: 0.8683 - val_loss: 0.3997 - val_accuracy: 0.8833\n",
            "Epoch 1408/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5052 - accuracy: 0.8678\n",
            "Epoch 1408: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5022 - accuracy: 0.8681 - val_loss: 0.3865 - val_accuracy: 0.8867\n",
            "Epoch 1409/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5117 - accuracy: 0.8672\n",
            "Epoch 1409: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5062 - accuracy: 0.8679 - val_loss: 0.4215 - val_accuracy: 0.8741\n",
            "Epoch 1410/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5085 - accuracy: 0.8631\n",
            "Epoch 1410: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5041 - accuracy: 0.8649 - val_loss: 0.4180 - val_accuracy: 0.8799\n",
            "Epoch 1411/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4791 - accuracy: 0.8685\n",
            "Epoch 1411: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4867 - accuracy: 0.8673 - val_loss: 0.4202 - val_accuracy: 0.8867\n",
            "Epoch 1412/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4658 - accuracy: 0.8720\n",
            "Epoch 1412: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4636 - accuracy: 0.8727 - val_loss: 0.3919 - val_accuracy: 0.8936\n",
            "Epoch 1413/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5113 - accuracy: 0.8630\n",
            "Epoch 1413: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5156 - accuracy: 0.8621 - val_loss: 0.4335 - val_accuracy: 0.8696\n",
            "Epoch 1414/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4971 - accuracy: 0.8630\n",
            "Epoch 1414: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4956 - accuracy: 0.8636 - val_loss: 0.4064 - val_accuracy: 0.8822\n",
            "Epoch 1415/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4888 - accuracy: 0.8656\n",
            "Epoch 1415: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4886 - accuracy: 0.8651 - val_loss: 0.4209 - val_accuracy: 0.8776\n",
            "Epoch 1416/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4679 - accuracy: 0.8705\n",
            "Epoch 1416: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.8714 - val_loss: 0.4418 - val_accuracy: 0.8719\n",
            "Epoch 1417/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4866 - accuracy: 0.8670\n",
            "Epoch 1417: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5007 - accuracy: 0.8653 - val_loss: 0.4075 - val_accuracy: 0.8867\n",
            "Epoch 1418/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4892 - accuracy: 0.8616\n",
            "Epoch 1418: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4881 - accuracy: 0.8618 - val_loss: 0.4044 - val_accuracy: 0.8867\n",
            "Epoch 1419/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4849 - accuracy: 0.8624\n",
            "Epoch 1419: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4849 - accuracy: 0.8624 - val_loss: 0.4126 - val_accuracy: 0.8822\n",
            "Epoch 1420/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4812 - accuracy: 0.8691\n",
            "Epoch 1420: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4826 - accuracy: 0.8693 - val_loss: 0.4355 - val_accuracy: 0.8776\n",
            "Epoch 1421/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5449 - accuracy: 0.8543\n",
            "Epoch 1421: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5431 - accuracy: 0.8544 - val_loss: 0.4692 - val_accuracy: 0.8570\n",
            "Epoch 1422/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5619 - accuracy: 0.8466\n",
            "Epoch 1422: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5599 - accuracy: 0.8468 - val_loss: 0.4166 - val_accuracy: 0.8753\n",
            "Epoch 1423/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4706 - accuracy: 0.8702\n",
            "Epoch 1423: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4696 - accuracy: 0.8703 - val_loss: 0.4178 - val_accuracy: 0.8822\n",
            "Epoch 1424/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5099 - accuracy: 0.8627\n",
            "Epoch 1424: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5089 - accuracy: 0.8631 - val_loss: 0.4334 - val_accuracy: 0.8822\n",
            "Epoch 1425/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4515 - accuracy: 0.8691\n",
            "Epoch 1425: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4515 - accuracy: 0.8691 - val_loss: 0.4321 - val_accuracy: 0.8684\n",
            "Epoch 1426/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5000 - accuracy: 0.8653\n",
            "Epoch 1426: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5048 - accuracy: 0.8643 - val_loss: 0.4573 - val_accuracy: 0.8867\n",
            "Epoch 1427/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5133 - accuracy: 0.8597\n",
            "Epoch 1427: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5099 - accuracy: 0.8598 - val_loss: 0.4232 - val_accuracy: 0.8947\n",
            "Epoch 1428/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5001 - accuracy: 0.8652\n",
            "Epoch 1428: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4964 - accuracy: 0.8663 - val_loss: 0.4321 - val_accuracy: 0.8833\n",
            "Epoch 1429/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4902 - accuracy: 0.8632\n",
            "Epoch 1429: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4890 - accuracy: 0.8634 - val_loss: 0.4169 - val_accuracy: 0.8856\n",
            "Epoch 1430/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4926 - accuracy: 0.8653\n",
            "Epoch 1430: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.8637 - val_loss: 0.4540 - val_accuracy: 0.8856\n",
            "Epoch 1431/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4897 - accuracy: 0.8712\n",
            "Epoch 1431: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4897 - accuracy: 0.8714 - val_loss: 0.4083 - val_accuracy: 0.8890\n",
            "Epoch 1432/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5103 - accuracy: 0.8588\n",
            "Epoch 1432: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5140 - accuracy: 0.8578 - val_loss: 0.4280 - val_accuracy: 0.8764\n",
            "Epoch 1433/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5001 - accuracy: 0.8658\n",
            "Epoch 1433: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4979 - accuracy: 0.8657 - val_loss: 0.4249 - val_accuracy: 0.8764\n",
            "Epoch 1434/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5173 - accuracy: 0.8649\n",
            "Epoch 1434: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5173 - accuracy: 0.8649 - val_loss: 0.4185 - val_accuracy: 0.8856\n",
            "Epoch 1435/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4759 - accuracy: 0.8657\n",
            "Epoch 1435: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4797 - accuracy: 0.8646 - val_loss: 0.4559 - val_accuracy: 0.8810\n",
            "Epoch 1436/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4624 - accuracy: 0.8720\n",
            "Epoch 1436: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4577 - accuracy: 0.8726 - val_loss: 0.4247 - val_accuracy: 0.8810\n",
            "Epoch 1437/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4583 - accuracy: 0.8757\n",
            "Epoch 1437: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4583 - accuracy: 0.8757 - val_loss: 0.4461 - val_accuracy: 0.8776\n",
            "Epoch 1438/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4445 - accuracy: 0.8778\n",
            "Epoch 1438: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4415 - accuracy: 0.8783 - val_loss: 0.4441 - val_accuracy: 0.8810\n",
            "Epoch 1439/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4638 - accuracy: 0.8713\n",
            "Epoch 1439: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4640 - accuracy: 0.8712 - val_loss: 0.4256 - val_accuracy: 0.8753\n",
            "Epoch 1440/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4885 - accuracy: 0.8656\n",
            "Epoch 1440: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4914 - accuracy: 0.8647 - val_loss: 0.4115 - val_accuracy: 0.8867\n",
            "Epoch 1441/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5001 - accuracy: 0.8618\n",
            "Epoch 1441: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5009 - accuracy: 0.8614 - val_loss: 0.3984 - val_accuracy: 0.8936\n",
            "Epoch 1442/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5096 - accuracy: 0.8665\n",
            "Epoch 1442: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.8653 - val_loss: 0.4470 - val_accuracy: 0.8730\n",
            "Epoch 1443/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5139 - accuracy: 0.8623\n",
            "Epoch 1443: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5204 - accuracy: 0.8611 - val_loss: 0.4577 - val_accuracy: 0.8844\n",
            "Epoch 1444/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5000 - accuracy: 0.8669\n",
            "Epoch 1444: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4964 - accuracy: 0.8674 - val_loss: 0.4286 - val_accuracy: 0.8856\n",
            "Epoch 1445/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4644 - accuracy: 0.8693\n",
            "Epoch 1445: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.8674 - val_loss: 0.4508 - val_accuracy: 0.8741\n",
            "Epoch 1446/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4833 - accuracy: 0.8694\n",
            "Epoch 1446: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4851 - accuracy: 0.8680 - val_loss: 0.3949 - val_accuracy: 0.8776\n",
            "Epoch 1447/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5028 - accuracy: 0.8621\n",
            "Epoch 1447: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5062 - accuracy: 0.8627 - val_loss: 0.3993 - val_accuracy: 0.8902\n",
            "Epoch 1448/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4923 - accuracy: 0.8649\n",
            "Epoch 1448: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.8664 - val_loss: 0.4209 - val_accuracy: 0.8776\n",
            "Epoch 1449/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5535 - accuracy: 0.8670\n",
            "Epoch 1449: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5983 - accuracy: 0.8659 - val_loss: 0.4111 - val_accuracy: 0.8856\n",
            "Epoch 1450/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4885 - accuracy: 0.8713\n",
            "Epoch 1450: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4934 - accuracy: 0.8706 - val_loss: 0.3797 - val_accuracy: 0.8890\n",
            "Epoch 1451/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5213 - accuracy: 0.8648\n",
            "Epoch 1451: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5209 - accuracy: 0.8637 - val_loss: 0.4242 - val_accuracy: 0.8810\n",
            "Epoch 1452/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4942 - accuracy: 0.8635\n",
            "Epoch 1452: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.8643 - val_loss: 0.4401 - val_accuracy: 0.8799\n",
            "Epoch 1453/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5440 - accuracy: 0.8597\n",
            "Epoch 1453: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5443 - accuracy: 0.8597 - val_loss: 0.4179 - val_accuracy: 0.8879\n",
            "Epoch 1454/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5383 - accuracy: 0.8603\n",
            "Epoch 1454: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5327 - accuracy: 0.8593 - val_loss: 0.4242 - val_accuracy: 0.8787\n",
            "Epoch 1455/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5014 - accuracy: 0.8633\n",
            "Epoch 1455: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5013 - accuracy: 0.8626 - val_loss: 0.4176 - val_accuracy: 0.8787\n",
            "Epoch 1456/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4988 - accuracy: 0.8606\n",
            "Epoch 1456: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4986 - accuracy: 0.8601 - val_loss: 0.3963 - val_accuracy: 0.8890\n",
            "Epoch 1457/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5119 - accuracy: 0.8666\n",
            "Epoch 1457: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5120 - accuracy: 0.8661 - val_loss: 0.4100 - val_accuracy: 0.8844\n",
            "Epoch 1458/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4682 - accuracy: 0.8738\n",
            "Epoch 1458: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.8742 - val_loss: 0.3961 - val_accuracy: 0.8856\n",
            "Epoch 1459/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4863 - accuracy: 0.8673\n",
            "Epoch 1459: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4873 - accuracy: 0.8669 - val_loss: 0.4259 - val_accuracy: 0.8902\n",
            "Epoch 1460/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4863 - accuracy: 0.8671\n",
            "Epoch 1460: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.8693 - val_loss: 0.4199 - val_accuracy: 0.8844\n",
            "Epoch 1461/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.8784\n",
            "Epoch 1461: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4611 - accuracy: 0.8783 - val_loss: 0.4217 - val_accuracy: 0.8810\n",
            "Epoch 1462/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5106 - accuracy: 0.8623\n",
            "Epoch 1462: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5072 - accuracy: 0.8630 - val_loss: 0.4266 - val_accuracy: 0.8924\n",
            "Epoch 1463/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4605 - accuracy: 0.8727\n",
            "Epoch 1463: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4518 - accuracy: 0.8747 - val_loss: 0.4349 - val_accuracy: 0.8799\n",
            "Epoch 1464/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5286 - accuracy: 0.8587\n",
            "Epoch 1464: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5287 - accuracy: 0.8580 - val_loss: 0.4130 - val_accuracy: 0.8822\n",
            "Epoch 1465/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4999 - accuracy: 0.8648\n",
            "Epoch 1465: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4987 - accuracy: 0.8667 - val_loss: 0.4115 - val_accuracy: 0.8833\n",
            "Epoch 1466/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4791 - accuracy: 0.8669\n",
            "Epoch 1466: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4776 - accuracy: 0.8666 - val_loss: 0.4181 - val_accuracy: 0.8890\n",
            "Epoch 1467/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4724 - accuracy: 0.8719\n",
            "Epoch 1467: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.8702 - val_loss: 0.3969 - val_accuracy: 0.8764\n",
            "Epoch 1468/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5144 - accuracy: 0.8594\n",
            "Epoch 1468: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5168 - accuracy: 0.8610 - val_loss: 0.4381 - val_accuracy: 0.8833\n",
            "Epoch 1469/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4790 - accuracy: 0.8661\n",
            "Epoch 1469: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.8666 - val_loss: 0.4214 - val_accuracy: 0.8799\n",
            "Epoch 1470/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4953 - accuracy: 0.8645\n",
            "Epoch 1470: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4965 - accuracy: 0.8644 - val_loss: 0.4154 - val_accuracy: 0.8867\n",
            "Epoch 1471/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4377 - accuracy: 0.8757\n",
            "Epoch 1471: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4377 - accuracy: 0.8757 - val_loss: 0.3959 - val_accuracy: 0.8867\n",
            "Epoch 1472/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5138 - accuracy: 0.8662\n",
            "Epoch 1472: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5112 - accuracy: 0.8667 - val_loss: 0.3960 - val_accuracy: 0.8936\n",
            "Epoch 1473/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5217 - accuracy: 0.8632\n",
            "Epoch 1473: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5225 - accuracy: 0.8620 - val_loss: 0.4295 - val_accuracy: 0.8787\n",
            "Epoch 1474/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4869 - accuracy: 0.8676\n",
            "Epoch 1474: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4869 - accuracy: 0.8676 - val_loss: 0.4091 - val_accuracy: 0.8902\n",
            "Epoch 1475/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4901 - accuracy: 0.8623\n",
            "Epoch 1475: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4922 - accuracy: 0.8621 - val_loss: 0.4345 - val_accuracy: 0.8856\n",
            "Epoch 1476/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4705 - accuracy: 0.8706\n",
            "Epoch 1476: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4723 - accuracy: 0.8702 - val_loss: 0.4441 - val_accuracy: 0.8776\n",
            "Epoch 1477/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4960 - accuracy: 0.8654\n",
            "Epoch 1477: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.8653 - val_loss: 0.4096 - val_accuracy: 0.8833\n",
            "Epoch 1478/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4986 - accuracy: 0.8646\n",
            "Epoch 1478: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4986 - accuracy: 0.8646 - val_loss: 0.4596 - val_accuracy: 0.8764\n",
            "Epoch 1479/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4589 - accuracy: 0.8716\n",
            "Epoch 1479: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4644 - accuracy: 0.8704 - val_loss: 0.4183 - val_accuracy: 0.8844\n",
            "Epoch 1480/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4795 - accuracy: 0.8698\n",
            "Epoch 1480: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4755 - accuracy: 0.8713 - val_loss: 0.4070 - val_accuracy: 0.8867\n",
            "Epoch 1481/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4659 - accuracy: 0.8657\n",
            "Epoch 1481: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4671 - accuracy: 0.8646 - val_loss: 0.4107 - val_accuracy: 0.8856\n",
            "Epoch 1482/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5083 - accuracy: 0.8630\n",
            "Epoch 1482: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5083 - accuracy: 0.8630 - val_loss: 0.4701 - val_accuracy: 0.8810\n",
            "Epoch 1483/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5343 - accuracy: 0.8631\n",
            "Epoch 1483: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5307 - accuracy: 0.8626 - val_loss: 0.4547 - val_accuracy: 0.8833\n",
            "Epoch 1484/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4798 - accuracy: 0.8716\n",
            "Epoch 1484: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4799 - accuracy: 0.8713 - val_loss: 0.4332 - val_accuracy: 0.8799\n",
            "Epoch 1485/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5401 - accuracy: 0.8594\n",
            "Epoch 1485: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5362 - accuracy: 0.8600 - val_loss: 0.4110 - val_accuracy: 0.8902\n",
            "Epoch 1486/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4745 - accuracy: 0.8679\n",
            "Epoch 1486: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.8679 - val_loss: 0.4367 - val_accuracy: 0.8867\n",
            "Epoch 1487/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4993 - accuracy: 0.8673\n",
            "Epoch 1487: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4966 - accuracy: 0.8676 - val_loss: 0.4657 - val_accuracy: 0.8822\n",
            "Epoch 1488/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4763 - accuracy: 0.8722\n",
            "Epoch 1488: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4794 - accuracy: 0.8713 - val_loss: 0.4188 - val_accuracy: 0.8833\n",
            "Epoch 1489/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4528 - accuracy: 0.8704\n",
            "Epoch 1489: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4501 - accuracy: 0.8706 - val_loss: 0.4110 - val_accuracy: 0.8844\n",
            "Epoch 1490/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4925 - accuracy: 0.8665\n",
            "Epoch 1490: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4906 - accuracy: 0.8669 - val_loss: 0.4342 - val_accuracy: 0.8822\n",
            "Epoch 1491/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5335 - accuracy: 0.8612\n",
            "Epoch 1491: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5346 - accuracy: 0.8601 - val_loss: 0.4572 - val_accuracy: 0.8753\n",
            "Epoch 1492/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5048 - accuracy: 0.8626\n",
            "Epoch 1492: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5072 - accuracy: 0.8613 - val_loss: 0.4335 - val_accuracy: 0.8684\n",
            "Epoch 1493/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4950 - accuracy: 0.8573\n",
            "Epoch 1493: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4927 - accuracy: 0.8587 - val_loss: 0.3915 - val_accuracy: 0.8844\n",
            "Epoch 1494/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4560 - accuracy: 0.8729\n",
            "Epoch 1494: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4550 - accuracy: 0.8732 - val_loss: 0.4015 - val_accuracy: 0.8844\n",
            "Epoch 1495/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4995 - accuracy: 0.8670\n",
            "Epoch 1495: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4953 - accuracy: 0.8674 - val_loss: 0.4123 - val_accuracy: 0.8924\n",
            "Epoch 1496/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4772 - accuracy: 0.8699\n",
            "Epoch 1496: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4770 - accuracy: 0.8696 - val_loss: 0.3974 - val_accuracy: 0.8913\n",
            "Epoch 1497/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4859 - accuracy: 0.8685\n",
            "Epoch 1497: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4830 - accuracy: 0.8677 - val_loss: 0.4065 - val_accuracy: 0.8879\n",
            "Epoch 1498/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5014 - accuracy: 0.8650\n",
            "Epoch 1498: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5017 - accuracy: 0.8637 - val_loss: 0.4208 - val_accuracy: 0.8799\n",
            "Epoch 1499/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4913 - accuracy: 0.8657\n",
            "Epoch 1499: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4949 - accuracy: 0.8651 - val_loss: 0.4169 - val_accuracy: 0.8890\n",
            "Epoch 1500/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5133 - accuracy: 0.8625\n",
            "Epoch 1500: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5077 - accuracy: 0.8641 - val_loss: 0.4330 - val_accuracy: 0.8822\n",
            "Epoch 1501/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4394 - accuracy: 0.8708\n",
            "Epoch 1501: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4394 - accuracy: 0.8707 - val_loss: 0.4197 - val_accuracy: 0.8879\n",
            "Epoch 1502/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4845 - accuracy: 0.8698\n",
            "Epoch 1502: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4840 - accuracy: 0.8697 - val_loss: 0.4060 - val_accuracy: 0.8764\n",
            "Epoch 1503/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.6179 - accuracy: 0.8613\n",
            "Epoch 1503: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.6179 - accuracy: 0.8613 - val_loss: 0.3962 - val_accuracy: 0.8867\n",
            "Epoch 1504/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4781 - accuracy: 0.8735\n",
            "Epoch 1504: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.8740 - val_loss: 0.4032 - val_accuracy: 0.8902\n",
            "Epoch 1505/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4871 - accuracy: 0.8695\n",
            "Epoch 1505: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4870 - accuracy: 0.8694 - val_loss: 0.4417 - val_accuracy: 0.8856\n",
            "Epoch 1506/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5431 - accuracy: 0.8629\n",
            "Epoch 1506: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5436 - accuracy: 0.8640 - val_loss: 0.4454 - val_accuracy: 0.8867\n",
            "Epoch 1507/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4765 - accuracy: 0.8647\n",
            "Epoch 1507: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4792 - accuracy: 0.8639 - val_loss: 0.4069 - val_accuracy: 0.8844\n",
            "Epoch 1508/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4854 - accuracy: 0.8669\n",
            "Epoch 1508: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4820 - accuracy: 0.8674 - val_loss: 0.4350 - val_accuracy: 0.8822\n",
            "Epoch 1509/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4918 - accuracy: 0.8697\n",
            "Epoch 1509: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4915 - accuracy: 0.8703 - val_loss: 0.4125 - val_accuracy: 0.8810\n",
            "Epoch 1510/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5296 - accuracy: 0.8681\n",
            "Epoch 1510: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5299 - accuracy: 0.8679 - val_loss: 0.4103 - val_accuracy: 0.8776\n",
            "Epoch 1511/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.8653\n",
            "Epoch 1511: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4991 - accuracy: 0.8653 - val_loss: 0.4032 - val_accuracy: 0.8867\n",
            "Epoch 1512/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5013 - accuracy: 0.8625\n",
            "Epoch 1512: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4980 - accuracy: 0.8636 - val_loss: 0.3867 - val_accuracy: 0.8890\n",
            "Epoch 1513/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4717 - accuracy: 0.8665\n",
            "Epoch 1513: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4710 - accuracy: 0.8666 - val_loss: 0.4100 - val_accuracy: 0.8776\n",
            "Epoch 1514/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4883 - accuracy: 0.8629\n",
            "Epoch 1514: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4992 - accuracy: 0.8618 - val_loss: 0.3915 - val_accuracy: 0.8867\n",
            "Epoch 1515/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4898 - accuracy: 0.8686\n",
            "Epoch 1515: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4892 - accuracy: 0.8687 - val_loss: 0.4123 - val_accuracy: 0.8799\n",
            "Epoch 1516/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4842 - accuracy: 0.8612\n",
            "Epoch 1516: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4856 - accuracy: 0.8608 - val_loss: 0.4020 - val_accuracy: 0.8799\n",
            "Epoch 1517/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5424 - accuracy: 0.8540\n",
            "Epoch 1517: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5681 - accuracy: 0.8528 - val_loss: 0.4284 - val_accuracy: 0.8673\n",
            "Epoch 1518/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.6069 - accuracy: 0.8521\n",
            "Epoch 1518: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.6049 - accuracy: 0.8525 - val_loss: 0.4571 - val_accuracy: 0.8638\n",
            "Epoch 1519/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5498 - accuracy: 0.8521\n",
            "Epoch 1519: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5465 - accuracy: 0.8525 - val_loss: 0.4613 - val_accuracy: 0.8741\n",
            "Epoch 1520/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5500 - accuracy: 0.8543\n",
            "Epoch 1520: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5445 - accuracy: 0.8560 - val_loss: 0.4341 - val_accuracy: 0.8856\n",
            "Epoch 1521/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4548 - accuracy: 0.8744\n",
            "Epoch 1521: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4542 - accuracy: 0.8743 - val_loss: 0.4063 - val_accuracy: 0.8844\n",
            "Epoch 1522/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4364 - accuracy: 0.8701\n",
            "Epoch 1522: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4408 - accuracy: 0.8690 - val_loss: 0.4114 - val_accuracy: 0.8913\n",
            "Epoch 1523/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4972 - accuracy: 0.8638\n",
            "Epoch 1523: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4902 - accuracy: 0.8663 - val_loss: 0.4058 - val_accuracy: 0.8856\n",
            "Epoch 1524/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5144 - accuracy: 0.8594\n",
            "Epoch 1524: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5110 - accuracy: 0.8603 - val_loss: 0.4385 - val_accuracy: 0.8822\n",
            "Epoch 1525/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5164 - accuracy: 0.8700\n",
            "Epoch 1525: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5098 - accuracy: 0.8713 - val_loss: 0.4182 - val_accuracy: 0.8822\n",
            "Epoch 1526/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5102 - accuracy: 0.8669\n",
            "Epoch 1526: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5091 - accuracy: 0.8670 - val_loss: 0.4468 - val_accuracy: 0.8741\n",
            "Epoch 1527/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4899 - accuracy: 0.8591\n",
            "Epoch 1527: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4977 - accuracy: 0.8593 - val_loss: 0.4338 - val_accuracy: 0.8822\n",
            "Epoch 1528/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4681 - accuracy: 0.8767\n",
            "Epoch 1528: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4651 - accuracy: 0.8792 - val_loss: 0.4025 - val_accuracy: 0.8890\n",
            "Epoch 1529/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5126 - accuracy: 0.8688\n",
            "Epoch 1529: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5160 - accuracy: 0.8677 - val_loss: 0.4269 - val_accuracy: 0.8867\n",
            "Epoch 1530/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4872 - accuracy: 0.8647\n",
            "Epoch 1530: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4843 - accuracy: 0.8657 - val_loss: 0.4048 - val_accuracy: 0.8787\n",
            "Epoch 1531/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4899 - accuracy: 0.8631\n",
            "Epoch 1531: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.8636 - val_loss: 0.4101 - val_accuracy: 0.8844\n",
            "Epoch 1532/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.8716\n",
            "Epoch 1532: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.8710 - val_loss: 0.4174 - val_accuracy: 0.8673\n",
            "Epoch 1533/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5152 - accuracy: 0.8647\n",
            "Epoch 1533: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5183 - accuracy: 0.8647 - val_loss: 0.4648 - val_accuracy: 0.8719\n",
            "Epoch 1534/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4859 - accuracy: 0.8679\n",
            "Epoch 1534: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4859 - accuracy: 0.8679 - val_loss: 0.4262 - val_accuracy: 0.8764\n",
            "Epoch 1535/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4948 - accuracy: 0.8641\n",
            "Epoch 1535: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4926 - accuracy: 0.8649 - val_loss: 0.4389 - val_accuracy: 0.8867\n",
            "Epoch 1536/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5137 - accuracy: 0.8572\n",
            "Epoch 1536: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5154 - accuracy: 0.8570 - val_loss: 0.4128 - val_accuracy: 0.8822\n",
            "Epoch 1537/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4821 - accuracy: 0.8778\n",
            "Epoch 1537: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4736 - accuracy: 0.8786 - val_loss: 0.3960 - val_accuracy: 0.8833\n",
            "Epoch 1538/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4878 - accuracy: 0.8704\n",
            "Epoch 1538: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4822 - accuracy: 0.8716 - val_loss: 0.4080 - val_accuracy: 0.8844\n",
            "Epoch 1539/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4731 - accuracy: 0.8682\n",
            "Epoch 1539: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.8679 - val_loss: 0.4232 - val_accuracy: 0.8856\n",
            "Epoch 1540/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5159 - accuracy: 0.8650\n",
            "Epoch 1540: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5174 - accuracy: 0.8634 - val_loss: 0.4288 - val_accuracy: 0.8650\n",
            "Epoch 1541/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5123 - accuracy: 0.8632\n",
            "Epoch 1541: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5083 - accuracy: 0.8637 - val_loss: 0.4239 - val_accuracy: 0.8844\n",
            "Epoch 1542/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4791 - accuracy: 0.8704\n",
            "Epoch 1542: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4819 - accuracy: 0.8694 - val_loss: 0.4194 - val_accuracy: 0.8764\n",
            "Epoch 1543/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4780 - accuracy: 0.8697\n",
            "Epoch 1543: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.8697 - val_loss: 0.4057 - val_accuracy: 0.8867\n",
            "Epoch 1544/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4787 - accuracy: 0.8707\n",
            "Epoch 1544: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.8686 - val_loss: 0.4237 - val_accuracy: 0.8867\n",
            "Epoch 1545/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5122 - accuracy: 0.8690\n",
            "Epoch 1545: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5066 - accuracy: 0.8694 - val_loss: 0.4032 - val_accuracy: 0.8879\n",
            "Epoch 1546/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4811 - accuracy: 0.8696\n",
            "Epoch 1546: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4814 - accuracy: 0.8697 - val_loss: 0.4060 - val_accuracy: 0.8867\n",
            "Epoch 1547/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5115 - accuracy: 0.8644\n",
            "Epoch 1547: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5135 - accuracy: 0.8646 - val_loss: 0.4030 - val_accuracy: 0.8947\n",
            "Epoch 1548/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4976 - accuracy: 0.8639\n",
            "Epoch 1548: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4976 - accuracy: 0.8639 - val_loss: 0.4207 - val_accuracy: 0.8787\n",
            "Epoch 1549/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4572 - accuracy: 0.8722\n",
            "Epoch 1549: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4541 - accuracy: 0.8722 - val_loss: 0.4355 - val_accuracy: 0.8822\n",
            "Epoch 1550/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4998 - accuracy: 0.8653\n",
            "Epoch 1550: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.8657 - val_loss: 0.4151 - val_accuracy: 0.8810\n",
            "Epoch 1551/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5749 - accuracy: 0.8591\n",
            "Epoch 1551: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5767 - accuracy: 0.8581 - val_loss: 0.4301 - val_accuracy: 0.8810\n",
            "Epoch 1552/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5223 - accuracy: 0.8639\n",
            "Epoch 1552: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5239 - accuracy: 0.8626 - val_loss: 0.3983 - val_accuracy: 0.8867\n",
            "Epoch 1553/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4809 - accuracy: 0.8657\n",
            "Epoch 1553: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4838 - accuracy: 0.8656 - val_loss: 0.4293 - val_accuracy: 0.8810\n",
            "Epoch 1554/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.8739\n",
            "Epoch 1554: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4635 - accuracy: 0.8747 - val_loss: 0.4091 - val_accuracy: 0.8822\n",
            "Epoch 1555/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5558 - accuracy: 0.8644\n",
            "Epoch 1555: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5557 - accuracy: 0.8651 - val_loss: 0.4088 - val_accuracy: 0.8799\n",
            "Epoch 1556/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5231 - accuracy: 0.8603\n",
            "Epoch 1556: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5208 - accuracy: 0.8607 - val_loss: 0.4359 - val_accuracy: 0.8833\n",
            "Epoch 1557/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4717 - accuracy: 0.8631\n",
            "Epoch 1557: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4717 - accuracy: 0.8631 - val_loss: 0.4348 - val_accuracy: 0.8810\n",
            "Epoch 1558/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5415 - accuracy: 0.8593\n",
            "Epoch 1558: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5363 - accuracy: 0.8600 - val_loss: 0.4081 - val_accuracy: 0.8879\n",
            "Epoch 1559/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4935 - accuracy: 0.8636\n",
            "Epoch 1559: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4865 - accuracy: 0.8650 - val_loss: 0.4091 - val_accuracy: 0.8810\n",
            "Epoch 1560/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4671 - accuracy: 0.8689\n",
            "Epoch 1560: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4757 - accuracy: 0.8681 - val_loss: 0.4340 - val_accuracy: 0.8753\n",
            "Epoch 1561/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5117 - accuracy: 0.8672\n",
            "Epoch 1561: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5126 - accuracy: 0.8671 - val_loss: 0.4451 - val_accuracy: 0.8822\n",
            "Epoch 1562/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4845 - accuracy: 0.8659\n",
            "Epoch 1562: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.8657 - val_loss: 0.4494 - val_accuracy: 0.8822\n",
            "Epoch 1563/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4818 - accuracy: 0.8768\n",
            "Epoch 1563: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.8776 - val_loss: 0.4253 - val_accuracy: 0.8890\n",
            "Epoch 1564/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4862 - accuracy: 0.8694\n",
            "Epoch 1564: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4947 - accuracy: 0.8691 - val_loss: 0.4541 - val_accuracy: 0.8741\n",
            "Epoch 1565/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4779 - accuracy: 0.8636\n",
            "Epoch 1565: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4772 - accuracy: 0.8637 - val_loss: 0.4160 - val_accuracy: 0.8959\n",
            "Epoch 1566/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4947 - accuracy: 0.8622\n",
            "Epoch 1566: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.8614 - val_loss: 0.4430 - val_accuracy: 0.8753\n",
            "Epoch 1567/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4735 - accuracy: 0.8693\n",
            "Epoch 1567: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4768 - accuracy: 0.8703 - val_loss: 0.3866 - val_accuracy: 0.8913\n",
            "Epoch 1568/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4984 - accuracy: 0.8627\n",
            "Epoch 1568: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5051 - accuracy: 0.8610 - val_loss: 0.4119 - val_accuracy: 0.8867\n",
            "Epoch 1569/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4903 - accuracy: 0.8625\n",
            "Epoch 1569: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4937 - accuracy: 0.8636 - val_loss: 0.4033 - val_accuracy: 0.8879\n",
            "Epoch 1570/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4877 - accuracy: 0.8656\n",
            "Epoch 1570: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.8669 - val_loss: 0.3876 - val_accuracy: 0.8947\n",
            "Epoch 1571/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5042 - accuracy: 0.8678\n",
            "Epoch 1571: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8684 - val_loss: 0.4189 - val_accuracy: 0.8856\n",
            "Epoch 1572/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5054 - accuracy: 0.8675\n",
            "Epoch 1572: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5043 - accuracy: 0.8674 - val_loss: 0.4149 - val_accuracy: 0.8833\n",
            "Epoch 1573/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4687 - accuracy: 0.8733\n",
            "Epoch 1573: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.8730 - val_loss: 0.4120 - val_accuracy: 0.8810\n",
            "Epoch 1574/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4839 - accuracy: 0.8693\n",
            "Epoch 1574: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.8690 - val_loss: 0.4175 - val_accuracy: 0.8867\n",
            "Epoch 1575/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4749 - accuracy: 0.8630\n",
            "Epoch 1575: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.8627 - val_loss: 0.4046 - val_accuracy: 0.8924\n",
            "Epoch 1576/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5004 - accuracy: 0.8719\n",
            "Epoch 1576: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4969 - accuracy: 0.8707 - val_loss: 0.4297 - val_accuracy: 0.9005\n",
            "Epoch 1577/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4657 - accuracy: 0.8703\n",
            "Epoch 1577: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.8706 - val_loss: 0.4238 - val_accuracy: 0.8959\n",
            "Epoch 1578/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5049 - accuracy: 0.8652\n",
            "Epoch 1578: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5030 - accuracy: 0.8640 - val_loss: 0.4045 - val_accuracy: 0.8890\n",
            "Epoch 1579/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5133 - accuracy: 0.8687\n",
            "Epoch 1579: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5193 - accuracy: 0.8684 - val_loss: 0.4100 - val_accuracy: 0.8947\n",
            "Epoch 1580/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5114 - accuracy: 0.8646\n",
            "Epoch 1580: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.8646 - val_loss: 0.4549 - val_accuracy: 0.8764\n",
            "Epoch 1581/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5153 - accuracy: 0.8613\n",
            "Epoch 1581: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5137 - accuracy: 0.8616 - val_loss: 0.4139 - val_accuracy: 0.8799\n",
            "Epoch 1582/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5077 - accuracy: 0.8620\n",
            "Epoch 1582: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5074 - accuracy: 0.8621 - val_loss: 0.4173 - val_accuracy: 0.8833\n",
            "Epoch 1583/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.6010 - accuracy: 0.8595\n",
            "Epoch 1583: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5885 - accuracy: 0.8593 - val_loss: 0.4413 - val_accuracy: 0.8810\n",
            "Epoch 1584/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5003 - accuracy: 0.8700\n",
            "Epoch 1584: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4976 - accuracy: 0.8689 - val_loss: 0.4169 - val_accuracy: 0.8936\n",
            "Epoch 1585/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.7379 - accuracy: 0.8558\n",
            "Epoch 1585: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.7355 - accuracy: 0.8561 - val_loss: 0.4922 - val_accuracy: 0.8627\n",
            "Epoch 1586/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5646 - accuracy: 0.8467\n",
            "Epoch 1586: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5594 - accuracy: 0.8475 - val_loss: 0.4433 - val_accuracy: 0.8844\n",
            "Epoch 1587/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5000 - accuracy: 0.8604\n",
            "Epoch 1587: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4999 - accuracy: 0.8604 - val_loss: 0.4052 - val_accuracy: 0.8924\n",
            "Epoch 1588/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5228 - accuracy: 0.8624\n",
            "Epoch 1588: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.8624 - val_loss: 0.4183 - val_accuracy: 0.8844\n",
            "Epoch 1589/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4745 - accuracy: 0.8656\n",
            "Epoch 1589: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.8653 - val_loss: 0.3957 - val_accuracy: 0.8890\n",
            "Epoch 1590/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5384 - accuracy: 0.8618\n",
            "Epoch 1590: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5384 - accuracy: 0.8618 - val_loss: 0.4205 - val_accuracy: 0.8787\n",
            "Epoch 1591/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4824 - accuracy: 0.8633\n",
            "Epoch 1591: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4819 - accuracy: 0.8631 - val_loss: 0.3975 - val_accuracy: 0.8913\n",
            "Epoch 1592/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.8742\n",
            "Epoch 1592: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.8749 - val_loss: 0.4087 - val_accuracy: 0.8936\n",
            "Epoch 1593/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4694 - accuracy: 0.8732\n",
            "Epoch 1593: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4694 - accuracy: 0.8732 - val_loss: 0.4032 - val_accuracy: 0.8856\n",
            "Epoch 1594/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4360 - accuracy: 0.8769\n",
            "Epoch 1594: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4363 - accuracy: 0.8763 - val_loss: 0.3985 - val_accuracy: 0.8970\n",
            "Epoch 1595/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5303 - accuracy: 0.8646\n",
            "Epoch 1595: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5355 - accuracy: 0.8636 - val_loss: 0.4049 - val_accuracy: 0.8822\n",
            "Epoch 1596/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5062 - accuracy: 0.8600\n",
            "Epoch 1596: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5029 - accuracy: 0.8607 - val_loss: 0.4100 - val_accuracy: 0.8856\n",
            "Epoch 1597/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4720 - accuracy: 0.8675\n",
            "Epoch 1597: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4730 - accuracy: 0.8673 - val_loss: 0.4144 - val_accuracy: 0.8890\n",
            "Epoch 1598/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5088 - accuracy: 0.8677\n",
            "Epoch 1598: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5098 - accuracy: 0.8667 - val_loss: 0.4208 - val_accuracy: 0.8844\n",
            "Epoch 1599/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4958 - accuracy: 0.8702\n",
            "Epoch 1599: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4943 - accuracy: 0.8713 - val_loss: 0.4169 - val_accuracy: 0.8924\n",
            "Epoch 1600/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4887 - accuracy: 0.8747\n",
            "Epoch 1600: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.8750 - val_loss: 0.4073 - val_accuracy: 0.8936\n",
            "Epoch 1601/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4690 - accuracy: 0.8662\n",
            "Epoch 1601: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4718 - accuracy: 0.8666 - val_loss: 0.4396 - val_accuracy: 0.8776\n",
            "Epoch 1602/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4235 - accuracy: 0.8754\n",
            "Epoch 1602: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4174 - accuracy: 0.8773 - val_loss: 0.3935 - val_accuracy: 0.8879\n",
            "Epoch 1603/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4439 - accuracy: 0.8734\n",
            "Epoch 1603: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4390 - accuracy: 0.8754 - val_loss: 0.3975 - val_accuracy: 0.8856\n",
            "Epoch 1604/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4717 - accuracy: 0.8645\n",
            "Epoch 1604: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.8644 - val_loss: 0.3825 - val_accuracy: 0.8902\n",
            "Epoch 1605/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5034 - accuracy: 0.8698\n",
            "Epoch 1605: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5034 - accuracy: 0.8689 - val_loss: 0.4113 - val_accuracy: 0.8856\n",
            "Epoch 1606/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4846 - accuracy: 0.8640\n",
            "Epoch 1606: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4829 - accuracy: 0.8633 - val_loss: 0.4213 - val_accuracy: 0.8924\n",
            "Epoch 1607/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4419 - accuracy: 0.8771\n",
            "Epoch 1607: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4517 - accuracy: 0.8760 - val_loss: 0.4021 - val_accuracy: 0.8924\n",
            "Epoch 1608/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5163 - accuracy: 0.8628\n",
            "Epoch 1608: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5155 - accuracy: 0.8634 - val_loss: 0.4322 - val_accuracy: 0.8890\n",
            "Epoch 1609/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4736 - accuracy: 0.8684\n",
            "Epoch 1609: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.8681 - val_loss: 0.4303 - val_accuracy: 0.8936\n",
            "Epoch 1610/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4833 - accuracy: 0.8712\n",
            "Epoch 1610: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4863 - accuracy: 0.8710 - val_loss: 0.4120 - val_accuracy: 0.8856\n",
            "Epoch 1611/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5080 - accuracy: 0.8702\n",
            "Epoch 1611: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5038 - accuracy: 0.8709 - val_loss: 0.4307 - val_accuracy: 0.8867\n",
            "Epoch 1612/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4519 - accuracy: 0.8729\n",
            "Epoch 1612: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4524 - accuracy: 0.8729 - val_loss: 0.4225 - val_accuracy: 0.8879\n",
            "Epoch 1613/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4842 - accuracy: 0.8678\n",
            "Epoch 1613: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4844 - accuracy: 0.8673 - val_loss: 0.4271 - val_accuracy: 0.8879\n",
            "Epoch 1614/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4661 - accuracy: 0.8715\n",
            "Epoch 1614: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4682 - accuracy: 0.8712 - val_loss: 0.4486 - val_accuracy: 0.8799\n",
            "Epoch 1615/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5356 - accuracy: 0.8661\n",
            "Epoch 1615: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5331 - accuracy: 0.8661 - val_loss: 0.4567 - val_accuracy: 0.8902\n",
            "Epoch 1616/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5798 - accuracy: 0.8638\n",
            "Epoch 1616: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5750 - accuracy: 0.8647 - val_loss: 0.4349 - val_accuracy: 0.8936\n",
            "Epoch 1617/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5093 - accuracy: 0.8612\n",
            "Epoch 1617: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5068 - accuracy: 0.8616 - val_loss: 0.4498 - val_accuracy: 0.8913\n",
            "Epoch 1618/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4812 - accuracy: 0.8683\n",
            "Epoch 1618: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4812 - accuracy: 0.8683 - val_loss: 0.4215 - val_accuracy: 0.8764\n",
            "Epoch 1619/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4684 - accuracy: 0.8691\n",
            "Epoch 1619: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4655 - accuracy: 0.8697 - val_loss: 0.4269 - val_accuracy: 0.8902\n",
            "Epoch 1620/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4990 - accuracy: 0.8679\n",
            "Epoch 1620: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5019 - accuracy: 0.8679 - val_loss: 0.4200 - val_accuracy: 0.8879\n",
            "Epoch 1621/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.5291 - accuracy: 0.8570\n",
            "Epoch 1621: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5334 - accuracy: 0.8580 - val_loss: 0.4277 - val_accuracy: 0.8856\n",
            "Epoch 1622/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5136 - accuracy: 0.8663\n",
            "Epoch 1622: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5136 - accuracy: 0.8663 - val_loss: 0.4139 - val_accuracy: 0.8936\n",
            "Epoch 1623/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4815 - accuracy: 0.8686\n",
            "Epoch 1623: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.8690 - val_loss: 0.4365 - val_accuracy: 0.8856\n",
            "Epoch 1624/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5172 - accuracy: 0.8686\n",
            "Epoch 1624: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5231 - accuracy: 0.8680 - val_loss: 0.4163 - val_accuracy: 0.8833\n",
            "Epoch 1625/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5353 - accuracy: 0.8657\n",
            "Epoch 1625: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5319 - accuracy: 0.8646 - val_loss: 0.3918 - val_accuracy: 0.8890\n",
            "Epoch 1626/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4793 - accuracy: 0.8708\n",
            "Epoch 1626: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4831 - accuracy: 0.8693 - val_loss: 0.4097 - val_accuracy: 0.8936\n",
            "Epoch 1627/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5317 - accuracy: 0.8548\n",
            "Epoch 1627: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5283 - accuracy: 0.8560 - val_loss: 0.4521 - val_accuracy: 0.8844\n",
            "Epoch 1628/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4653 - accuracy: 0.8673\n",
            "Epoch 1628: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4653 - accuracy: 0.8677 - val_loss: 0.4809 - val_accuracy: 0.8856\n",
            "Epoch 1629/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4868 - accuracy: 0.8675\n",
            "Epoch 1629: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4802 - accuracy: 0.8687 - val_loss: 0.4529 - val_accuracy: 0.8924\n",
            "Epoch 1630/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4931 - accuracy: 0.8701\n",
            "Epoch 1630: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4926 - accuracy: 0.8699 - val_loss: 0.4609 - val_accuracy: 0.8879\n",
            "Epoch 1631/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4847 - accuracy: 0.8723\n",
            "Epoch 1631: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4873 - accuracy: 0.8709 - val_loss: 0.4440 - val_accuracy: 0.8776\n",
            "Epoch 1632/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5230 - accuracy: 0.8591\n",
            "Epoch 1632: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5230 - accuracy: 0.8594 - val_loss: 0.4422 - val_accuracy: 0.8776\n",
            "Epoch 1633/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5280 - accuracy: 0.8621\n",
            "Epoch 1633: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5266 - accuracy: 0.8618 - val_loss: 0.4468 - val_accuracy: 0.8867\n",
            "Epoch 1634/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4862 - accuracy: 0.8685\n",
            "Epoch 1634: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4855 - accuracy: 0.8684 - val_loss: 0.4140 - val_accuracy: 0.8936\n",
            "Epoch 1635/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4645 - accuracy: 0.8701\n",
            "Epoch 1635: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.8700 - val_loss: 0.4756 - val_accuracy: 0.8867\n",
            "Epoch 1636/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4515 - accuracy: 0.8746\n",
            "Epoch 1636: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.8740 - val_loss: 0.4236 - val_accuracy: 0.8833\n",
            "Epoch 1637/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4602 - accuracy: 0.8733\n",
            "Epoch 1637: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4623 - accuracy: 0.8730 - val_loss: 0.4346 - val_accuracy: 0.8879\n",
            "Epoch 1638/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5183 - accuracy: 0.8625\n",
            "Epoch 1638: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5382 - accuracy: 0.8610 - val_loss: 0.4648 - val_accuracy: 0.8616\n",
            "Epoch 1639/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5154 - accuracy: 0.8576\n",
            "Epoch 1639: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5154 - accuracy: 0.8576 - val_loss: 0.4104 - val_accuracy: 0.8924\n",
            "Epoch 1640/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5195 - accuracy: 0.8694\n",
            "Epoch 1640: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5207 - accuracy: 0.8686 - val_loss: 0.4057 - val_accuracy: 0.8913\n",
            "Epoch 1641/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5492 - accuracy: 0.8590\n",
            "Epoch 1641: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5478 - accuracy: 0.8593 - val_loss: 0.4132 - val_accuracy: 0.8879\n",
            "Epoch 1642/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4828 - accuracy: 0.8679\n",
            "Epoch 1642: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4828 - accuracy: 0.8679 - val_loss: 0.4040 - val_accuracy: 0.8936\n",
            "Epoch 1643/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5373 - accuracy: 0.8667\n",
            "Epoch 1643: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5374 - accuracy: 0.8663 - val_loss: 0.4268 - val_accuracy: 0.8879\n",
            "Epoch 1644/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4839 - accuracy: 0.8704\n",
            "Epoch 1644: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4867 - accuracy: 0.8700 - val_loss: 0.4375 - val_accuracy: 0.8787\n",
            "Epoch 1645/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4949 - accuracy: 0.8619\n",
            "Epoch 1645: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4910 - accuracy: 0.8628 - val_loss: 0.4343 - val_accuracy: 0.8879\n",
            "Epoch 1646/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4333 - accuracy: 0.8782\n",
            "Epoch 1646: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4338 - accuracy: 0.8792 - val_loss: 0.4353 - val_accuracy: 0.8890\n",
            "Epoch 1647/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4270 - accuracy: 0.8809\n",
            "Epoch 1647: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4270 - accuracy: 0.8809 - val_loss: 0.4227 - val_accuracy: 0.8867\n",
            "Epoch 1648/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4997 - accuracy: 0.8679\n",
            "Epoch 1648: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4936 - accuracy: 0.8684 - val_loss: 0.4050 - val_accuracy: 0.8947\n",
            "Epoch 1649/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5453 - accuracy: 0.8586\n",
            "Epoch 1649: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5380 - accuracy: 0.8583 - val_loss: 0.4370 - val_accuracy: 0.8833\n",
            "Epoch 1650/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4712 - accuracy: 0.8687\n",
            "Epoch 1650: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4747 - accuracy: 0.8677 - val_loss: 0.4421 - val_accuracy: 0.8936\n",
            "Epoch 1651/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4930 - accuracy: 0.8615\n",
            "Epoch 1651: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4901 - accuracy: 0.8623 - val_loss: 0.4437 - val_accuracy: 0.8970\n",
            "Epoch 1652/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4727 - accuracy: 0.8748\n",
            "Epoch 1652: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4782 - accuracy: 0.8739 - val_loss: 0.4321 - val_accuracy: 0.8913\n",
            "Epoch 1653/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4546 - accuracy: 0.8734\n",
            "Epoch 1653: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4539 - accuracy: 0.8733 - val_loss: 0.4188 - val_accuracy: 0.8982\n",
            "Epoch 1654/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4685 - accuracy: 0.8675\n",
            "Epoch 1654: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.8647 - val_loss: 0.4815 - val_accuracy: 0.8776\n",
            "Epoch 1655/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5049 - accuracy: 0.8696\n",
            "Epoch 1655: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5065 - accuracy: 0.8690 - val_loss: 0.4439 - val_accuracy: 0.8833\n",
            "Epoch 1656/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4900 - accuracy: 0.8702\n",
            "Epoch 1656: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.8702 - val_loss: 0.4450 - val_accuracy: 0.8867\n",
            "Epoch 1657/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5158 - accuracy: 0.8636\n",
            "Epoch 1657: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.8639 - val_loss: 0.4236 - val_accuracy: 0.8913\n",
            "Epoch 1658/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4878 - accuracy: 0.8697\n",
            "Epoch 1658: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4852 - accuracy: 0.8702 - val_loss: 0.4188 - val_accuracy: 0.8890\n",
            "Epoch 1659/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.8656\n",
            "Epoch 1659: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4810 - accuracy: 0.8654 - val_loss: 0.4559 - val_accuracy: 0.8833\n",
            "Epoch 1660/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5016 - accuracy: 0.8701\n",
            "Epoch 1660: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5044 - accuracy: 0.8696 - val_loss: 0.4117 - val_accuracy: 0.8844\n",
            "Epoch 1661/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.8635\n",
            "Epoch 1661: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5063 - accuracy: 0.8639 - val_loss: 0.4556 - val_accuracy: 0.8776\n",
            "Epoch 1662/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4567 - accuracy: 0.8745\n",
            "Epoch 1662: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4554 - accuracy: 0.8750 - val_loss: 0.4613 - val_accuracy: 0.8867\n",
            "Epoch 1663/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4679 - accuracy: 0.8687\n",
            "Epoch 1663: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4674 - accuracy: 0.8690 - val_loss: 0.4484 - val_accuracy: 0.8879\n",
            "Epoch 1664/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.8693\n",
            "Epoch 1664: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4746 - accuracy: 0.8694 - val_loss: 0.4538 - val_accuracy: 0.8936\n",
            "Epoch 1665/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4737 - accuracy: 0.8738\n",
            "Epoch 1665: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.8733 - val_loss: 0.4566 - val_accuracy: 0.8799\n",
            "Epoch 1666/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5200 - accuracy: 0.8690\n",
            "Epoch 1666: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5286 - accuracy: 0.8684 - val_loss: 0.4650 - val_accuracy: 0.8913\n",
            "Epoch 1667/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4937 - accuracy: 0.8672\n",
            "Epoch 1667: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4965 - accuracy: 0.8664 - val_loss: 0.4205 - val_accuracy: 0.8902\n",
            "Epoch 1668/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4695 - accuracy: 0.8677\n",
            "Epoch 1668: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4674 - accuracy: 0.8681 - val_loss: 0.4220 - val_accuracy: 0.8924\n",
            "Epoch 1669/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5194 - accuracy: 0.8667\n",
            "Epoch 1669: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5165 - accuracy: 0.8667 - val_loss: 0.5123 - val_accuracy: 0.8707\n",
            "Epoch 1670/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5439 - accuracy: 0.8516\n",
            "Epoch 1670: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5424 - accuracy: 0.8520 - val_loss: 0.4345 - val_accuracy: 0.8856\n",
            "Epoch 1671/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4946 - accuracy: 0.8727\n",
            "Epoch 1671: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4946 - accuracy: 0.8727 - val_loss: 0.4483 - val_accuracy: 0.8776\n",
            "Epoch 1672/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5609 - accuracy: 0.8586\n",
            "Epoch 1672: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5485 - accuracy: 0.8603 - val_loss: 0.4485 - val_accuracy: 0.8856\n",
            "Epoch 1673/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4721 - accuracy: 0.8719\n",
            "Epoch 1673: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4731 - accuracy: 0.8723 - val_loss: 0.4150 - val_accuracy: 0.8902\n",
            "Epoch 1674/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5157 - accuracy: 0.8655\n",
            "Epoch 1674: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5098 - accuracy: 0.8664 - val_loss: 0.4109 - val_accuracy: 0.8822\n",
            "Epoch 1675/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4600 - accuracy: 0.8743\n",
            "Epoch 1675: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4582 - accuracy: 0.8743 - val_loss: 0.4077 - val_accuracy: 0.8913\n",
            "Epoch 1676/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.8735\n",
            "Epoch 1676: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4592 - accuracy: 0.8734 - val_loss: 0.4418 - val_accuracy: 0.8936\n",
            "Epoch 1677/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4920 - accuracy: 0.8694\n",
            "Epoch 1677: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4913 - accuracy: 0.8694 - val_loss: 0.4278 - val_accuracy: 0.8856\n",
            "Epoch 1678/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4989 - accuracy: 0.8650\n",
            "Epoch 1678: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4956 - accuracy: 0.8647 - val_loss: 0.4254 - val_accuracy: 0.8844\n",
            "Epoch 1679/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4948 - accuracy: 0.8693\n",
            "Epoch 1679: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4948 - accuracy: 0.8693 - val_loss: 0.4073 - val_accuracy: 0.8982\n",
            "Epoch 1680/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4432 - accuracy: 0.8774\n",
            "Epoch 1680: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4434 - accuracy: 0.8772 - val_loss: 0.4067 - val_accuracy: 0.8970\n",
            "Epoch 1681/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4884 - accuracy: 0.8694\n",
            "Epoch 1681: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.8704 - val_loss: 0.4081 - val_accuracy: 0.8856\n",
            "Epoch 1682/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5156 - accuracy: 0.8598\n",
            "Epoch 1682: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.8604 - val_loss: 0.4074 - val_accuracy: 0.8879\n",
            "Epoch 1683/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5039 - accuracy: 0.8623\n",
            "Epoch 1683: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5041 - accuracy: 0.8631 - val_loss: 0.4201 - val_accuracy: 0.8959\n",
            "Epoch 1684/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5139 - accuracy: 0.8663\n",
            "Epoch 1684: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.8661 - val_loss: 0.4203 - val_accuracy: 0.8902\n",
            "Epoch 1685/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4812 - accuracy: 0.8683\n",
            "Epoch 1685: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4806 - accuracy: 0.8684 - val_loss: 0.4361 - val_accuracy: 0.8844\n",
            "Epoch 1686/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5067 - accuracy: 0.8665\n",
            "Epoch 1686: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.8676 - val_loss: 0.4483 - val_accuracy: 0.8696\n",
            "Epoch 1687/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5532 - accuracy: 0.8586\n",
            "Epoch 1687: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5536 - accuracy: 0.8563 - val_loss: 0.4280 - val_accuracy: 0.8696\n",
            "Epoch 1688/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5243 - accuracy: 0.8636\n",
            "Epoch 1688: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5222 - accuracy: 0.8630 - val_loss: 0.4010 - val_accuracy: 0.8822\n",
            "Epoch 1689/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5061 - accuracy: 0.8687\n",
            "Epoch 1689: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5061 - accuracy: 0.8687 - val_loss: 0.4286 - val_accuracy: 0.8844\n",
            "Epoch 1690/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4964 - accuracy: 0.8681\n",
            "Epoch 1690: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.8689 - val_loss: 0.4153 - val_accuracy: 0.8970\n",
            "Epoch 1691/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4789 - accuracy: 0.8728\n",
            "Epoch 1691: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4773 - accuracy: 0.8729 - val_loss: 0.4295 - val_accuracy: 0.8890\n",
            "Epoch 1692/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.8719\n",
            "Epoch 1692: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4587 - accuracy: 0.8719 - val_loss: 0.4118 - val_accuracy: 0.8959\n",
            "Epoch 1693/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.8710\n",
            "Epoch 1693: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4679 - accuracy: 0.8719 - val_loss: 0.3993 - val_accuracy: 0.8982\n",
            "Epoch 1694/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4803 - accuracy: 0.8676\n",
            "Epoch 1694: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4760 - accuracy: 0.8679 - val_loss: 0.4145 - val_accuracy: 0.8913\n",
            "Epoch 1695/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5060 - accuracy: 0.8629\n",
            "Epoch 1695: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.8626 - val_loss: 0.4236 - val_accuracy: 0.8913\n",
            "Epoch 1696/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4845 - accuracy: 0.8695\n",
            "Epoch 1696: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4897 - accuracy: 0.8681 - val_loss: 0.4397 - val_accuracy: 0.8799\n",
            "Epoch 1697/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5217 - accuracy: 0.8638\n",
            "Epoch 1697: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.8641 - val_loss: 0.4401 - val_accuracy: 0.8867\n",
            "Epoch 1698/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5029 - accuracy: 0.8665\n",
            "Epoch 1698: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5046 - accuracy: 0.8659 - val_loss: 0.3895 - val_accuracy: 0.8913\n",
            "Epoch 1699/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5889 - accuracy: 0.8609\n",
            "Epoch 1699: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5783 - accuracy: 0.8623 - val_loss: 0.4270 - val_accuracy: 0.8867\n",
            "Epoch 1700/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5424 - accuracy: 0.8668\n",
            "Epoch 1700: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5542 - accuracy: 0.8667 - val_loss: 0.4318 - val_accuracy: 0.8833\n",
            "Epoch 1701/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5225 - accuracy: 0.8631\n",
            "Epoch 1701: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.5225 - accuracy: 0.8631 - val_loss: 0.4259 - val_accuracy: 0.8879\n",
            "Epoch 1702/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4839 - accuracy: 0.8649\n",
            "Epoch 1702: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4971 - accuracy: 0.8640 - val_loss: 0.4135 - val_accuracy: 0.8936\n",
            "Epoch 1703/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5263 - accuracy: 0.8671\n",
            "Epoch 1703: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5221 - accuracy: 0.8681 - val_loss: 0.4057 - val_accuracy: 0.8959\n",
            "Epoch 1704/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4617 - accuracy: 0.8703\n",
            "Epoch 1704: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4571 - accuracy: 0.8710 - val_loss: 0.4127 - val_accuracy: 0.8890\n",
            "Epoch 1705/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.8755\n",
            "Epoch 1705: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.8753 - val_loss: 0.4353 - val_accuracy: 0.8856\n",
            "Epoch 1706/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5191 - accuracy: 0.8576\n",
            "Epoch 1706: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5192 - accuracy: 0.8577 - val_loss: 0.3899 - val_accuracy: 0.8890\n",
            "Epoch 1707/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4344 - accuracy: 0.8770\n",
            "Epoch 1707: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4344 - accuracy: 0.8770 - val_loss: 0.4123 - val_accuracy: 0.8856\n",
            "Epoch 1708/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5133 - accuracy: 0.8638\n",
            "Epoch 1708: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5142 - accuracy: 0.8636 - val_loss: 0.4219 - val_accuracy: 0.8890\n",
            "Epoch 1709/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4837 - accuracy: 0.8672\n",
            "Epoch 1709: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4836 - accuracy: 0.8670 - val_loss: 0.4234 - val_accuracy: 0.8890\n",
            "Epoch 1710/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4784 - accuracy: 0.8698\n",
            "Epoch 1710: val_loss did not improve from 0.37249\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4763 - accuracy: 0.8694 - val_loss: 0.4266 - val_accuracy: 0.8902\n",
            "Epoch 1711/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4393 - accuracy: 0.8791\n",
            "Epoch 1711: val_loss improved from 0.37249 to 0.37125, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4384 - accuracy: 0.8790 - val_loss: 0.3713 - val_accuracy: 0.8970\n",
            "Epoch 1712/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4721 - accuracy: 0.8736\n",
            "Epoch 1712: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4721 - accuracy: 0.8736 - val_loss: 0.4296 - val_accuracy: 0.8924\n",
            "Epoch 1713/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5105 - accuracy: 0.8641\n",
            "Epoch 1713: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5076 - accuracy: 0.8650 - val_loss: 0.4404 - val_accuracy: 0.8844\n",
            "Epoch 1714/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5002 - accuracy: 0.8618\n",
            "Epoch 1714: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4944 - accuracy: 0.8630 - val_loss: 0.4118 - val_accuracy: 0.8924\n",
            "Epoch 1715/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5148 - accuracy: 0.8673\n",
            "Epoch 1715: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5148 - accuracy: 0.8673 - val_loss: 0.4317 - val_accuracy: 0.8902\n",
            "Epoch 1716/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5149 - accuracy: 0.8654\n",
            "Epoch 1716: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5131 - accuracy: 0.8656 - val_loss: 0.4187 - val_accuracy: 0.8936\n",
            "Epoch 1717/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4805 - accuracy: 0.8625\n",
            "Epoch 1717: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.8627 - val_loss: 0.3892 - val_accuracy: 0.8970\n",
            "Epoch 1718/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4662 - accuracy: 0.8696\n",
            "Epoch 1718: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4679 - accuracy: 0.8689 - val_loss: 0.4291 - val_accuracy: 0.8879\n",
            "Epoch 1719/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4841 - accuracy: 0.8627\n",
            "Epoch 1719: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4841 - accuracy: 0.8627 - val_loss: 0.4671 - val_accuracy: 0.8730\n",
            "Epoch 1720/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4719 - accuracy: 0.8755\n",
            "Epoch 1720: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4648 - accuracy: 0.8773 - val_loss: 0.4531 - val_accuracy: 0.8810\n",
            "Epoch 1721/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5141 - accuracy: 0.8661\n",
            "Epoch 1721: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5179 - accuracy: 0.8664 - val_loss: 0.4383 - val_accuracy: 0.8799\n",
            "Epoch 1722/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4751 - accuracy: 0.8730\n",
            "Epoch 1722: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4765 - accuracy: 0.8722 - val_loss: 0.4281 - val_accuracy: 0.8924\n",
            "Epoch 1723/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5173 - accuracy: 0.8688\n",
            "Epoch 1723: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5169 - accuracy: 0.8689 - val_loss: 0.4393 - val_accuracy: 0.8890\n",
            "Epoch 1724/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4913 - accuracy: 0.8669\n",
            "Epoch 1724: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4896 - accuracy: 0.8661 - val_loss: 0.4437 - val_accuracy: 0.8879\n",
            "Epoch 1725/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4824 - accuracy: 0.8710\n",
            "Epoch 1725: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4877 - accuracy: 0.8714 - val_loss: 0.4340 - val_accuracy: 0.8776\n",
            "Epoch 1726/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4314 - accuracy: 0.8781\n",
            "Epoch 1726: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4321 - accuracy: 0.8776 - val_loss: 0.4149 - val_accuracy: 0.8867\n",
            "Epoch 1727/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4198 - accuracy: 0.8852\n",
            "Epoch 1727: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4192 - accuracy: 0.8853 - val_loss: 0.4227 - val_accuracy: 0.8902\n",
            "Epoch 1728/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4657 - accuracy: 0.8714\n",
            "Epoch 1728: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4628 - accuracy: 0.8707 - val_loss: 0.4291 - val_accuracy: 0.8890\n",
            "Epoch 1729/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5112 - accuracy: 0.8633\n",
            "Epoch 1729: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5074 - accuracy: 0.8636 - val_loss: 0.4505 - val_accuracy: 0.8776\n",
            "Epoch 1730/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5010 - accuracy: 0.8659\n",
            "Epoch 1730: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5010 - accuracy: 0.8654 - val_loss: 0.4565 - val_accuracy: 0.8776\n",
            "Epoch 1731/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4944 - accuracy: 0.8687\n",
            "Epoch 1731: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4914 - accuracy: 0.8676 - val_loss: 0.4636 - val_accuracy: 0.8753\n",
            "Epoch 1732/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.8683\n",
            "Epoch 1732: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4693 - accuracy: 0.8690 - val_loss: 0.4309 - val_accuracy: 0.8947\n",
            "Epoch 1733/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5358 - accuracy: 0.8641\n",
            "Epoch 1733: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5358 - accuracy: 0.8641 - val_loss: 0.4715 - val_accuracy: 0.8856\n",
            "Epoch 1734/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5068 - accuracy: 0.8690\n",
            "Epoch 1734: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.8684 - val_loss: 0.4466 - val_accuracy: 0.8867\n",
            "Epoch 1735/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.6019 - accuracy: 0.8538\n",
            "Epoch 1735: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.6024 - accuracy: 0.8525 - val_loss: 0.4682 - val_accuracy: 0.8902\n",
            "Epoch 1736/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5064 - accuracy: 0.8645\n",
            "Epoch 1736: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5074 - accuracy: 0.8640 - val_loss: 0.4689 - val_accuracy: 0.8890\n",
            "Epoch 1737/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4831 - accuracy: 0.8667\n",
            "Epoch 1737: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4791 - accuracy: 0.8670 - val_loss: 0.5077 - val_accuracy: 0.8879\n",
            "Epoch 1738/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5058 - accuracy: 0.8623\n",
            "Epoch 1738: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5043 - accuracy: 0.8630 - val_loss: 0.4794 - val_accuracy: 0.8902\n",
            "Epoch 1739/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5412 - accuracy: 0.8638\n",
            "Epoch 1739: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5391 - accuracy: 0.8643 - val_loss: 0.4542 - val_accuracy: 0.8913\n",
            "Epoch 1740/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5059 - accuracy: 0.8638\n",
            "Epoch 1740: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.8628 - val_loss: 0.4496 - val_accuracy: 0.8833\n",
            "Epoch 1741/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5084 - accuracy: 0.8606\n",
            "Epoch 1741: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5056 - accuracy: 0.8606 - val_loss: 0.4302 - val_accuracy: 0.8959\n",
            "Epoch 1742/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4983 - accuracy: 0.8673\n",
            "Epoch 1742: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5003 - accuracy: 0.8661 - val_loss: 0.4272 - val_accuracy: 0.8844\n",
            "Epoch 1743/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4614 - accuracy: 0.8718\n",
            "Epoch 1743: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4572 - accuracy: 0.8736 - val_loss: 0.4564 - val_accuracy: 0.8970\n",
            "Epoch 1744/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4829 - accuracy: 0.8735\n",
            "Epoch 1744: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.8742 - val_loss: 0.4294 - val_accuracy: 0.8947\n",
            "Epoch 1745/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.8761\n",
            "Epoch 1745: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4742 - accuracy: 0.8760 - val_loss: 0.4089 - val_accuracy: 0.8959\n",
            "Epoch 1746/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4819 - accuracy: 0.8712\n",
            "Epoch 1746: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.8703 - val_loss: 0.4618 - val_accuracy: 0.8936\n",
            "Epoch 1747/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4519 - accuracy: 0.8740\n",
            "Epoch 1747: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4533 - accuracy: 0.8740 - val_loss: 0.4210 - val_accuracy: 0.8947\n",
            "Epoch 1748/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4980 - accuracy: 0.8746\n",
            "Epoch 1748: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4988 - accuracy: 0.8736 - val_loss: 0.4583 - val_accuracy: 0.8913\n",
            "Epoch 1749/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4971 - accuracy: 0.8670\n",
            "Epoch 1749: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4961 - accuracy: 0.8663 - val_loss: 0.4362 - val_accuracy: 0.8902\n",
            "Epoch 1750/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8742\n",
            "Epoch 1750: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4509 - accuracy: 0.8742 - val_loss: 0.4285 - val_accuracy: 0.8879\n",
            "Epoch 1751/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4488 - accuracy: 0.8765\n",
            "Epoch 1751: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4487 - accuracy: 0.8759 - val_loss: 0.4042 - val_accuracy: 0.8947\n",
            "Epoch 1752/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4800 - accuracy: 0.8711\n",
            "Epoch 1752: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4864 - accuracy: 0.8704 - val_loss: 0.4122 - val_accuracy: 0.8879\n",
            "Epoch 1753/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5211 - accuracy: 0.8588\n",
            "Epoch 1753: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5188 - accuracy: 0.8596 - val_loss: 0.4135 - val_accuracy: 0.8936\n",
            "Epoch 1754/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5147 - accuracy: 0.8658\n",
            "Epoch 1754: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5182 - accuracy: 0.8643 - val_loss: 0.3915 - val_accuracy: 0.8970\n",
            "Epoch 1755/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5472 - accuracy: 0.8686\n",
            "Epoch 1755: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5412 - accuracy: 0.8689 - val_loss: 0.4309 - val_accuracy: 0.8947\n",
            "Epoch 1756/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4986 - accuracy: 0.8614\n",
            "Epoch 1756: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4971 - accuracy: 0.8627 - val_loss: 0.3987 - val_accuracy: 0.8982\n",
            "Epoch 1757/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5237 - accuracy: 0.8614\n",
            "Epoch 1757: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5252 - accuracy: 0.8610 - val_loss: 0.4001 - val_accuracy: 0.8924\n",
            "Epoch 1758/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5095 - accuracy: 0.8625\n",
            "Epoch 1758: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5090 - accuracy: 0.8616 - val_loss: 0.3884 - val_accuracy: 0.8993\n",
            "Epoch 1759/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5323 - accuracy: 0.8627\n",
            "Epoch 1759: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.8624 - val_loss: 0.4318 - val_accuracy: 0.8741\n",
            "Epoch 1760/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5306 - accuracy: 0.8573\n",
            "Epoch 1760: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5304 - accuracy: 0.8570 - val_loss: 0.4044 - val_accuracy: 0.8902\n",
            "Epoch 1761/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5503 - accuracy: 0.8608\n",
            "Epoch 1761: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5507 - accuracy: 0.8617 - val_loss: 0.3754 - val_accuracy: 0.8936\n",
            "Epoch 1762/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4842 - accuracy: 0.8718\n",
            "Epoch 1762: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4817 - accuracy: 0.8726 - val_loss: 0.4016 - val_accuracy: 0.8936\n",
            "Epoch 1763/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5395 - accuracy: 0.8597\n",
            "Epoch 1763: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5357 - accuracy: 0.8597 - val_loss: 0.4066 - val_accuracy: 0.8856\n",
            "Epoch 1764/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5034 - accuracy: 0.8638\n",
            "Epoch 1764: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5049 - accuracy: 0.8620 - val_loss: 0.4108 - val_accuracy: 0.8936\n",
            "Epoch 1765/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4709 - accuracy: 0.8696\n",
            "Epoch 1765: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4707 - accuracy: 0.8693 - val_loss: 0.4262 - val_accuracy: 0.8844\n",
            "Epoch 1766/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4599 - accuracy: 0.8682\n",
            "Epoch 1766: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4568 - accuracy: 0.8686 - val_loss: 0.3922 - val_accuracy: 0.8947\n",
            "Epoch 1767/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4979 - accuracy: 0.8714\n",
            "Epoch 1767: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.8729 - val_loss: 0.4090 - val_accuracy: 0.8867\n",
            "Epoch 1768/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4810 - accuracy: 0.8731\n",
            "Epoch 1768: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4801 - accuracy: 0.8733 - val_loss: 0.4171 - val_accuracy: 0.8844\n",
            "Epoch 1769/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5008 - accuracy: 0.8638\n",
            "Epoch 1769: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5025 - accuracy: 0.8644 - val_loss: 0.4030 - val_accuracy: 0.8924\n",
            "Epoch 1770/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5191 - accuracy: 0.8579\n",
            "Epoch 1770: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5163 - accuracy: 0.8583 - val_loss: 0.4330 - val_accuracy: 0.8867\n",
            "Epoch 1771/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5184 - accuracy: 0.8627\n",
            "Epoch 1771: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.8630 - val_loss: 0.4211 - val_accuracy: 0.8867\n",
            "Epoch 1772/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5700 - accuracy: 0.8601\n",
            "Epoch 1772: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5645 - accuracy: 0.8601 - val_loss: 0.4293 - val_accuracy: 0.8822\n",
            "Epoch 1773/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5390 - accuracy: 0.8618\n",
            "Epoch 1773: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5386 - accuracy: 0.8624 - val_loss: 0.4139 - val_accuracy: 0.8913\n",
            "Epoch 1774/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4648 - accuracy: 0.8674\n",
            "Epoch 1774: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4656 - accuracy: 0.8673 - val_loss: 0.4062 - val_accuracy: 0.8959\n",
            "Epoch 1775/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5190 - accuracy: 0.8600\n",
            "Epoch 1775: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5155 - accuracy: 0.8601 - val_loss: 0.4340 - val_accuracy: 0.8833\n",
            "Epoch 1776/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5292 - accuracy: 0.8603\n",
            "Epoch 1776: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5267 - accuracy: 0.8606 - val_loss: 0.3958 - val_accuracy: 0.8890\n",
            "Epoch 1777/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5301 - accuracy: 0.8588\n",
            "Epoch 1777: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5290 - accuracy: 0.8587 - val_loss: 0.4065 - val_accuracy: 0.8856\n",
            "Epoch 1778/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5474 - accuracy: 0.8610\n",
            "Epoch 1778: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5412 - accuracy: 0.8623 - val_loss: 0.3895 - val_accuracy: 0.8822\n",
            "Epoch 1779/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5230 - accuracy: 0.8589\n",
            "Epoch 1779: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5177 - accuracy: 0.8596 - val_loss: 0.4024 - val_accuracy: 0.8902\n",
            "Epoch 1780/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4730 - accuracy: 0.8638\n",
            "Epoch 1780: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4709 - accuracy: 0.8641 - val_loss: 0.3847 - val_accuracy: 0.8902\n",
            "Epoch 1781/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4862 - accuracy: 0.8724\n",
            "Epoch 1781: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4842 - accuracy: 0.8724 - val_loss: 0.4027 - val_accuracy: 0.8924\n",
            "Epoch 1782/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4427 - accuracy: 0.8768\n",
            "Epoch 1782: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4759 - accuracy: 0.8773 - val_loss: 0.4269 - val_accuracy: 0.8753\n",
            "Epoch 1783/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5074 - accuracy: 0.8603\n",
            "Epoch 1783: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5007 - accuracy: 0.8617 - val_loss: 0.4221 - val_accuracy: 0.8867\n",
            "Epoch 1784/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4866 - accuracy: 0.8682\n",
            "Epoch 1784: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4941 - accuracy: 0.8683 - val_loss: 0.4175 - val_accuracy: 0.8810\n",
            "Epoch 1785/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4724 - accuracy: 0.8670\n",
            "Epoch 1785: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4684 - accuracy: 0.8673 - val_loss: 0.4013 - val_accuracy: 0.8890\n",
            "Epoch 1786/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4996 - accuracy: 0.8704\n",
            "Epoch 1786: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5000 - accuracy: 0.8694 - val_loss: 0.3934 - val_accuracy: 0.8924\n",
            "Epoch 1787/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4543 - accuracy: 0.8744\n",
            "Epoch 1787: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4609 - accuracy: 0.8744 - val_loss: 0.3782 - val_accuracy: 0.9005\n",
            "Epoch 1788/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4854 - accuracy: 0.8754\n",
            "Epoch 1788: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.8760 - val_loss: 0.3939 - val_accuracy: 0.8902\n",
            "Epoch 1789/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5009 - accuracy: 0.8692\n",
            "Epoch 1789: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5012 - accuracy: 0.8693 - val_loss: 0.4134 - val_accuracy: 0.8833\n",
            "Epoch 1790/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5052 - accuracy: 0.8672\n",
            "Epoch 1790: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5016 - accuracy: 0.8674 - val_loss: 0.4114 - val_accuracy: 0.8936\n",
            "Epoch 1791/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.5059 - accuracy: 0.8703\n",
            "Epoch 1791: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5022 - accuracy: 0.8707 - val_loss: 0.4115 - val_accuracy: 0.8947\n",
            "Epoch 1792/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4974 - accuracy: 0.8724\n",
            "Epoch 1792: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4999 - accuracy: 0.8716 - val_loss: 0.3969 - val_accuracy: 0.8844\n",
            "Epoch 1793/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4823 - accuracy: 0.8696\n",
            "Epoch 1793: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4808 - accuracy: 0.8694 - val_loss: 0.4134 - val_accuracy: 0.8890\n",
            "Epoch 1794/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5016 - accuracy: 0.8626\n",
            "Epoch 1794: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4920 - accuracy: 0.8644 - val_loss: 0.4185 - val_accuracy: 0.8959\n",
            "Epoch 1795/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4768 - accuracy: 0.8727\n",
            "Epoch 1795: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.8719 - val_loss: 0.4061 - val_accuracy: 0.8913\n",
            "Epoch 1796/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4740 - accuracy: 0.8792\n",
            "Epoch 1796: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4749 - accuracy: 0.8787 - val_loss: 0.4230 - val_accuracy: 0.8799\n",
            "Epoch 1797/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4757 - accuracy: 0.8722\n",
            "Epoch 1797: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4783 - accuracy: 0.8720 - val_loss: 0.4064 - val_accuracy: 0.8947\n",
            "Epoch 1798/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5166 - accuracy: 0.8641\n",
            "Epoch 1798: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5122 - accuracy: 0.8640 - val_loss: 0.3865 - val_accuracy: 0.8982\n",
            "Epoch 1799/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4456 - accuracy: 0.8803\n",
            "Epoch 1799: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4430 - accuracy: 0.8805 - val_loss: 0.3975 - val_accuracy: 0.8924\n",
            "Epoch 1800/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5238 - accuracy: 0.8633\n",
            "Epoch 1800: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5159 - accuracy: 0.8641 - val_loss: 0.4160 - val_accuracy: 0.8924\n",
            "Epoch 1801/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5071 - accuracy: 0.8677\n",
            "Epoch 1801: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5047 - accuracy: 0.8673 - val_loss: 0.4323 - val_accuracy: 0.8822\n",
            "Epoch 1802/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5138 - accuracy: 0.8698\n",
            "Epoch 1802: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5167 - accuracy: 0.8694 - val_loss: 0.4139 - val_accuracy: 0.8799\n",
            "Epoch 1803/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5221 - accuracy: 0.8608\n",
            "Epoch 1803: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5192 - accuracy: 0.8617 - val_loss: 0.3865 - val_accuracy: 0.8844\n",
            "Epoch 1804/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5242 - accuracy: 0.8646\n",
            "Epoch 1804: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5247 - accuracy: 0.8640 - val_loss: 0.4227 - val_accuracy: 0.8844\n",
            "Epoch 1805/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4868 - accuracy: 0.8677\n",
            "Epoch 1805: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4867 - accuracy: 0.8683 - val_loss: 0.3956 - val_accuracy: 0.8936\n",
            "Epoch 1806/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5051 - accuracy: 0.8730\n",
            "Epoch 1806: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5051 - accuracy: 0.8730 - val_loss: 0.4192 - val_accuracy: 0.8810\n",
            "Epoch 1807/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4607 - accuracy: 0.8721\n",
            "Epoch 1807: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4607 - accuracy: 0.8722 - val_loss: 0.4182 - val_accuracy: 0.8879\n",
            "Epoch 1808/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4861 - accuracy: 0.8713\n",
            "Epoch 1808: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4821 - accuracy: 0.8723 - val_loss: 0.4341 - val_accuracy: 0.8844\n",
            "Epoch 1809/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4955 - accuracy: 0.8707\n",
            "Epoch 1809: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.8713 - val_loss: 0.4451 - val_accuracy: 0.8799\n",
            "Epoch 1810/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4728 - accuracy: 0.8674\n",
            "Epoch 1810: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4714 - accuracy: 0.8674 - val_loss: 0.4162 - val_accuracy: 0.8902\n",
            "Epoch 1811/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4807 - accuracy: 0.8716\n",
            "Epoch 1811: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4833 - accuracy: 0.8709 - val_loss: 0.4225 - val_accuracy: 0.8913\n",
            "Epoch 1812/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4748 - accuracy: 0.8728\n",
            "Epoch 1812: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4680 - accuracy: 0.8743 - val_loss: 0.3963 - val_accuracy: 0.8936\n",
            "Epoch 1813/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4807 - accuracy: 0.8704\n",
            "Epoch 1813: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4795 - accuracy: 0.8709 - val_loss: 0.3936 - val_accuracy: 0.8902\n",
            "Epoch 1814/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4860 - accuracy: 0.8687\n",
            "Epoch 1814: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4860 - accuracy: 0.8681 - val_loss: 0.4098 - val_accuracy: 0.8844\n",
            "Epoch 1815/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4583 - accuracy: 0.8758\n",
            "Epoch 1815: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.8757 - val_loss: 0.3961 - val_accuracy: 0.8936\n",
            "Epoch 1816/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4799 - accuracy: 0.8710\n",
            "Epoch 1816: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.8700 - val_loss: 0.4267 - val_accuracy: 0.8856\n",
            "Epoch 1817/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5220 - accuracy: 0.8621\n",
            "Epoch 1817: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5230 - accuracy: 0.8623 - val_loss: 0.4429 - val_accuracy: 0.8810\n",
            "Epoch 1818/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5224 - accuracy: 0.8672\n",
            "Epoch 1818: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5226 - accuracy: 0.8671 - val_loss: 0.3970 - val_accuracy: 0.8844\n",
            "Epoch 1819/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4824 - accuracy: 0.8776\n",
            "Epoch 1819: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4846 - accuracy: 0.8772 - val_loss: 0.3814 - val_accuracy: 0.9005\n",
            "Epoch 1820/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5366 - accuracy: 0.8647\n",
            "Epoch 1820: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5312 - accuracy: 0.8657 - val_loss: 0.4194 - val_accuracy: 0.8856\n",
            "Epoch 1821/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4776 - accuracy: 0.8692\n",
            "Epoch 1821: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4803 - accuracy: 0.8686 - val_loss: 0.4049 - val_accuracy: 0.8890\n",
            "Epoch 1822/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4535 - accuracy: 0.8733\n",
            "Epoch 1822: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4618 - accuracy: 0.8713 - val_loss: 0.4144 - val_accuracy: 0.8924\n",
            "Epoch 1823/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.8711\n",
            "Epoch 1823: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4649 - accuracy: 0.8713 - val_loss: 0.4051 - val_accuracy: 0.8993\n",
            "Epoch 1824/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4800 - accuracy: 0.8749\n",
            "Epoch 1824: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4793 - accuracy: 0.8753 - val_loss: 0.4276 - val_accuracy: 0.8947\n",
            "Epoch 1825/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4519 - accuracy: 0.8749\n",
            "Epoch 1825: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4514 - accuracy: 0.8744 - val_loss: 0.4144 - val_accuracy: 0.8913\n",
            "Epoch 1826/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4401 - accuracy: 0.8731\n",
            "Epoch 1826: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4432 - accuracy: 0.8722 - val_loss: 0.3931 - val_accuracy: 0.9016\n",
            "Epoch 1827/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5528 - accuracy: 0.8677\n",
            "Epoch 1827: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5478 - accuracy: 0.8674 - val_loss: 0.4007 - val_accuracy: 0.8959\n",
            "Epoch 1828/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5365 - accuracy: 0.8664\n",
            "Epoch 1828: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5365 - accuracy: 0.8664 - val_loss: 0.4492 - val_accuracy: 0.8741\n",
            "Epoch 1829/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4595 - accuracy: 0.8706\n",
            "Epoch 1829: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.8710 - val_loss: 0.4058 - val_accuracy: 0.8902\n",
            "Epoch 1830/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4842 - accuracy: 0.8672\n",
            "Epoch 1830: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4958 - accuracy: 0.8650 - val_loss: 0.4136 - val_accuracy: 0.8902\n",
            "Epoch 1831/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4758 - accuracy: 0.8743\n",
            "Epoch 1831: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4716 - accuracy: 0.8749 - val_loss: 0.4280 - val_accuracy: 0.8936\n",
            "Epoch 1832/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5530 - accuracy: 0.8686\n",
            "Epoch 1832: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5525 - accuracy: 0.8684 - val_loss: 0.4847 - val_accuracy: 0.8844\n",
            "Epoch 1833/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.6024 - accuracy: 0.8460\n",
            "Epoch 1833: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5832 - accuracy: 0.8497 - val_loss: 0.4393 - val_accuracy: 0.8833\n",
            "Epoch 1834/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5131 - accuracy: 0.8609\n",
            "Epoch 1834: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5144 - accuracy: 0.8613 - val_loss: 0.4582 - val_accuracy: 0.8867\n",
            "Epoch 1835/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.8675\n",
            "Epoch 1835: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4693 - accuracy: 0.8670 - val_loss: 0.4255 - val_accuracy: 0.8982\n",
            "Epoch 1836/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4853 - accuracy: 0.8751\n",
            "Epoch 1836: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4868 - accuracy: 0.8746 - val_loss: 0.4110 - val_accuracy: 0.8970\n",
            "Epoch 1837/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4886 - accuracy: 0.8662\n",
            "Epoch 1837: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4947 - accuracy: 0.8650 - val_loss: 0.4280 - val_accuracy: 0.8890\n",
            "Epoch 1838/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4969 - accuracy: 0.8662\n",
            "Epoch 1838: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4931 - accuracy: 0.8659 - val_loss: 0.3997 - val_accuracy: 0.8924\n",
            "Epoch 1839/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4828 - accuracy: 0.8747\n",
            "Epoch 1839: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4798 - accuracy: 0.8753 - val_loss: 0.4122 - val_accuracy: 0.8879\n",
            "Epoch 1840/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5080 - accuracy: 0.8649\n",
            "Epoch 1840: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5096 - accuracy: 0.8634 - val_loss: 0.4147 - val_accuracy: 0.8799\n",
            "Epoch 1841/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4929 - accuracy: 0.8710\n",
            "Epoch 1841: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4954 - accuracy: 0.8696 - val_loss: 0.4187 - val_accuracy: 0.8890\n",
            "Epoch 1842/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5428 - accuracy: 0.8710\n",
            "Epoch 1842: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5428 - accuracy: 0.8710 - val_loss: 0.4227 - val_accuracy: 0.8924\n",
            "Epoch 1843/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4739 - accuracy: 0.8727\n",
            "Epoch 1843: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4737 - accuracy: 0.8719 - val_loss: 0.3992 - val_accuracy: 0.8959\n",
            "Epoch 1844/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5912 - accuracy: 0.8648\n",
            "Epoch 1844: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5934 - accuracy: 0.8646 - val_loss: 0.4020 - val_accuracy: 0.8913\n",
            "Epoch 1845/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5444 - accuracy: 0.8613\n",
            "Epoch 1845: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5449 - accuracy: 0.8613 - val_loss: 0.4065 - val_accuracy: 0.8959\n",
            "Epoch 1846/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5633 - accuracy: 0.8553\n",
            "Epoch 1846: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5591 - accuracy: 0.8551 - val_loss: 0.4270 - val_accuracy: 0.8822\n",
            "Epoch 1847/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4679 - accuracy: 0.8691\n",
            "Epoch 1847: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4659 - accuracy: 0.8691 - val_loss: 0.4249 - val_accuracy: 0.8844\n",
            "Epoch 1848/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5043 - accuracy: 0.8667\n",
            "Epoch 1848: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4998 - accuracy: 0.8687 - val_loss: 0.4133 - val_accuracy: 0.8844\n",
            "Epoch 1849/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4815 - accuracy: 0.8704\n",
            "Epoch 1849: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4814 - accuracy: 0.8703 - val_loss: 0.3961 - val_accuracy: 0.8993\n",
            "Epoch 1850/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4503 - accuracy: 0.8760\n",
            "Epoch 1850: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4599 - accuracy: 0.8744 - val_loss: 0.4003 - val_accuracy: 0.8947\n",
            "Epoch 1851/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5230 - accuracy: 0.8723\n",
            "Epoch 1851: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5228 - accuracy: 0.8724 - val_loss: 0.4080 - val_accuracy: 0.8913\n",
            "Epoch 1852/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5068 - accuracy: 0.8636\n",
            "Epoch 1852: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4998 - accuracy: 0.8647 - val_loss: 0.4088 - val_accuracy: 0.8947\n",
            "Epoch 1853/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5035 - accuracy: 0.8688\n",
            "Epoch 1853: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5023 - accuracy: 0.8690 - val_loss: 0.4090 - val_accuracy: 0.8879\n",
            "Epoch 1854/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5691 - accuracy: 0.8564\n",
            "Epoch 1854: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5646 - accuracy: 0.8568 - val_loss: 0.4210 - val_accuracy: 0.8856\n",
            "Epoch 1855/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4917 - accuracy: 0.8659\n",
            "Epoch 1855: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4964 - accuracy: 0.8657 - val_loss: 0.3898 - val_accuracy: 0.8947\n",
            "Epoch 1856/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4826 - accuracy: 0.8692\n",
            "Epoch 1856: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4780 - accuracy: 0.8693 - val_loss: 0.4541 - val_accuracy: 0.8879\n",
            "Epoch 1857/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5458 - accuracy: 0.8603\n",
            "Epoch 1857: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5541 - accuracy: 0.8603 - val_loss: 0.4150 - val_accuracy: 0.8970\n",
            "Epoch 1858/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5271 - accuracy: 0.8618\n",
            "Epoch 1858: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5326 - accuracy: 0.8611 - val_loss: 0.4256 - val_accuracy: 0.8890\n",
            "Epoch 1859/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4955 - accuracy: 0.8732\n",
            "Epoch 1859: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4981 - accuracy: 0.8723 - val_loss: 0.4153 - val_accuracy: 0.8913\n",
            "Epoch 1860/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4874 - accuracy: 0.8662\n",
            "Epoch 1860: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.8663 - val_loss: 0.3990 - val_accuracy: 0.8936\n",
            "Epoch 1861/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5116 - accuracy: 0.8598\n",
            "Epoch 1861: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5058 - accuracy: 0.8614 - val_loss: 0.4128 - val_accuracy: 0.8799\n",
            "Epoch 1862/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5097 - accuracy: 0.8671\n",
            "Epoch 1862: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4998 - accuracy: 0.8699 - val_loss: 0.4095 - val_accuracy: 0.8890\n",
            "Epoch 1863/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5214 - accuracy: 0.8605\n",
            "Epoch 1863: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5189 - accuracy: 0.8621 - val_loss: 0.4018 - val_accuracy: 0.8913\n",
            "Epoch 1864/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4507 - accuracy: 0.8746\n",
            "Epoch 1864: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4497 - accuracy: 0.8746 - val_loss: 0.4032 - val_accuracy: 0.8902\n",
            "Epoch 1865/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5122 - accuracy: 0.8633\n",
            "Epoch 1865: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5085 - accuracy: 0.8640 - val_loss: 0.4224 - val_accuracy: 0.8993\n",
            "Epoch 1866/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4590 - accuracy: 0.8767\n",
            "Epoch 1866: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4556 - accuracy: 0.8775 - val_loss: 0.4476 - val_accuracy: 0.8913\n",
            "Epoch 1867/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4952 - accuracy: 0.8729\n",
            "Epoch 1867: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4976 - accuracy: 0.8714 - val_loss: 0.4056 - val_accuracy: 0.8902\n",
            "Epoch 1868/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4850 - accuracy: 0.8768\n",
            "Epoch 1868: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4813 - accuracy: 0.8772 - val_loss: 0.4363 - val_accuracy: 0.8799\n",
            "Epoch 1869/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4912 - accuracy: 0.8635\n",
            "Epoch 1869: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.8623 - val_loss: 0.3975 - val_accuracy: 0.8902\n",
            "Epoch 1870/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4686 - accuracy: 0.8780\n",
            "Epoch 1870: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4708 - accuracy: 0.8769 - val_loss: 0.4149 - val_accuracy: 0.8970\n",
            "Epoch 1871/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4686 - accuracy: 0.8711\n",
            "Epoch 1871: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4738 - accuracy: 0.8696 - val_loss: 0.4220 - val_accuracy: 0.9005\n",
            "Epoch 1872/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4936 - accuracy: 0.8777\n",
            "Epoch 1872: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4854 - accuracy: 0.8777 - val_loss: 0.4504 - val_accuracy: 0.8810\n",
            "Epoch 1873/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4511 - accuracy: 0.8756\n",
            "Epoch 1873: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4511 - accuracy: 0.8759 - val_loss: 0.4643 - val_accuracy: 0.8833\n",
            "Epoch 1874/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4774 - accuracy: 0.8759\n",
            "Epoch 1874: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4774 - accuracy: 0.8756 - val_loss: 0.4192 - val_accuracy: 0.8879\n",
            "Epoch 1875/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5163 - accuracy: 0.8674\n",
            "Epoch 1875: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5191 - accuracy: 0.8663 - val_loss: 0.4328 - val_accuracy: 0.8764\n",
            "Epoch 1876/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5552 - accuracy: 0.8560\n",
            "Epoch 1876: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5521 - accuracy: 0.8563 - val_loss: 0.4527 - val_accuracy: 0.8902\n",
            "Epoch 1877/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5510 - accuracy: 0.8587\n",
            "Epoch 1877: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5498 - accuracy: 0.8587 - val_loss: 0.4432 - val_accuracy: 0.8959\n",
            "Epoch 1878/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4654 - accuracy: 0.8678\n",
            "Epoch 1878: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4705 - accuracy: 0.8689 - val_loss: 0.4052 - val_accuracy: 0.8947\n",
            "Epoch 1879/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4689 - accuracy: 0.8677\n",
            "Epoch 1879: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4661 - accuracy: 0.8679 - val_loss: 0.4335 - val_accuracy: 0.8844\n",
            "Epoch 1880/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4471 - accuracy: 0.8779\n",
            "Epoch 1880: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 7ms/step - loss: 0.4471 - accuracy: 0.8779 - val_loss: 0.4216 - val_accuracy: 0.8970\n",
            "Epoch 1881/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4840 - accuracy: 0.8743\n",
            "Epoch 1881: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4837 - accuracy: 0.8750 - val_loss: 0.4725 - val_accuracy: 0.8776\n",
            "Epoch 1882/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.8738\n",
            "Epoch 1882: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4858 - accuracy: 0.8737 - val_loss: 0.4117 - val_accuracy: 0.8833\n",
            "Epoch 1883/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.8747\n",
            "Epoch 1883: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4675 - accuracy: 0.8743 - val_loss: 0.4031 - val_accuracy: 0.8947\n",
            "Epoch 1884/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5014 - accuracy: 0.8667\n",
            "Epoch 1884: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5034 - accuracy: 0.8660 - val_loss: 0.3866 - val_accuracy: 0.8822\n",
            "Epoch 1885/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4639 - accuracy: 0.8766\n",
            "Epoch 1885: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4652 - accuracy: 0.8752 - val_loss: 0.4110 - val_accuracy: 0.8844\n",
            "Epoch 1886/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4493 - accuracy: 0.8761\n",
            "Epoch 1886: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4601 - accuracy: 0.8742 - val_loss: 0.4232 - val_accuracy: 0.8890\n",
            "Epoch 1887/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5190 - accuracy: 0.8696\n",
            "Epoch 1887: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5190 - accuracy: 0.8696 - val_loss: 0.3891 - val_accuracy: 0.8936\n",
            "Epoch 1888/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5225 - accuracy: 0.8640\n",
            "Epoch 1888: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5288 - accuracy: 0.8637 - val_loss: 0.3897 - val_accuracy: 0.8970\n",
            "Epoch 1889/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4884 - accuracy: 0.8661\n",
            "Epoch 1889: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4904 - accuracy: 0.8659 - val_loss: 0.3911 - val_accuracy: 0.9016\n",
            "Epoch 1890/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4828 - accuracy: 0.8701\n",
            "Epoch 1890: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4839 - accuracy: 0.8700 - val_loss: 0.4025 - val_accuracy: 0.8913\n",
            "Epoch 1891/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5579 - accuracy: 0.8682\n",
            "Epoch 1891: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5518 - accuracy: 0.8687 - val_loss: 0.4104 - val_accuracy: 0.8833\n",
            "Epoch 1892/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4714 - accuracy: 0.8731\n",
            "Epoch 1892: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4752 - accuracy: 0.8726 - val_loss: 0.4286 - val_accuracy: 0.8902\n",
            "Epoch 1893/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.5158 - accuracy: 0.8596\n",
            "Epoch 1893: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5186 - accuracy: 0.8593 - val_loss: 0.4169 - val_accuracy: 0.8890\n",
            "Epoch 1894/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4975 - accuracy: 0.8632\n",
            "Epoch 1894: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5019 - accuracy: 0.8624 - val_loss: 0.4345 - val_accuracy: 0.8879\n",
            "Epoch 1895/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5412 - accuracy: 0.8591\n",
            "Epoch 1895: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5379 - accuracy: 0.8604 - val_loss: 0.4118 - val_accuracy: 0.8822\n",
            "Epoch 1896/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4581 - accuracy: 0.8676\n",
            "Epoch 1896: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4622 - accuracy: 0.8674 - val_loss: 0.3806 - val_accuracy: 0.9039\n",
            "Epoch 1897/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4993 - accuracy: 0.8676\n",
            "Epoch 1897: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5128 - accuracy: 0.8673 - val_loss: 0.4108 - val_accuracy: 0.8913\n",
            "Epoch 1898/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4878 - accuracy: 0.8670\n",
            "Epoch 1898: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4957 - accuracy: 0.8664 - val_loss: 0.4033 - val_accuracy: 0.8913\n",
            "Epoch 1899/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4841 - accuracy: 0.8639\n",
            "Epoch 1899: val_loss did not improve from 0.37125\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4799 - accuracy: 0.8650 - val_loss: 0.3928 - val_accuracy: 0.8856\n",
            "Epoch 1900/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4793 - accuracy: 0.8715\n",
            "Epoch 1900: val_loss improved from 0.37125 to 0.36752, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4752 - accuracy: 0.8723 - val_loss: 0.3675 - val_accuracy: 0.9027\n",
            "Epoch 1901/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4895 - accuracy: 0.8688\n",
            "Epoch 1901: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4895 - accuracy: 0.8687 - val_loss: 0.3818 - val_accuracy: 0.8970\n",
            "Epoch 1902/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.8718\n",
            "Epoch 1902: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4673 - accuracy: 0.8713 - val_loss: 0.3818 - val_accuracy: 0.8982\n",
            "Epoch 1903/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4520 - accuracy: 0.8705\n",
            "Epoch 1903: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4568 - accuracy: 0.8703 - val_loss: 0.3989 - val_accuracy: 0.8982\n",
            "Epoch 1904/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4555 - accuracy: 0.8736\n",
            "Epoch 1904: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4535 - accuracy: 0.8744 - val_loss: 0.3782 - val_accuracy: 0.8936\n",
            "Epoch 1905/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4906 - accuracy: 0.8749\n",
            "Epoch 1905: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4917 - accuracy: 0.8746 - val_loss: 0.3943 - val_accuracy: 0.8959\n",
            "Epoch 1906/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5352 - accuracy: 0.8680\n",
            "Epoch 1906: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5342 - accuracy: 0.8677 - val_loss: 0.3907 - val_accuracy: 0.8924\n",
            "Epoch 1907/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4488 - accuracy: 0.8747\n",
            "Epoch 1907: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4499 - accuracy: 0.8732 - val_loss: 0.3758 - val_accuracy: 0.8970\n",
            "Epoch 1908/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4993 - accuracy: 0.8708\n",
            "Epoch 1908: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4950 - accuracy: 0.8702 - val_loss: 0.3964 - val_accuracy: 0.8890\n",
            "Epoch 1909/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4807 - accuracy: 0.8728\n",
            "Epoch 1909: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4785 - accuracy: 0.8730 - val_loss: 0.3860 - val_accuracy: 0.8982\n",
            "Epoch 1910/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4656 - accuracy: 0.8787\n",
            "Epoch 1910: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4666 - accuracy: 0.8787 - val_loss: 0.3970 - val_accuracy: 0.8913\n",
            "Epoch 1911/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4679 - accuracy: 0.8738\n",
            "Epoch 1911: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4745 - accuracy: 0.8739 - val_loss: 0.4014 - val_accuracy: 0.8924\n",
            "Epoch 1912/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4895 - accuracy: 0.8647\n",
            "Epoch 1912: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4841 - accuracy: 0.8661 - val_loss: 0.3967 - val_accuracy: 0.8924\n",
            "Epoch 1913/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5212 - accuracy: 0.8622\n",
            "Epoch 1913: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5152 - accuracy: 0.8616 - val_loss: 0.4168 - val_accuracy: 0.8890\n",
            "Epoch 1914/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4828 - accuracy: 0.8702\n",
            "Epoch 1914: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4859 - accuracy: 0.8696 - val_loss: 0.4182 - val_accuracy: 0.8867\n",
            "Epoch 1915/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4801 - accuracy: 0.8661\n",
            "Epoch 1915: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4797 - accuracy: 0.8671 - val_loss: 0.3994 - val_accuracy: 0.8902\n",
            "Epoch 1916/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4904 - accuracy: 0.8620\n",
            "Epoch 1916: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4903 - accuracy: 0.8621 - val_loss: 0.4181 - val_accuracy: 0.8959\n",
            "Epoch 1917/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4800 - accuracy: 0.8693\n",
            "Epoch 1917: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4740 - accuracy: 0.8706 - val_loss: 0.4249 - val_accuracy: 0.8902\n",
            "Epoch 1918/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5495 - accuracy: 0.8624\n",
            "Epoch 1918: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5461 - accuracy: 0.8614 - val_loss: 0.4069 - val_accuracy: 0.8764\n",
            "Epoch 1919/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4933 - accuracy: 0.8683\n",
            "Epoch 1919: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4866 - accuracy: 0.8700 - val_loss: 0.4135 - val_accuracy: 0.8924\n",
            "Epoch 1920/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4530 - accuracy: 0.8735\n",
            "Epoch 1920: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4497 - accuracy: 0.8742 - val_loss: 0.4088 - val_accuracy: 0.8879\n",
            "Epoch 1921/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4831 - accuracy: 0.8732\n",
            "Epoch 1921: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4822 - accuracy: 0.8729 - val_loss: 0.4102 - val_accuracy: 0.8924\n",
            "Epoch 1922/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4517 - accuracy: 0.8797\n",
            "Epoch 1922: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4589 - accuracy: 0.8796 - val_loss: 0.4014 - val_accuracy: 0.8867\n",
            "Epoch 1923/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4764 - accuracy: 0.8752\n",
            "Epoch 1923: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4700 - accuracy: 0.8760 - val_loss: 0.4085 - val_accuracy: 0.8913\n",
            "Epoch 1924/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5322 - accuracy: 0.8710\n",
            "Epoch 1924: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.8700 - val_loss: 0.3922 - val_accuracy: 0.8890\n",
            "Epoch 1925/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4690 - accuracy: 0.8773\n",
            "Epoch 1925: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4645 - accuracy: 0.8773 - val_loss: 0.3836 - val_accuracy: 0.8913\n",
            "Epoch 1926/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5069 - accuracy: 0.8693\n",
            "Epoch 1926: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5069 - accuracy: 0.8693 - val_loss: 0.3817 - val_accuracy: 0.8924\n",
            "Epoch 1927/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4712 - accuracy: 0.8756\n",
            "Epoch 1927: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4722 - accuracy: 0.8769 - val_loss: 0.4096 - val_accuracy: 0.8947\n",
            "Epoch 1928/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5305 - accuracy: 0.8744\n",
            "Epoch 1928: val_loss did not improve from 0.36752\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5293 - accuracy: 0.8744 - val_loss: 0.3770 - val_accuracy: 0.8982\n",
            "Epoch 1929/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4633 - accuracy: 0.8755\n",
            "Epoch 1929: val_loss improved from 0.36752 to 0.36520, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4727 - accuracy: 0.8742 - val_loss: 0.3652 - val_accuracy: 0.8890\n",
            "Epoch 1930/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5718 - accuracy: 0.8611\n",
            "Epoch 1930: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5648 - accuracy: 0.8617 - val_loss: 0.4044 - val_accuracy: 0.8799\n",
            "Epoch 1931/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4531 - accuracy: 0.8658\n",
            "Epoch 1931: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4531 - accuracy: 0.8657 - val_loss: 0.3893 - val_accuracy: 0.8913\n",
            "Epoch 1932/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4352 - accuracy: 0.8786\n",
            "Epoch 1932: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4362 - accuracy: 0.8790 - val_loss: 0.3918 - val_accuracy: 0.8856\n",
            "Epoch 1933/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4685 - accuracy: 0.8714\n",
            "Epoch 1933: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4685 - accuracy: 0.8714 - val_loss: 0.3853 - val_accuracy: 0.8844\n",
            "Epoch 1934/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.8759\n",
            "Epoch 1934: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4662 - accuracy: 0.8757 - val_loss: 0.3933 - val_accuracy: 0.8867\n",
            "Epoch 1935/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4326 - accuracy: 0.8786\n",
            "Epoch 1935: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4380 - accuracy: 0.8782 - val_loss: 0.3943 - val_accuracy: 0.8947\n",
            "Epoch 1936/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.4569 - accuracy: 0.8712\n",
            "Epoch 1936: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4595 - accuracy: 0.8702 - val_loss: 0.4104 - val_accuracy: 0.8902\n",
            "Epoch 1937/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4822 - accuracy: 0.8703\n",
            "Epoch 1937: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4811 - accuracy: 0.8704 - val_loss: 0.3921 - val_accuracy: 0.8982\n",
            "Epoch 1938/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5155 - accuracy: 0.8719\n",
            "Epoch 1938: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5125 - accuracy: 0.8720 - val_loss: 0.4121 - val_accuracy: 0.8890\n",
            "Epoch 1939/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4958 - accuracy: 0.8601\n",
            "Epoch 1939: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4941 - accuracy: 0.8601 - val_loss: 0.4101 - val_accuracy: 0.8844\n",
            "Epoch 1940/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5091 - accuracy: 0.8638\n",
            "Epoch 1940: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5114 - accuracy: 0.8628 - val_loss: 0.4480 - val_accuracy: 0.8810\n",
            "Epoch 1941/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5548 - accuracy: 0.8703\n",
            "Epoch 1941: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5644 - accuracy: 0.8694 - val_loss: 0.4179 - val_accuracy: 0.8890\n",
            "Epoch 1942/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4829 - accuracy: 0.8687\n",
            "Epoch 1942: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4781 - accuracy: 0.8704 - val_loss: 0.4350 - val_accuracy: 0.8776\n",
            "Epoch 1943/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4469 - accuracy: 0.8725\n",
            "Epoch 1943: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4402 - accuracy: 0.8739 - val_loss: 0.4112 - val_accuracy: 0.8982\n",
            "Epoch 1944/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4273 - accuracy: 0.8772\n",
            "Epoch 1944: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4202 - accuracy: 0.8797 - val_loss: 0.3753 - val_accuracy: 0.9005\n",
            "Epoch 1945/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4344 - accuracy: 0.8786\n",
            "Epoch 1945: val_loss did not improve from 0.36520\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4337 - accuracy: 0.8787 - val_loss: 0.3975 - val_accuracy: 0.8902\n",
            "Epoch 1946/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4511 - accuracy: 0.8754\n",
            "Epoch 1946: val_loss improved from 0.36520 to 0.35800, saving model to saved_models/audio_classification.hdf5\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4510 - accuracy: 0.8754 - val_loss: 0.3580 - val_accuracy: 0.9005\n",
            "Epoch 1947/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4870 - accuracy: 0.8645\n",
            "Epoch 1947: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4959 - accuracy: 0.8639 - val_loss: 0.3988 - val_accuracy: 0.8856\n",
            "Epoch 1948/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5294 - accuracy: 0.8614\n",
            "Epoch 1948: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5294 - accuracy: 0.8614 - val_loss: 0.4037 - val_accuracy: 0.8924\n",
            "Epoch 1949/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.5318 - accuracy: 0.8612\n",
            "Epoch 1949: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5470 - accuracy: 0.8577 - val_loss: 0.4106 - val_accuracy: 0.8810\n",
            "Epoch 1950/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4968 - accuracy: 0.8708\n",
            "Epoch 1950: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4995 - accuracy: 0.8693 - val_loss: 0.3799 - val_accuracy: 0.8970\n",
            "Epoch 1951/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5251 - accuracy: 0.8655\n",
            "Epoch 1951: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5254 - accuracy: 0.8634 - val_loss: 0.4116 - val_accuracy: 0.8867\n",
            "Epoch 1952/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5158 - accuracy: 0.8642\n",
            "Epoch 1952: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5157 - accuracy: 0.8644 - val_loss: 0.3780 - val_accuracy: 0.8959\n",
            "Epoch 1953/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5238 - accuracy: 0.8619\n",
            "Epoch 1953: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5233 - accuracy: 0.8620 - val_loss: 0.3902 - val_accuracy: 0.8856\n",
            "Epoch 1954/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4791 - accuracy: 0.8681\n",
            "Epoch 1954: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4766 - accuracy: 0.8684 - val_loss: 0.3976 - val_accuracy: 0.8902\n",
            "Epoch 1955/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5767 - accuracy: 0.8648\n",
            "Epoch 1955: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5780 - accuracy: 0.8623 - val_loss: 0.4161 - val_accuracy: 0.8936\n",
            "Epoch 1956/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5761 - accuracy: 0.8522\n",
            "Epoch 1956: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5792 - accuracy: 0.8520 - val_loss: 0.4254 - val_accuracy: 0.8867\n",
            "Epoch 1957/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5622 - accuracy: 0.8533\n",
            "Epoch 1957: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5496 - accuracy: 0.8563 - val_loss: 0.4294 - val_accuracy: 0.8764\n",
            "Epoch 1958/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5224 - accuracy: 0.8653\n",
            "Epoch 1958: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5219 - accuracy: 0.8661 - val_loss: 0.4074 - val_accuracy: 0.8924\n",
            "Epoch 1959/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5171 - accuracy: 0.8568\n",
            "Epoch 1959: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5088 - accuracy: 0.8588 - val_loss: 0.4011 - val_accuracy: 0.8970\n",
            "Epoch 1960/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.8693\n",
            "Epoch 1960: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4641 - accuracy: 0.8693 - val_loss: 0.3739 - val_accuracy: 0.8879\n",
            "Epoch 1961/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4867 - accuracy: 0.8694\n",
            "Epoch 1961: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.4883 - accuracy: 0.8691 - val_loss: 0.3997 - val_accuracy: 0.8822\n",
            "Epoch 1962/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.5362 - accuracy: 0.8594\n",
            "Epoch 1962: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5333 - accuracy: 0.8593 - val_loss: 0.3925 - val_accuracy: 0.8879\n",
            "Epoch 1963/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5045 - accuracy: 0.8610\n",
            "Epoch 1963: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5045 - accuracy: 0.8610 - val_loss: 0.3772 - val_accuracy: 0.8959\n",
            "Epoch 1964/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4873 - accuracy: 0.8702\n",
            "Epoch 1964: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4820 - accuracy: 0.8702 - val_loss: 0.3971 - val_accuracy: 0.8867\n",
            "Epoch 1965/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4975 - accuracy: 0.8691\n",
            "Epoch 1965: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4932 - accuracy: 0.8704 - val_loss: 0.4001 - val_accuracy: 0.8844\n",
            "Epoch 1966/2000\n",
            "128/140 [==========================>...] - ETA: 0s - loss: 0.5468 - accuracy: 0.8603\n",
            "Epoch 1966: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5328 - accuracy: 0.8624 - val_loss: 0.3975 - val_accuracy: 0.8890\n",
            "Epoch 1967/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4885 - accuracy: 0.8667\n",
            "Epoch 1967: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4883 - accuracy: 0.8647 - val_loss: 0.3855 - val_accuracy: 0.8947\n",
            "Epoch 1968/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4793 - accuracy: 0.8703\n",
            "Epoch 1968: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4784 - accuracy: 0.8691 - val_loss: 0.4152 - val_accuracy: 0.8936\n",
            "Epoch 1969/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4952 - accuracy: 0.8768\n",
            "Epoch 1969: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4972 - accuracy: 0.8766 - val_loss: 0.4330 - val_accuracy: 0.8890\n",
            "Epoch 1970/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.4686 - accuracy: 0.8684\n",
            "Epoch 1970: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4688 - accuracy: 0.8679 - val_loss: 0.4184 - val_accuracy: 0.8902\n",
            "Epoch 1971/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.4641 - accuracy: 0.8797\n",
            "Epoch 1971: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4643 - accuracy: 0.8792 - val_loss: 0.4093 - val_accuracy: 0.8936\n",
            "Epoch 1972/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4838 - accuracy: 0.8717\n",
            "Epoch 1972: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4816 - accuracy: 0.8712 - val_loss: 0.4185 - val_accuracy: 0.8867\n",
            "Epoch 1973/2000\n",
            "137/140 [============================>.] - ETA: 0s - loss: 0.5145 - accuracy: 0.8695\n",
            "Epoch 1973: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5107 - accuracy: 0.8703 - val_loss: 0.4219 - val_accuracy: 0.8833\n",
            "Epoch 1974/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4910 - accuracy: 0.8660\n",
            "Epoch 1974: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4900 - accuracy: 0.8659 - val_loss: 0.4337 - val_accuracy: 0.8867\n",
            "Epoch 1975/2000\n",
            "138/140 [============================>.] - ETA: 0s - loss: 0.5041 - accuracy: 0.8700\n",
            "Epoch 1975: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 6ms/step - loss: 0.5044 - accuracy: 0.8694 - val_loss: 0.4086 - val_accuracy: 0.8970\n",
            "Epoch 1976/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4611 - accuracy: 0.8742\n",
            "Epoch 1976: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4581 - accuracy: 0.8744 - val_loss: 0.4062 - val_accuracy: 0.8810\n",
            "Epoch 1977/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4714 - accuracy: 0.8727\n",
            "Epoch 1977: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4743 - accuracy: 0.8726 - val_loss: 0.4019 - val_accuracy: 0.8879\n",
            "Epoch 1978/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.4923 - accuracy: 0.8728\n",
            "Epoch 1978: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4907 - accuracy: 0.8732 - val_loss: 0.4134 - val_accuracy: 0.8867\n",
            "Epoch 1979/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5114 - accuracy: 0.8624\n",
            "Epoch 1979: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5143 - accuracy: 0.8606 - val_loss: 0.4278 - val_accuracy: 0.8844\n",
            "Epoch 1980/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.5502 - accuracy: 0.8568\n",
            "Epoch 1980: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5502 - accuracy: 0.8570 - val_loss: 0.4178 - val_accuracy: 0.8902\n",
            "Epoch 1981/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5077 - accuracy: 0.8672\n",
            "Epoch 1981: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.8680 - val_loss: 0.4165 - val_accuracy: 0.8856\n",
            "Epoch 1982/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4576 - accuracy: 0.8708\n",
            "Epoch 1982: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4569 - accuracy: 0.8710 - val_loss: 0.4101 - val_accuracy: 0.8924\n",
            "Epoch 1983/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5628 - accuracy: 0.8610\n",
            "Epoch 1983: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5628 - accuracy: 0.8610 - val_loss: 0.4349 - val_accuracy: 0.8810\n",
            "Epoch 1984/2000\n",
            "133/140 [===========================>..] - ETA: 0s - loss: 0.5163 - accuracy: 0.8657\n",
            "Epoch 1984: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5184 - accuracy: 0.8650 - val_loss: 0.4040 - val_accuracy: 0.8924\n",
            "Epoch 1985/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4630 - accuracy: 0.8773\n",
            "Epoch 1985: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4633 - accuracy: 0.8770 - val_loss: 0.4208 - val_accuracy: 0.8833\n",
            "Epoch 1986/2000\n",
            "135/140 [===========================>..] - ETA: 0s - loss: 0.4297 - accuracy: 0.8839\n",
            "Epoch 1986: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4292 - accuracy: 0.8835 - val_loss: 0.3696 - val_accuracy: 0.8970\n",
            "Epoch 1987/2000\n",
            "134/140 [===========================>..] - ETA: 0s - loss: 0.4761 - accuracy: 0.8825\n",
            "Epoch 1987: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4807 - accuracy: 0.8816 - val_loss: 0.4535 - val_accuracy: 0.8936\n",
            "Epoch 1988/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.4852 - accuracy: 0.8774\n",
            "Epoch 1988: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4877 - accuracy: 0.8769 - val_loss: 0.4124 - val_accuracy: 0.8959\n",
            "Epoch 1989/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4987 - accuracy: 0.8701\n",
            "Epoch 1989: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4956 - accuracy: 0.8709 - val_loss: 0.3927 - val_accuracy: 0.8913\n",
            "Epoch 1990/2000\n",
            "136/140 [============================>.] - ETA: 0s - loss: 0.4693 - accuracy: 0.8726\n",
            "Epoch 1990: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4703 - accuracy: 0.8717 - val_loss: 0.3770 - val_accuracy: 0.9027\n",
            "Epoch 1991/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.5173 - accuracy: 0.8706\n",
            "Epoch 1991: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5079 - accuracy: 0.8720 - val_loss: 0.4228 - val_accuracy: 0.8810\n",
            "Epoch 1992/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.5071 - accuracy: 0.8685\n",
            "Epoch 1992: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5058 - accuracy: 0.8691 - val_loss: 0.3996 - val_accuracy: 0.8844\n",
            "Epoch 1993/2000\n",
            "132/140 [===========================>..] - ETA: 0s - loss: 0.5042 - accuracy: 0.8691\n",
            "Epoch 1993: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5109 - accuracy: 0.8699 - val_loss: 0.3702 - val_accuracy: 0.8867\n",
            "Epoch 1994/2000\n",
            "131/140 [===========================>..] - ETA: 0s - loss: 0.4614 - accuracy: 0.8786\n",
            "Epoch 1994: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4735 - accuracy: 0.8783 - val_loss: 0.3893 - val_accuracy: 0.8913\n",
            "Epoch 1995/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.5012 - accuracy: 0.8627\n",
            "Epoch 1995: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.5012 - accuracy: 0.8627 - val_loss: 0.3998 - val_accuracy: 0.8936\n",
            "Epoch 1996/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4474 - accuracy: 0.8784\n",
            "Epoch 1996: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4469 - accuracy: 0.8786 - val_loss: 0.3775 - val_accuracy: 0.8890\n",
            "Epoch 1997/2000\n",
            "130/140 [==========================>...] - ETA: 0s - loss: 0.4746 - accuracy: 0.8732\n",
            "Epoch 1997: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4733 - accuracy: 0.8729 - val_loss: 0.4067 - val_accuracy: 0.8913\n",
            "Epoch 1998/2000\n",
            "129/140 [==========================>...] - ETA: 0s - loss: 0.4567 - accuracy: 0.8690\n",
            "Epoch 1998: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4650 - accuracy: 0.8683 - val_loss: 0.3820 - val_accuracy: 0.8936\n",
            "Epoch 1999/2000\n",
            "139/140 [============================>.] - ETA: 0s - loss: 0.4623 - accuracy: 0.8755\n",
            "Epoch 1999: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4630 - accuracy: 0.8757 - val_loss: 0.3801 - val_accuracy: 0.8936\n",
            "Epoch 2000/2000\n",
            "140/140 [==============================] - ETA: 0s - loss: 0.4439 - accuracy: 0.8770\n",
            "Epoch 2000: val_loss did not improve from 0.35800\n",
            "140/140 [==============================] - 1s 5ms/step - loss: 0.4439 - accuracy: 0.8770 - val_loss: 0.3946 - val_accuracy: 0.8913\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5e6045f390>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "num_epochs = 2000\n",
        "num_batch_size = 50\n",
        "checkpointer = ModelCheckpoint(filepath='saved_models/audio_classification.hdf5', \n",
        "                               verbose=1, save_best_only=True)\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=num_batch_size, epochs=num_epochs, validation_data=(X_val, y_val), callbacks=[checkpointer], verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "BAx5L8gKanef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2471d69e-239f-471e-b5db-95d7bc31777f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9014891386032104\n"
          ]
        }
      ],
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "MHo6lsFIuXh8"
      },
      "outputs": [],
      "source": [
        "# Done"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DgHYX0r7nI4h"
      },
      "execution_count": 31,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "62KuqEjySSUU"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "2d8cd8638caa719e77c3ece9ee6c9cdab6f2065d170551d375a17b4273bc3a23"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}